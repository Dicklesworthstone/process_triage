{"id":"process_triage-00b","title":"Implement numerical stability primitives","description":"## Task\nImplement core numerical stability primitives used throughout the math library.\n\n## Background\nBayesian computation involves products of many small probabilities. Without log-domain computation and stability tricks, results underflow to zero.\n\n## Required Primitives\n1. **log_sum_exp(log_values)**: Compute log(sum(exp(log_values))) stably\n   - log_sum_exp([a,b,...]) = max + log(sum(exp(v - max)))\n   \n2. **log_add_exp(a, b)**: Compute log(exp(a) + exp(b))\n   - = max(a,b) + log1p(exp(-abs(a-b)))\n   \n3. **log_sub_exp(a, b)**: Compute log(exp(a) - exp(b)) for a \u003e b\n   - = a + log1p(-exp(b-a))\n   \n4. **lgamma(x)**: Log gamma function (may use system library)\n\n5. **log_beta(a, b)**: = lgamma(a) + lgamma(b) - lgamma(a+b)\n\n6. **log_factorial(n)**: = lgamma(n+1)\n\n7. **log_binomial(n, k)**: = lgamma(n+1) - lgamma(k+1) - lgamma(n-k+1)\n\n## Implementation Notes\n- Use Rust std::f64 intrinsics where available\n- Consider SIMD versions for batched operations\n- Handle inf/-inf/NaN gracefully\n- log1p and expm1 for small arguments\n\n## Test Cases\n- log_sum_exp([0,0]) ≈ log(2)\n- log_sum_exp([-1000, 0]) ≈ 0 (large value dominates)\n- Compare with naive implementation for moderate values\n\n## Deliverables\n- Rust module: math/stable.rs\n- Unit tests with edge cases\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:23:58.822231358-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:23:58.822231358-05:00"}
{"id":"process_triage-03n","title":"Implement evidence ledger display with drill-down","description":"## Overview\nCreate an interactive evidence ledger display allowing users to explore all signals collected for each process.\n\n## Background\nThe inference engine collects dozens of evidence signals per process: CPU usage patterns, memory trends, file descriptors, network connections, cgroup membership, etc. Users need to see this evidence to understand and verify recommendations.\n\n## Why It Matters\nTrust comes from transparency. When pt says a process is likely abandoned, users should be able to drill down and see exactly what signals contributed to that conclusion. This also helps identify false positives by revealing which evidence might be misleading.\n\n## Technical Approach\n1. Organize evidence by category (resources, timing, context, behavior)\n2. Show evidence items with their Bayesian weight contribution\n3. Implement drill-down from summary to detail view\n4. Support filtering by evidence type or strength\n5. Highlight strongest contributors (highest Bayes factors)\n\n## Display Components\n- **Summary row**: Top 3 contributors with abbreviated values\n- **Category panels**: Expandable sections for each evidence type\n- **Detail view**: Full signal value, prior, likelihood, posterior contribution\n- **Search/filter**: Find specific evidence by name or value\n\n## Evidence Categories\n- Resource usage (CPU, memory, IO)\n- Timing (age, idle time, burst patterns)\n- Context (parent, cgroup, user)\n- Behavior (signals, restarts, file activity)\n- Network (connections, listening ports)\n\n## Success Criteria\n- All evidence visible and organized\n- Drill-down navigation intuitive\n- Search and filter functional\n- Bayes factor contributions displayed accurately","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:32:03.504657493-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:32:47.812911028-05:00"}
{"id":"process_triage-097","title":"Self-Update Mechanism","description":"## Overview\nAdd a secure, robust self-update mechanism to pt, following the patterns established in repo_updater and giil.\n\n## Current State\n- pt has NO self-update capability\n- Users must manually check for updates\n- No VERSION file for version tracking\n- No infrastructure for update verification\n\n## Target State\nA complete self-update system with:\n1. **Version detection** via HTTP redirect (no GitHub API needed)\n2. **Checksum verification** for security\n3. **Bash syntax validation** before replacement\n4. **Atomic file replacement** to prevent corruption\n5. **Permission pre-checking** for fail-fast behavior\n\n## Why No GitHub API?\nFrom repo_updater's design:\n- Avoids rate limiting issues\n- Works through corporate proxies that block API\n- Simpler implementation with fewer failure modes\n- Uses redirect probing: curl follows `/releases/latest` → extracts version from final URL\n\n## Security Model\n1. Download checksums.txt from GitHub release\n2. Verify downloaded script matches expected hash\n3. Validate bash syntax with `bash -n`\n4. Only then replace the running script\n\n## Implementation Pattern\n```bash\n# Get latest version without API\nlatest_url=$(curl -fsSL -o /dev/null -w '%{url_effective}' \\\n    'https://github.com/USER/REPO/releases/latest')\nlatest_version=${latest_url##*/v}  # Extract version from URL\n\n# Verify checksum\nexpected=$(curl -fsSL \".../checksums.sha256\" | grep ' pt$' | cut -d' ' -f1)\nactual=$(sha256sum \"$temp_file\" | cut -d' ' -f1)\n[[ \"$expected\" == \"$actual\" ]] || die 'Checksum mismatch'\n\n# Validate syntax before replacing\nbash -n \"$temp_file\" || die 'Downloaded file is not valid bash'\n\n# Atomic replacement\nmv \"$temp_file\" \"$script_path\"\n```\n\n## CLI Integration\n- `pt update` - Check and install updates\n- `pt update --check` - Check only, don't install\n- `pt --version` - Show current version (already exists)\n\n## Success Criteria\n- [ ] VERSION file exists and is single source of truth\n- [ ] Update check works without GitHub API\n- [ ] Checksums are verified before installation\n- [ ] Syntax is validated before replacement\n- [ ] Atomic replacement prevents corruption\n- [ ] Clear messaging for all outcomes","status":"open","priority":1,"issue_type":"epic","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:31:19.148532987-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:31:19.148532987-05:00"}
{"id":"process_triage-0ij","title":"Implement Bayes factor computation","description":"## Task\nImplement Bayes factor computation for model comparison.\n\n## Background\nSection 4.4 describes Bayes factors:\n- BF_{H1,H0} = P(data|H1) / P(data|H0)\n- log BF = log P(data|H1) - log P(data|H0)\n- Interpretation: evidence strength for H1 over H0\n\nFor conjugate models, marginal likelihoods are available in closed form:\n- Beta-Binomial: ∫ P(k|n,p) Beta(p|a,b) dp = BetaBinom(k|n,a,b)\n- Gamma-Poisson: similar closed form\n\nMDL interpretation (Section 4.4):\n- -log marginal likelihood = code length\n- Comparing BF = comparing compression\n\n## Functions Needed\n- log_marginal_likelihood(model, data) - per model type\n- log_bayes_factor(model1, model2, data)\n- bayes_factor_to_evidence_strength(bf) → 'barely', 'substantial', 'strong', etc.\n\n## Evidence Strength Scale (Jeffreys)\n- BF \u003c 1: supports H0\n- 1-3: barely worth mentioning\n- 3-10: substantial\n- 10-30: strong\n- 30-100: very strong\n- \u003e100: decisive\n\n## Implementation Notes\n- Always work in log domain\n- Return both log BF and interpretable category\n- Handle degenerate cases (infinite evidence)\n\n## Deliverables\n- Rust module: math/bayes_factor.rs\n- Unit tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:23:59.561583099-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:23:59.561583099-05:00"}
{"id":"process_triage-0io","title":"Implement Kalman smoothing for noisy signals","description":"## Task\nImplement Kalman filtering/smoothing for denoising CPU/load time series.\n\n## Background\nSection 4.23 specifies:\n- Linear Gaussian state-space model\n- Closed-form filtering and smoothing\n- Reduces noise in CPU/load observations\n\n## Model\nx_t = A × x_{t-1} + w_t (state evolution)\ny_t = C × x_t + v_t (observation)\n\nWhere:\n- x_t is true underlying CPU/load\n- y_t is noisy observation\n- w_t ~ N(0, Q), v_t ~ N(0, R)\n\n## Implementation Notes\n- Single-variable case (scalar Kalman)\n- Forward filtering pass\n- Backward smoothing pass (RTS smoother)\n- Tune Q, R based on observed noise characteristics\n\n## Use Cases\n- Smooth CPU% time series before trend fitting\n- Detect true level vs measurement noise\n- Improve change-point detection\n\n## Output Structure\n{\n  \"kalman_smoothed\": {\n    \"cpu\": [45.2, 46.1, 45.8, ...],  // smoothed values\n    \"uncertainty\": [2.1, 1.8, 1.5, ...]  // posterior std\n  }\n}\n\n## Deliverables\n- Rust module: inference/kalman.rs\n- Scalar Kalman filter\n- RTS smoother\n- Unit tests\n- Documentation","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:27:46.151196187-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:27:46.151196187-05:00"}
{"id":"process_triage-0nk","title":"Add unit tests for each CLI command","description":"## Purpose\nCreate systematic unit tests for each pt CLI command to verify correct behavior, error handling, and edge cases.\n\n## Parent Epic\nExpanded Test Coverage (process_triage-bgd)\n\n## Depends On\n- Test helper with mock injection (process_triage-h2y)\n\n## Test Scenarios\n\n### test/test_commands.bats\n\n```bash\n#!/usr/bin/env bats\n\nload 'test_helper/common'\n\nsetup() {\n    setup_test_env\n    test_start \"$BATS_TEST_NAME\" \"CLI command test\"\n    export PT_SCRIPT=\"${BATS_TEST_DIRNAME}/../pt\"\n}\n\nteardown() {\n    test_end \"$BATS_TEST_NAME\" \"${BATS_TEST_COMPLETED:-fail}\"\n    restore_path\n    teardown_test_env\n}\n\n#==============================================================================\n# HELP COMMAND TESTS\n#==============================================================================\n\n@test \"Command: pt help shows usage information\" {\n    test_info \"Running: pt help\"\n    run \"$PT_SCRIPT\" help\n    \n    assert_equals \"0\" \"$status\" \"help should succeed\"\n    \n    test_info \"Verifying help content\"\n    assert_contains \"$output\" \"Process Triage\" \"Should show tool name\"\n    assert_contains \"$output\" \"scan\" \"Should document scan\"\n    assert_contains \"$output\" \"history\" \"Should document history\"\n    assert_contains \"$output\" \"clear\" \"Should document clear\"\n    assert_contains \"$output\" \"help\" \"Should document help\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Command: pt --help is alias for help\" {\n    test_info \"Running: pt --help\"\n    run \"$PT_SCRIPT\" --help\n    \n    assert_equals \"0\" \"$status\" \"--help should succeed\"\n    assert_contains \"$output\" \"Process Triage\" \"Should show same content as help\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Command: pt -h is alias for help\" {\n    test_info \"Running: pt -h\"\n    run \"$PT_SCRIPT\" -h\n    \n    assert_equals \"0\" \"$status\" \"-h should succeed\"\n    assert_contains \"$output\" \"Process Triage\" \"Should show same content as help\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# VERSION COMMAND TESTS\n#==============================================================================\n\n@test \"Command: pt --version shows version\" {\n    test_info \"Running: pt --version\"\n    run \"$PT_SCRIPT\" --version\n    \n    assert_equals \"0\" \"$status\" \"version should succeed\"\n    assert_contains \"$output\" \"pt version\" \"Should show version prefix\"\n    \n    # Verify semver format\n    test_info \"Checking version format\"\n    [[ \"$output\" =~ [0-9]+\\.[0-9]+\\.[0-9]+ ]]\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Command: pt -v is alias for version\" {\n    test_info \"Running: pt -v\"\n    run \"$PT_SCRIPT\" -v\n    \n    assert_equals \"0\" \"$status\" \"-v should succeed\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Command: pt version is alias for --version\" {\n    test_info \"Running: pt version\"\n    run \"$PT_SCRIPT\" version\n    \n    assert_equals \"0\" \"$status\" \"version subcommand should succeed\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# SCAN COMMAND TESTS\n#==============================================================================\n\n@test \"Command: pt scan succeeds with no processes\" {\n    test_info \"Setting up: empty process list\"\n    \n    create_mock_ps \"\"\n    use_mock_bin\n    \n    test_info \"Running: pt scan\"\n    run \"$PT_SCRIPT\" scan\n    \n    # Should succeed even with no candidates\n    assert_equals \"0\" \"$status\" \"scan should succeed\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Command: pt scan shows candidates when found\" {\n    test_info \"Setting up: mock process list\"\n    \n    create_mock_ps \"$(mock_ps_with_stuck_test 7200)\"\n    use_mock_bin\n    \n    test_info \"Running: pt scan\"\n    run \"$PT_SCRIPT\" scan\n    \n    assert_equals \"0\" \"$status\" \"scan should succeed\"\n    \n    # Should show the process\n    test_info \"Verifying output contains process info\"\n    # Output format depends on implementation\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Command: pt scan respects NO_COLOR\" {\n    test_info \"Setting up: NO_COLOR environment\"\n    \n    export NO_COLOR=1\n    create_mock_ps \"$(mock_ps_with_stuck_test)\"\n    use_mock_bin\n    \n    test_info \"Running: pt scan with NO_COLOR=1\"\n    run \"$PT_SCRIPT\" scan\n    \n    # Output should NOT contain ANSI escape codes\n    assert_not_contains \"$output\" $'\\033' \"Should not contain escape codes\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# HISTORY COMMAND TESTS\n#==============================================================================\n\n@test \"Command: pt history with empty decisions\" {\n    test_info \"Setting up: empty decision file\"\n    \n    echo '{}' \u003e \"${CONFIG_DIR}/decisions.json\"\n    export PROCESS_TRIAGE_CONFIG=\"$CONFIG_DIR\"\n    \n    test_info \"Running: pt history\"\n    run \"$PT_SCRIPT\" history\n    \n    assert_equals \"0\" \"$status\" \"history should succeed\"\n    \n    # Should indicate no history or show empty\n    test_info \"Output: $output\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Command: pt history shows saved decisions\" {\n    skip_if_no_jq\n    \n    test_info \"Setting up: populated decision file\"\n    \n    cat \u003e \"${CONFIG_DIR}/decisions.json\" \u003c\u003c 'EOF'\n{\n    \"bun test --watch\": \"kill\",\n    \"gunicorn\": \"spare\",\n    \"next dev\": \"kill\"\n}\nEOF\n    export PROCESS_TRIAGE_CONFIG=\"$CONFIG_DIR\"\n    \n    test_info \"Running: pt history\"\n    run \"$PT_SCRIPT\" history\n    \n    assert_equals \"0\" \"$status\" \"history should succeed\"\n    \n    # Should show the patterns\n    assert_contains \"$output\" \"bun test\" \"Should show bun test pattern\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# CLEAR COMMAND TESTS\n#==============================================================================\n\n@test \"Command: pt clear removes decisions (non-interactive)\" {\n    skip_if_no_jq\n    \n    test_info \"Setting up: decisions to clear\"\n    \n    echo '{\"pattern1\": \"kill\"}' \u003e \"${CONFIG_DIR}/decisions.json\"\n    export PROCESS_TRIAGE_CONFIG=\"$CONFIG_DIR\"\n    \n    # For non-interactive, we need to handle confirmation\n    # This depends on implementation\n    \n    test_info \"Running: pt clear\"\n    # May need to pipe 'y' for confirmation\n    echo 'y' | \"$PT_SCRIPT\" clear 2\u003e/dev/null || run \"$PT_SCRIPT\" clear --force 2\u003e/dev/null || true\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# ERROR HANDLING TESTS\n#==============================================================================\n\n@test \"Command: unknown command shows error\" {\n    test_info \"Running: pt unknowncommand\"\n    run \"$PT_SCRIPT\" unknowncommand\n    \n    # Should fail\n    [[ $status -ne 0 ]]\n    \n    # Should show helpful message\n    assert_contains \"$output\" \"Unknown\\|unknown\\|help\" \"Should mention unknown or help\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Command: multiple unknown commands all fail\" {\n    for cmd in foo bar baz notacommand; do\n        test_info \"Testing unknown command: $cmd\"\n        run \"$PT_SCRIPT\" \"$cmd\"\n        [[ $status -ne 0 ]]\n    done\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# DEFAULT COMMAND TESTS\n#==============================================================================\n\n@test \"Command: pt with no args runs default (run)\" {\n    test_info \"Setting up: mock for default command\"\n    \n    # Default command should be 'run' (interactive mode)\n    # In test, this might need special handling\n    \n    export CI=true  # Might affect behavior\n    create_mock_ps \"\"\n    use_mock_bin\n    \n    test_info \"Running: pt (no arguments)\"\n    # This might prompt for input in interactive mode\n    # Run with timeout or specific test handling\n    timeout 5 \"$PT_SCRIPT\" 2\u003e/dev/null || true\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Command: pt run is explicit default\" {\n    test_info \"Running: pt run\"\n    \n    export CI=true\n    create_mock_ps \"\"\n    use_mock_bin\n    \n    timeout 5 \"$PT_SCRIPT\" run 2\u003e/dev/null || true\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# ENVIRONMENT VARIABLE TESTS\n#==============================================================================\n\n@test \"Command: respects PT_DEBUG=1\" {\n    test_info \"Setting up: PT_DEBUG=1\"\n    \n    export PT_DEBUG=1\n    create_mock_ps \"$(mock_ps_with_stuck_test)\"\n    use_mock_bin\n    \n    test_info \"Running: pt scan with debug\"\n    run \"$PT_SCRIPT\" scan\n    \n    # Debug output should appear (depends on implementation)\n    test_info \"Output length: ${#output}\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n```\n\n## Success Criteria\n- [ ] help command and aliases tested\n- [ ] version command and aliases tested\n- [ ] scan command tested (empty, with results, NO_COLOR)\n- [ ] history command tested (empty, populated)\n- [ ] clear command tested\n- [ ] Unknown commands tested\n- [ ] Default command tested\n- [ ] Environment variables tested\n- [ ] All tests have detailed logging","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:49:13.792264809-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:49:13.792264809-05:00","dependencies":[{"issue_id":"process_triage-0nk","depends_on_id":"process_triage-h2y","type":"blocks","created_at":"2026-01-14T22:50:31.165127826-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-0pu","title":"Implement supervisor signature database","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:34:49.89288293-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:34:49.89288293-05:00"}
{"id":"process_triage-0uy","title":"Implement posterior predictive checks (PPC)","description":"## Task\nImplement posterior predictive checks for detecting model misspecification.\n\n## Background\nSection 4.41 specifies PPC:\n- Compare observed traces to posterior predictive distributions\n- Detect when model doesn't fit the data\n- Trigger fallback to robust layers when PPC fails\n\n## Approach\n1. Generate samples from posterior predictive\n2. Compute test statistics on real and simulated data\n3. p-value = P(T(sim) ≥ T(real))\n4. Low p-value indicates misspecification\n\n## Test Statistics\n- Mean CPU%\n- Variance of IO\n- Run lengths\n- Change-point counts\n\n## When PPC Fails\n- Widen priors (more uncertainty)\n- Switch to robust layers (Huberization, DRO)\n- Reduce Safe-Bayes learning rate η\n- Flag in output for transparency\n\n## Integration with MDL\n- Monitor prequential log-loss\n- Sustained surprise = misspecification trigger\n- CTW regret as drift indicator\n\n## Output Structure\n{\n  \"ppc_results\": {\n    \"passed\": false,\n    \"failed_checks\": [\"cpu_variance\", \"io_pattern\"],\n    \"action_taken\": \"widened_priors\",\n    \"confidence_adjustment\": -0.1\n  }\n}\n\n## Deliverables\n- Rust module: inference/ppc.rs\n- Test statistic computation\n- Misspecification detection\n- Fallback triggering\n- Unit tests\n- Documentation","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:28:12.809874805-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:28:12.809874805-05:00"}
{"id":"process_triage-167","title":"Implement maximal tool installation system (Phase 3a)","description":"## Task\nImplement the bash wrapper's tool installation system that attempts to install all available instrumentation tools.\n\n## Background\nSection 3a specifies 'always try to install everything':\n- Detect OS and package manager\n- Attempt full install; continue on individual failures\n- Use non-interactive installs\n- Record what's available vs missing\n- Download pinned binaries when packages unavailable\n\n## Package Lists by Platform\n**Debian/Ubuntu (apt)**:\nsysstat, linux-tools-common, linux-tools-$(uname -r), bpftrace, bcc, bpftool, iotop, nethogs, iftop, lsof, atop, sysdig, smem, numactl, turbostat, powertop, strace, ltrace, ethtool, iproute2, conntrack-tools, cgroup-tools, acct, auditd, pcp, gdb, elfutils, binutils\n\n**Fedora/RHEL (dnf)**: Similar set with dnf package names\n\n**Arch (pacman)**: Similar set with pacman package names\n\n**Alpine (apk)**: Reduced set for minimal environments\n\n**macOS (Homebrew)**: lsof, htop, plus native tools (fs_usage, sample, spindump, powermetrics)\n\n## Implementation Notes\n- Script in bash for wrapper\n- Use sudo -n (non-interactive) to avoid hanging\n- Log all install attempts\n- Create capabilities manifest after install\n- Handle daemonized packages carefully (don't auto-start auditd)\n\n## Deliverables\n- Bash script: pt-install-tools\n- Per-platform package lists\n- Capabilities manifest generator\n- Installation log format\n- Documentation","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:25:36.370403179-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:25:36.370403179-05:00"}
{"id":"process_triage-18z","title":"Add TTY detection and NO_COLOR support","description":"## Purpose\nAdd proper terminal detection to ensure colors/styling only appear when appropriate, following accessibility standards.\n\n## Parent Epic\nConsole Output Styling Enhancement (process_triage-y8e)\n\n## Current State\nThe pt script uses colors unconditionally via gum. No fallback exists when:\n- Output is piped (`pt scan | grep something`)\n- Running in CI environment\n- User has NO_COLOR set (accessibility)\n- Terminal doesn't support colors\n\n## Implementation\n\n### 1. Add Detection Variables (near top of script)\n```bash\n#------------------------------------------------------------------------------\n# Terminal detection\n#------------------------------------------------------------------------------\n\n# Detect if we're in an interactive terminal\nIS_TTY=false\n[[ -t 1 ]] \u0026\u0026 IS_TTY=true\n\n# Detect if colors should be disabled\n# NO_COLOR is a standard: https://no-color.org/\nUSE_COLOR=true\nif [[ \"$IS_TTY\" \\!= \"true\" ]] || [[ -n \"${NO_COLOR:-}\" ]]; then\n    USE_COLOR=false\nfi\n\n# Detect CI environment\nIS_CI=false\n[[ -n \"${CI:-}\" ]] \u0026\u0026 IS_CI=true\n```\n\n### 2. Conditional Color Definitions\n```bash\n#------------------------------------------------------------------------------\n# ANSI color codes (disabled if NO_COLOR or non-TTY)\n#------------------------------------------------------------------------------\n\nif [[ \"$USE_COLOR\" == \"true\" ]]; then\n    RED='\\033[0;31m'\n    GREEN='\\033[0;32m'\n    YELLOW='\\033[1;33m'\n    BLUE='\\033[0;34m'\n    CYAN='\\033[0;36m'\n    MAGENTA='\\033[0;35m'\n    BOLD='\\033[1m'\n    DIM='\\033[2m'\n    RESET='\\033[0m'\nelse\n    RED='' GREEN='' YELLOW='' BLUE='' CYAN='' MAGENTA=''\n    BOLD='' DIM='' RESET=''\nfi\n```\n\n### 3. Update Gum Availability Check\n```bash\n# Gum should only be used in interactive TTY, not in CI\nGUM_AVAILABLE=false\nif [[ \"$IS_TTY\" == \"true\" ]] \u0026\u0026 [[ \"$IS_CI\" \\!= \"true\" ]] \u0026\u0026 command -v gum \u0026\u003e/dev/null; then\n    GUM_AVAILABLE=true\nfi\n```\n\n## Testing\n```bash\n# Should show colors\npt scan\n\n# Should NOT show colors\npt scan | cat\nNO_COLOR=1 pt scan\nCI=true pt scan\n```\n\n## NO_COLOR Standard\nFrom https://no-color.org/:\n\u003e Command-line software which adds ANSI color to its output by default should check for the presence of a NO_COLOR environment variable that, when present (regardless of its value), prevents the addition of ANSI color.\n\n## Success Criteria\n- [ ] Colors appear in interactive terminal\n- [ ] Colors disabled when piped\n- [ ] Colors disabled when NO_COLOR is set\n- [ ] Colors disabled in CI environments\n- [ ] Gum only used in interactive TTY","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:33:31.544024152-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:33:31.544024152-05:00"}
{"id":"process_triage-1t1","title":"Implement action plan generation","description":"## Task\nImplement generation of executable action plans from decisions.\n\n## Background\nAfter inference and decision, we need an explicit action plan:\n- Per-PID recommended action\n- Ordering (dependencies, safety)\n- Timeouts and rollback hints\n- Pre-flight checks\n\n## Plan Structure\n{\n  \"plan_id\": \"plan-abc123\",\n  \"session_id\": \"sess-xyz789\",\n  \"actions\": [\n    {\n      \"target\": {\"pid\": 1234, \"start_id\": \"12345.1234\", \"uid\": 1000},\n      \"action\": \"pause\",\n      \"order\": 1,\n      \"timeout_ms\": 5000,\n      \"pre_checks\": [\"verify_identity\", \"check_not_protected\"],\n      \"on_success\": [\"proceed_to_next\"],\n      \"on_failure\": [\"log_failure\", \"skip_to_next\"]\n    },\n    {\n      \"target\": {\"pid\": 1234, \"start_id\": \"12345.1234\", \"uid\": 1000},\n      \"action\": \"kill\",\n      \"order\": 2,\n      \"wait_before_ms\": 5000,  // observe paused state first\n      \"timeout_ms\": 10000\n    }\n  ],\n  \"pre_toggled\": [1234, 2345],  // for TUI\n  \"safety_gates_passed\": true\n}\n\n## Implementation Notes\n- Generate from decision output\n- Apply staging rules (pause before kill)\n- Include identity tuples for all targets\n- Mark pre-toggled for TUI display\n- Include safety gate status\n\n## Deliverables\n- Rust module: action/plan.rs\n- Plan generation from decisions\n- Staging logic\n- Unit tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:29:48.003991085-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:29:48.003991085-05:00"}
{"id":"process_triage-1zu","title":"Add checksum verification option to installer","description":"## Purpose\nAdd optional checksum verification to the installer, enabled via VERIFY=1 environment variable.\n\n## Parent Epic\nInstallation Infrastructure (process_triage-n0r)\n\n## Depends On\n- Add cross-platform mktemp and download functions\n- Release automation generates checksums (process_triage-aip)\n\n## Usage\n\n```bash\n# Without verification (default - for simplicity)\ncurl -fsSL .../install.sh | bash\n\n# With verification (security-conscious users)\nVERIFY=1 curl -fsSL .../install.sh | bash\n```\n\n## Implementation\n\n```bash\nverify_download() {\n    local file=\"$1\"\n    local version=\"$2\"\n    \n    if [[ \"${VERIFY:-}\" != \"1\" ]]; then\n        return 0  # Verification not requested\n    fi\n    \n    log_step \"Verifying checksum...\"\n    \n    # Download expected checksum\n    local checksum_url=\"${RELEASES_URL}/download/v${version}/pt.sha256\"\n    local expected\n    \n    expected=$(curl -fsSL --connect-timeout 5 \"$checksum_url\" 2\u003e/dev/null) || {\n        log_error \"Could not download checksum file\"\n        log_error \"URL: $checksum_url\"\n        log_error \"\"\n        log_error \"If this is a new release, checksums may not be available yet.\"\n        log_error \"Try again in a few minutes, or install without verification:\"\n        log_error \"  curl -fsSL .../install.sh | bash\"\n        return 1\n    }\n    \n    # Extract hash (format: \"hash  filename\" or just \"hash\")\n    expected=\"${expected%% *}\"\n    \n    # Compute actual\n    local actual\n    actual=$(sha256_file \"$file\") || {\n        log_warn \"Could not compute checksum (no SHA256 tool)\"\n        log_warn \"Skipping verification\"\n        return 0\n    }\n    \n    # Compare\n    if [[ \"$expected\" == \"$actual\" ]]; then\n        log_success \"Checksum verified: ${actual:0:16}...\"\n        return 0\n    else\n        log_error \"Checksum mismatch!\"\n        log_error \"Expected: $expected\"\n        log_error \"Actual:   $actual\"\n        log_error \"\"\n        log_error \"The downloaded file may be corrupted or tampered with.\"\n        log_error \"Please report this issue if it persists.\"\n        return 1\n    fi\n}\n```\n\n## Integration\n\n```bash\nmain() {\n    # ... download pt to temp file ...\n    \n    # Verify if requested\n    if ! verify_download \"$temp_file\" \"$version\"; then\n        log_error \"Installation aborted due to verification failure\"\n        exit 1\n    fi\n    \n    # ... continue with installation ...\n}\n```\n\n## Manual Verification Instructions (for README)\n\n```bash\n# Download pt\ncurl -fsSL https://github.com/.../releases/download/v1.0.0/pt -o pt\n\n# Download checksum\ncurl -fsSL https://github.com/.../releases/download/v1.0.0/pt.sha256 -o pt.sha256\n\n# Verify\nsha256sum -c pt.sha256\n# or on macOS:\nshasum -a 256 -c pt.sha256\n```\n\n## Success Criteria\n- [ ] VERIFY=1 enables verification\n- [ ] Without VERIFY, install proceeds without check\n- [ ] Clear error if checksum file unavailable\n- [ ] Clear error on mismatch\n- [ ] Works on Linux (sha256sum) and macOS (shasum)\n- [ ] Graceful degradation if no SHA256 tool","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:36:33.838790733-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:36:33.838790733-05:00","dependencies":[{"issue_id":"process_triage-1zu","depends_on_id":"process_triage-c57","type":"blocks","created_at":"2026-01-14T22:40:45.58810567-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-22q","title":"Implement Gamma distribution and hazard rate updates","description":"## Task\nImplement Gamma distribution utilities for hazard rate modeling.\n\n## Background\nSection 4.5 uses Gamma priors on hazard rates:\n- λ ~ Gamma(α, β) - prior on hazard rate (rate parameterization)\n- Posterior after exposure E and events N: Gamma(α + N, β + E)\n- Mean: α/β, Variance: α/β²\n\nHazard rates appear in:\n- Per-regime abandonment hazards\n- Survival modeling\n- Runtime distributions\n\n## Functions Needed\n- gamma_pdf(x, shape, rate)\n- log_gamma_pdf(x, shape, rate)\n- gamma_cdf(x, shape, rate)\n- gamma_mean(shape, rate) = shape / rate\n- gamma_var(shape, rate) = shape / rate²\n- gamma_update(shape, rate, events, exposure) → (shape_new, rate_new)\n\n## Implementation Notes\n- Use rate parameterization throughout (not scale)\n- log_gamma_pdf = shape*log(rate) - lgamma(shape) + (shape-1)*log(x) - rate*x\n- Handle x=0 edge case\n- Lomax/Pareto-II: marginal survival when integrating out λ\n\n## Test Cases\n- Exponential is Gamma(1, rate)\n- Chi-squared is Gamma(k/2, 1/2)\n- Known quantiles from tables\n\n## Deliverables\n- Rust module: math/gamma.rs\n- Unit tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:23:32.57947795-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:23:32.57947795-05:00"}
{"id":"process_triage-2f3","title":"Create priors.json schema for Bayesian hyperparameters","description":"## Task\nDefine the JSON schema for priors.json which contains all Bayesian hyperparameters used by the inference engine.\n\n## Background\nThe inference engine uses conjugate priors throughout:\n- Beta distributions for Bernoulli features (orphan, TTY, net activity)\n- Beta-Binomial for CPU occupancy\n- Gamma distributions for hazard rates and runtime\n- Dirichlet for categorical features (command categories, state flags)\n\nSection 4.2-4.5 specifies:\n- CPU: p_u,C ~ Beta(alpha_C, beta_C)\n- Runtime: t|C ~ Gamma(α_t,C, β_t,C)\n- Orphan: p_o,C ~ Beta(a_o,C, b_o,C)\n- State flags: pi_C ~ Dirichlet(alpha^state_C)\n- Command/CWD: rho_C ~ Dirichlet(alpha^cmd_C)\n- TTY: q_C ~ Beta(a_tty,C, b_tty,C)\n- Net: r_C ~ Beta(a_net,C, b_net,C)\n- Hazard rates: lambda ~ Gamma(α, β) per regime\n\n## Deliverables\n- JSON Schema for priors.json\n- Default prior values with documentation\n- Per-class (useful, useful-but-bad, abandoned, zombie) hyperparameters\n- Hazard regime definitions (TTY lost, PPID=1, IO flatline, etc.)\n- Version field for schema evolution\n\n## Technical Considerations\n- Use rate parameterization for Gamma (shape, rate) not (shape, scale)\n- Hyperparameters should be human-editable\n- Include comments/documentation fields\n- Support machine-level customization (learned priors)\n\n## Example Structure\n{\n  \"schema_version\": \"1.0\",\n  \"classes\": {\n    \"useful\": {\n      \"prior_prob\": 0.7,\n      \"cpu_beta\": {\"alpha\": 2.0, \"beta\": 5.0},\n      \"runtime_gamma\": {\"shape\": 2.0, \"rate\": 0.01},\n      ...\n    },\n    ...\n  },\n  \"hazard_regimes\": [\n    {\"name\": \"tty_lost\", \"gamma\": {\"shape\": 2.0, \"rate\": 1.0}},\n    ...\n  ]\n}","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:20:57.391200514-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:20:57.391200514-05:00"}
{"id":"process_triage-2kz","title":"Define dormant mode daemon specification","description":"## Task\nSpecify the dormant mode daemon (ptd) that provides 24/7 monitoring with minimal overhead.\n\n## Background\nSection 3.7 specifies two operating modes:\n- Active mode: Full collection + inference + plan (on-demand)\n- Dormant mode (ptd): Lightweight monitoring with escalation\n\nDormant mode mechanics:\n- Collect minimal signals at low frequency\n- Use sketches/sparse localization for cheap monitoring\n- Detect triggers (sustained load, PSI stall, orphan spikes)\n- On trigger: quick scan → deep scan suspects → generate session → notify\n- Never become the hog (strict overhead budget)\n\n## Deliverables\n- Trigger specification (what conditions escalate)\n- Overhead budget (max CPU%, max memory)\n- Collection cadence and signals\n- Escalation protocol\n- Cooldown and backoff rules\n- Integration specifications:\n  - Linux: systemd user service + timer\n  - macOS: launchd agent\n- Inbox UX for pending plans\n- Coordination with manual/agent runs\n\n## Technical Considerations\n- Use EWMA + change detection for noise-robust triggers\n- Consider time-uniform concentration bounds for sequential testing\n- Must acquire pt lock before escalation\n- nice/ionice for resource limiting\n- Log triggers and escalations for debugging\n\n## Safety Constraints\n- Never take destructive actions from daemon\n- Default: plan ready for review\n- Optional: auto-apply non-destructive mitigations (pause/throttle) if configured","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:22:03.252468415-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:22:03.252468415-05:00"}
{"id":"process_triage-2l3","title":"EPIC: Phase 1 - Spec and Config Foundation","description":"## Overview\nThis epic covers all specification and configuration groundwork that must be completed before any implementation begins. This is the architectural foundation that everything else builds upon.\n\n## Background \u0026 Context\nThe current pt tool is a simple bash script with basic heuristics. The transformation plan requires defining comprehensive schemas, contracts, and specifications that will guide all subsequent implementation. Without this foundation, implementation will lack coherence and the alien artifact quality will be compromised.\n\n## Why This Matters\n- **Consistency**: All subsequent phases need stable contracts to build against\n- **Testability**: Schemas enable automated contract testing\n- **Agent Integration**: AI agents need predictable, stable interfaces\n- **Auditability**: Explicit specifications enable the galaxy-brain transparency goal\n- **Safety**: Policy and guardrail definitions prevent ad-hoc safety implementations\n\n## Scope\n1. Package architecture (pt bash wrapper vs pt-core Rust monolith)\n2. CLI surface design and stable output formats\n3. Golden path UX definition\n4. Session model and artifact directory layout\n5. All JSON schemas (priors.json, policy.json, telemetry, capabilities)\n6. Agent/robot contract definitions\n7. Target identity and privilege contracts\n8. Bundle/report specifications\n9. Dormant daemon specifications\n10. Galaxy-brain mode contract\n\n## Success Criteria\n- All schemas are defined in versioned JSON Schema files\n- CLI surface is documented with stable option names and exit codes\n- Contracts are testable (can write contract tests before implementation)\n- No ambiguity remains about output formats or behavior modes\n\n## Technical Considerations\n- Use JSON Schema for all configuration schemas\n- Schema versions must be explicit (semver)\n- Exit codes must be automation-friendly (0=clean, 1=candidates exist, etc.)\n- Consider backwards compatibility from the start","status":"open","priority":0,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:19:45.135316743-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:19:52.408002261-05:00"}
{"id":"process_triage-2ws","title":"Define bundle and report specifications","description":"## Task\nSpecify the .ptb bundle format and the premium HTML report generator.\n\n## Background\nSection 3.6 specifies shareable artifacts:\n- .ptb bundle: Single portable file containing session data\n- HTML report: Single static file, CDN-loaded libs, premium visual polish\n\nBundle format:\n- Container: ZIP (cross-platform) or tar.zst (power users)\n- Contents: manifest.json, plan.json, telemetry/, raw/ (optional), report.html\n- Export profiles: minimal, safe, forensic\n- Optional encryption for secure transport\n\nReport requirements:\n- Single file that works with file:// (no server needed)\n- CDN-loaded libraries with pinned versions and SRI\n- Visual polish: dashboard, sortable tables, drilldowns, timelines\n- Galaxy-brain tab for math transparency\n- Optional DuckDB-WASM for power queries\n\n## Deliverables\n- Bundle manifest schema (checksums, versions, redaction policy)\n- Directory structure within bundle\n- Export profile specifications\n- HTML report structure and features\n- CDN library stack (Tailwind, Tabulator, ECharts, Mermaid, KaTeX)\n- SRI hash requirements\n- --embed-assets offline mode specification\n\n## Technical Considerations\n- ZIP allows in-browser unpacking via JSZip\n- Plan + summaries embedded directly in HTML (not fetched)\n- Optional bundle attachment via file picker\n- Report should render in under 2 seconds\n- Mobile-responsive design","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:22:02.48264523-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:22:02.48264523-05:00"}
{"id":"process_triage-3ir","title":"EPIC: Phase 3 - Evidence Collection System","description":"## Overview\nThis epic covers all data collection infrastructure: from basic ps output to deep /proc inspection to maximal instrumentation with eBPF/perf.\n\n## Background \u0026 Context\nThe inference engine is only as good as its evidence. Section 3 and Phase 3/3a specify a layered collection system:\n1. Quick scan: ps + basic features (fast, low overhead)\n2. Deep scan: /proc inspection, schedstat, cgroup, fd, network (moderate overhead)\n3. Maximal: perf, eBPF, strace, syscall tracing (high fidelity but expensive)\n\nThe plan emphasizes 'always try to install everything and collect as much as possible' while respecting overhead budgets.\n\n## Why This Matters\n- **Classification Accuracy**: More signals = better posteriors\n- **Explainability**: Rich evidence enables detailed 'why' explanations\n- **Graceful Degradation**: Must work with minimal tools, excel with maximal\n- **Safety**: Collection itself must never destabilize the system\n\n## Scope\n1. Quick scan implementation (ps parsing)\n2. Deep scan (/proc, cgroup, network, fd)\n3. Tool runner with timeouts and caps\n4. Progress event emission\n5. Maximal tool installation (per-distro packages)\n6. Capability detection and caching\n7. Platform-specific collection (Linux vs macOS)\n\n## Success Criteria\n- Quick scan completes in \u003c1s for typical systems\n- Deep scan completes within overhead budget\n- Collection never hangs or destabilizes system\n- Missing tools are detected and gracefully degraded\n- Collected data feeds inference correctly\n\n## Technical Considerations\n- Tool availability varies by platform/permissions\n- Some tools require root/sudo\n- Container environments have limited /proc visibility\n- macOS has different tools (fs_usage, sample vs perf, strace)","status":"open","priority":0,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:24:32.68087147-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:24:32.68087147-05:00"}
{"id":"process_triage-3mi","title":"Define pt-core CLI surface and stable output formats","description":"## Task\nSpecify the complete CLI surface for pt-core including:\n- All subcommands (scan, deep-scan, infer, decide, ui, agent, duck, bundle, report, daemon)\n- All flags and options per subcommand\n- Output formats (JSON, Markdown, JSONL, Parquet)\n- Exit codes with semantic meaning\n\n## Background\nThe plan specifies automation-friendly exit codes:\n- 0 = clean / nothing to do\n- 1 = candidates exist (plan produced) but no actions executed\n- 2 = actions executed successfully\n- 3 = partial failure executing actions\n- 4 = blocked by safety gates / policy\n- 5 = goal not achievable\n- 6 = session interrupted / resumable\n- \u003e=10 = tooling/internal error\n\nAnd output formats with token-efficiency:\n- --format json (default, token-efficient)\n- --format md (human-readable)\n- --format jsonl (streaming)\n- --format summary (one-line)\n- --format metrics (key=value)\n- --format slack (narrative)\n- --format exitcode (minimal)\n\n## Deliverables\n- CLI specification document with all commands/options\n- Exit code table with semantic meanings\n- Output format specifications with examples\n- Schema version strategy (additive changes preferred)\n\n## Technical Considerations\n- JSON output must include schema_version, session_id, generated_at, host_id, summary\n- JSONL is for streaming progress events\n- Token-efficiency: defaults return just enough; deeper details via flags\n- Consider --compact, --fields, --limit for output control","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:20:22.816889835-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:20:22.816889835-05:00"}
{"id":"process_triage-3nz","title":"Implement policy.json enforcement engine","description":"## Overview\nBuild the central policy enforcement engine that validates all actions against policy.json rules.\n\n## Background\nPolicy.json defines immutable constraints: protected patterns, rate limits, loss thresholds, and special rules like require_human_for_supervised. The enforcement engine sits between the decision engine and action execution, blocking any action that violates policy.\n\n## Why It Matters\nDefense in depth. Even if inference goes wrong or there's a bug, policy enforcement provides a hard stop. This is especially critical for protected patterns (never kill sshd) and supervised process protection.\n\n## Technical Approach\n1. Parse policy.json at startup, validate schema\n2. Create PolicyEnforcer struct with check methods\n3. Intercept all action requests before execution\n4. Return detailed violation reports when blocked\n5. Support policy hot-reload for long-running daemon mode\n\n## Enforcement Checkpoints\n- Pre-scan: Verify scan scope is allowed\n- Pre-recommend: Check protected patterns\n- Pre-action: Rate limits, loss thresholds, supervisor rules\n- Post-action: Audit log entry\n\n## Policy Rule Types\n- **Hard blocks**: Protected patterns (regex), max loss threshold\n- **Rate limits**: Per-minute, per-hour, per-session\n- **Conditional**: require_human_for_supervised, require_confirm_for_high_loss\n- **Informational**: Log level, telemetry settings\n\n## Success Criteria\n- All policy rules enforced consistently\n- Clear violation messages with rule reference\n- Policy changes applied without restart (daemon mode)\n- No action can bypass enforcement layer","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:32:58.459019139-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:33:47.32099174-05:00"}
{"id":"process_triage-3ot","title":"Implement Beta-Binomial posterior predictive","description":"## Task\nImplement the Beta-Binomial posterior predictive distribution for CPU occupancy modeling.\n\n## Background\nSection 4.2 specifies CPU occupancy modeling:\n- p_u,C ~ Beta(alpha_C, beta_C) - prior on CPU busy probability\n- k_ticks | p, C ~ Binomial(n_ticks, p) - observed busy ticks\n- Posterior: Beta(alpha + k, beta + n - k)\n- Posterior predictive: Beta-Binomial\n\nThe Beta-Binomial PMF is:\nP(k | n, alpha, beta) = C(n,k) * B(k+alpha, n-k+beta) / B(alpha, beta)\n\nwhere B is the Beta function.\n\n## Implementation Notes\n- Use log-domain: log_beta_binom_pmf\n- log C(n,k) = lgamma(n+1) - lgamma(k+1) - lgamma(n-k+1)\n- log B(a,b) = lgamma(a) + lgamma(b) - lgamma(a+b)\n- Handle n_eff (effective tick count) for correlated samples\n\n## Functions Needed\n- beta_binom_pmf(k, n, alpha, beta)\n- log_beta_binom_pmf(k, n, alpha, beta)\n- beta_binom_cdf(k, n, alpha, beta)\n- beta_binom_mean(n, alpha, beta) = n * alpha / (alpha + beta)\n- beta_binom_var(n, alpha, beta) = formula involves n, alpha, beta\n\n## Test Cases\n- Matches Beta-Binomial tables\n- Degenerates to Binomial as alpha, beta → large\n- Mean equals n * prior_mean\n\n## Deliverables\n- Rust module extension: math/beta_binomial.rs\n- Unit tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:23:04.313918073-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:23:04.313918073-05:00"}
{"id":"process_triage-3q6","title":"Implement shadow mode background daemon","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:34:47.592840567-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:34:47.592840567-05:00"}
{"id":"process_triage-3v6","title":"Add bash syntax validation before replacement","description":"## Purpose\nValidate that downloaded scripts are valid bash before replacing the running script, preventing bricking.\n\n## Parent Epic\nSelf-Update Mechanism (process_triage-097)\n\n## Depends On\n- Add checksum verification for updates\n\n## Why This Matters\nIf a corrupted or truncated file is installed:\n1. User runs `pt` → syntax error → script doesn't work\n2. User can't use `pt update` to fix it (script is broken)\n3. Manual intervention required\n\n## Implementation\n\n### Syntax Validation Function\n```bash\nvalidate_bash_syntax() {\n    local file=\"$1\"\n    \n    # bash -n parses but doesn't execute\n    # Returns 0 if valid, non-zero if syntax errors\n    if \\! bash -n \"$file\" 2\u003e/dev/null; then\n        log_error \"Downloaded file is not valid bash\"\n        \n        # Show the actual error for debugging\n        log_debug \"Syntax check output:\"\n        bash -n \"$file\" 2\u003e\u00261 | while read -r line; do\n            log_debug \"  $line\"\n        done\n        \n        return 1\n    fi\n    \n    log_debug \"Bash syntax validation passed\"\n    return 0\n}\n```\n\n### Additional Sanity Checks\n```bash\nvalidate_script() {\n    local file=\"$1\"\n    \n    # 1. Check it's not empty\n    if [[ \\! -s \"$file\" ]]; then\n        log_error \"Downloaded file is empty\"\n        return 1\n    fi\n    \n    # 2. Check it starts with shebang\n    local first_line\n    first_line=$(head -n1 \"$file\")\n    if [[ \"$first_line\" \\!= \"#\\!/\"* ]]; then\n        log_error \"Downloaded file doesn't start with shebang\"\n        return 1\n    fi\n    \n    # 3. Check bash syntax\n    if \\! validate_bash_syntax \"$file\"; then\n        return 1\n    fi\n    \n    # 4. Check it contains expected content (anti-tampering)\n    if \\! grep -q 'VERSION=' \"$file\"; then\n        log_error \"Downloaded file missing VERSION constant\"\n        return 1\n    fi\n    \n    if \\! grep -q 'Process Triage' \"$file\"; then\n        log_error \"Downloaded file missing expected identifier\"\n        return 1\n    fi\n    \n    log_success \"Script validation passed\"\n    return 0\n}\n```\n\n### Integration with Update Flow\n```bash\ndo_update() {\n    local version=\"$1\"\n    local temp_file=\"...\"\n    \n    # ... download ...\n    \n    # Verify checksum\n    verify_checksum \"$temp_file\" \"$version\" || return 1\n    \n    # Validate script\n    validate_script \"$temp_file\" || {\n        log_error \"Script validation failed, aborting update\"\n        return 1\n    }\n    \n    # Now safe to replace\n    # ...\n}\n```\n\n## What bash -n Catches\n- Syntax errors (unclosed quotes, brackets)\n- Parse errors (invalid commands in wrong places)\n- Heredoc issues (unterminated heredocs)\n\n## What bash -n Doesn't Catch\n- Runtime errors (undefined variables with set -u)\n- Logic errors\n- Missing dependencies\n\nThat's why we also check for expected content markers.\n\n## Success Criteria\n- [ ] Syntax validation with bash -n\n- [ ] Empty file detection\n- [ ] Shebang verification\n- [ ] Expected content markers checked\n- [ ] Clear error messages on failure\n- [ ] Debug output shows actual syntax errors","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:35:05.792231414-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:35:05.792231414-05:00","dependencies":[{"issue_id":"process_triage-3v6","depends_on_id":"process_triage-nk1","type":"blocks","created_at":"2026-01-14T22:52:20.687792331-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-45o","title":"Add pattern normalization tests","description":"## Purpose\nAdd comprehensive tests for the pattern normalization algorithm that creates stable process fingerprints.\n\n## Parent Epic\nExpanded Test Coverage (process_triage-bgd)\n\n## Why Pattern Normalization Matters\nThe decision memory system relies on normalized patterns to match similar processes across sessions:\n- `bun test --port 3000` and `bun test --port 4000` should match\n- `node /tmp/abc123/server.js` and `node /tmp/xyz789/server.js` should match\n- PIDs, UUIDs, ports should be generalized\n\n## Implementation\n\n### test/test_patterns.bats\n```bash\n#!/usr/bin/env bats\n\nsetup() {\n    export TEST_MODE=1\n    source \"${BATS_TEST_DIRNAME}/../pt\" 2\u003e/dev/null || true\n}\n\n#------------------------------------------------------------------------------\n# PID removal tests\n#------------------------------------------------------------------------------\n\n@test \"normalize_pattern: removes 5+ digit PIDs\" {\n    local result\n    result=$(normalize_pattern \"node 12345 server.js\")\n    \n    [[ \"$result\" != *\"12345\"* ]]\n}\n\n@test \"normalize_pattern: removes 6 digit PIDs\" {\n    local result\n    result=$(normalize_pattern \"process 123456 running\")\n    \n    [[ \"$result\" != *\"123456\"* ]]\n}\n\n@test \"normalize_pattern: keeps 4 digit numbers\" {\n    # 4-digit numbers might be ports, keep them (handled separately)\n    local result\n    result=$(normalize_pattern \"server on port 3000\")\n    \n    # Port normalization handles this, but raw 4-digit stays\n    [[ \"$result\" == *\"3000\"* ]] || [[ \"$result\" == *\"PORT\"* ]]\n}\n\n#------------------------------------------------------------------------------\n# Port normalization tests\n#------------------------------------------------------------------------------\n\n@test \"normalize_pattern: --port=3000 becomes --port=PORT\" {\n    local result\n    result=$(normalize_pattern \"next dev --port=3000\")\n    \n    [[ \"$result\" == *\"--port=PORT\"* ]]\n}\n\n@test \"normalize_pattern: --port 8080 becomes --port PORT\" {\n    local result\n    result=$(normalize_pattern \"server --port 8080\")\n    \n    [[ \"$result\" == *\"--port\"* ]] \u0026\u0026 [[ \"$result\" == *\"PORT\"* ]]\n}\n\n@test \"normalize_pattern: :8080 in URL becomes :PORT\" {\n    local result\n    result=$(normalize_pattern \"http://localhost:8080/api\")\n    \n    [[ \"$result\" == *\":PORT\"* ]]\n}\n\n@test \"normalize_pattern: :3000 becomes :PORT\" {\n    local result\n    result=$(normalize_pattern \"listening on :3000\")\n    \n    [[ \"$result\" == *\":PORT\"* ]]\n}\n\n#------------------------------------------------------------------------------\n# UUID normalization tests\n#------------------------------------------------------------------------------\n\n@test \"normalize_pattern: standard UUID becomes UUID\" {\n    local result\n    result=$(normalize_pattern \"process-550e8400-e29b-41d4-a716-446655440000-worker\")\n    \n    [[ \"$result\" == *\"UUID\"* ]]\n    [[ \"$result\" != *\"550e8400\"* ]]\n}\n\n@test \"normalize_pattern: multiple UUIDs normalized\" {\n    local result\n    result=$(normalize_pattern \"a1b2c3d4-e5f6-7890-abcd-ef1234567890 to 11111111-2222-3333-4444-555555555555\")\n    \n    # Should have UUID placeholder(s)\n    [[ \"$result\" == *\"UUID\"* ]]\n    [[ \"$result\" != *\"a1b2c3d4\"* ]]\n}\n\n#------------------------------------------------------------------------------\n# Temp path normalization tests\n#------------------------------------------------------------------------------\n\n@test \"normalize_pattern: /tmp/abc123 becomes /tmp/TMP\" {\n    local result\n    result=$(normalize_pattern \"node /tmp/abc123xyz/server.js\")\n    \n    [[ \"$result\" == *\"/tmp/TMP\"* ]]\n}\n\n@test \"normalize_pattern: complex temp paths normalized\" {\n    local result\n    result=$(normalize_pattern \"/tmp/pytest-of-user/pytest-123/test0\")\n    \n    [[ \"$result\" == *\"/tmp/TMP\"* ]]\n}\n\n#------------------------------------------------------------------------------\n# Whitespace normalization tests\n#------------------------------------------------------------------------------\n\n@test \"normalize_pattern: collapses multiple spaces\" {\n    local result\n    result=$(normalize_pattern \"command    with   many    spaces\")\n    \n    # Should not have multiple consecutive spaces\n    [[ \"$result\" != *\"  \"* ]]\n}\n\n@test \"normalize_pattern: trims leading/trailing whitespace\" {\n    local result\n    result=$(normalize_pattern \"  padded command  \")\n    \n    # Should not start or end with space\n    [[ \"$result\" != \" \"* ]]\n    [[ \"$result\" != *\" \" ]]\n}\n\n#------------------------------------------------------------------------------\n# Truncation tests\n#------------------------------------------------------------------------------\n\n@test \"normalize_pattern: long commands truncated to 150 chars\" {\n    local long_cmd=\"$(printf 'a%.0s' {1..200})\"\n    local result\n    result=$(normalize_pattern \"$long_cmd\")\n    \n    (( ${#result} \u003c= 150 ))\n}\n\n#------------------------------------------------------------------------------\n# Combined normalization tests\n#------------------------------------------------------------------------------\n\n@test \"normalize_pattern: complex command fully normalized\" {\n    local cmd=\"bun test --port=3000 /tmp/test123/spec 12345678 550e8400-e29b-41d4-a716-446655440000\"\n    local result\n    result=$(normalize_pattern \"$cmd\")\n    \n    # Port normalized\n    [[ \"$result\" == *\"--port=PORT\"* ]] || [[ \"$result\" == *\"--port PORT\"* ]]\n    # Temp path normalized\n    [[ \"$result\" == *\"/tmp/TMP\"* ]]\n    # PID removed\n    [[ \"$result\" != *\"12345678\"* ]]\n    # UUID normalized\n    [[ \"$result\" == *\"UUID\"* ]]\n}\n\n@test \"normalize_pattern: identical processes with different PIDs match\" {\n    local pattern1 pattern2\n    pattern1=$(normalize_pattern \"bun test --watch pid:12345\")\n    pattern2=$(normalize_pattern \"bun test --watch pid:67890\")\n    \n    [[ \"$pattern1\" == \"$pattern2\" ]]\n}\n\n@test \"normalize_pattern: identical processes with different ports match\" {\n    local pattern1 pattern2\n    pattern1=$(normalize_pattern \"next dev --port=3000\")\n    pattern2=$(normalize_pattern \"next dev --port=8080\")\n    \n    [[ \"$pattern1\" == \"$pattern2\" ]]\n}\n```\n\n## Success Criteria\n- [ ] PID removal tested\n- [ ] Port normalization tested (both formats)\n- [ ] UUID normalization tested\n- [ ] Temp path normalization tested\n- [ ] Whitespace handling tested\n- [ ] Truncation tested\n- [ ] Combined normalizations tested\n- [ ] Equivalence of similar processes verified","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:39:24.017811611-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:39:24.017811611-05:00","dependencies":[{"issue_id":"process_triage-45o","depends_on_id":"process_triage-h2y","type":"blocks","created_at":"2026-01-14T22:40:49.269246813-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-4l7","title":"Add E2E tests for self-update mechanism","description":"## Purpose\nCreate comprehensive end-to-end tests for the self-update mechanism to verify version checking, downloading, verification, and installation work correctly.\n\n## Parent Epic\nExpanded Test Coverage (process_triage-bgd)\n\n## Depends On\n- Test helper with mock injection (process_triage-h2y)\n- Add 'pt update' command to CLI (process_triage-a50) - tests should be ready when feature lands\n\n## Why This Is Critical\nThe self-update mechanism:\n- Modifies the running script\n- Downloads from the internet\n- Executes checksums\n- Has security implications\n\nIf it fails, users could be left with a broken tool. Comprehensive testing prevents this.\n\n## Test Scenarios\n\n### test/test_e2e_update.bats\n\n```bash\n#!/usr/bin/env bats\n\nload 'test_helper/common'\n\nsetup() {\n    setup_test_env\n    test_start \"$BATS_TEST_NAME\" \"Self-update E2E test\"\n    \n    # Create a copy of pt for testing (don't modify real script)\n    export PT_TEST_SCRIPT=\"${TEST_DIR}/pt_test_copy\"\n    cp \"${BATS_TEST_DIRNAME}/../pt\" \"$PT_TEST_SCRIPT\"\n    chmod +x \"$PT_TEST_SCRIPT\"\n}\n\nteardown() {\n    test_end \"$BATS_TEST_NAME\" \"${BATS_TEST_COMPLETED:-fail}\"\n    restore_path\n    teardown_test_env\n}\n\n#==============================================================================\n# VERSION CHECKING TESTS\n#==============================================================================\n\n@test \"E2E Update: --check detects newer version available\" {\n    test_info \"Setting up: mock curl to return newer version URL\"\n    \n    # Current version in script (extract it)\n    local current_version\n    current_version=$(grep '^VERSION=' \"$PT_TEST_SCRIPT\" | cut -d'\"' -f2)\n    test_info \"Current version: $current_version\"\n    \n    # Mock curl to simulate redirect to newer version\n    create_mock_curl_redirect \"https://github.com/user/repo/releases/tag/v99.0.0\"\n    use_mock_bin\n    \n    test_info \"Running: pt update --check\"\n    run \"$PT_TEST_SCRIPT\" update --check\n    \n    test_info \"Exit code: $status, Output: $output\"\n    \n    # Should indicate update available\n    assert_contains \"$output\" \"available\\|99.0.0\" \"Should show newer version\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E Update: --check shows already up to date\" {\n    test_info \"Setting up: mock curl to return current version URL\"\n    \n    local current_version\n    current_version=$(grep '^VERSION=' \"$PT_TEST_SCRIPT\" | cut -d'\"' -f2)\n    test_info \"Current version: $current_version\"\n    \n    # Mock curl to return current version\n    create_mock_curl_redirect \"https://github.com/user/repo/releases/tag/v${current_version}\"\n    use_mock_bin\n    \n    test_info \"Running: pt update --check\"\n    run \"$PT_TEST_SCRIPT\" update --check\n    \n    test_info \"Exit code: $status, Output: $output\"\n    \n    # Should indicate up to date\n    assert_contains \"$output\" \"latest\\|up to date\\|$current_version\" \"Should show current\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E Update: handles network failure gracefully\" {\n    test_info \"Setting up: mock curl to fail\"\n    \n    create_mock_command \"curl\" \"\" 1  # Exit with error\n    use_mock_bin\n    \n    test_info \"Running: pt update --check\"\n    run \"$PT_TEST_SCRIPT\" update --check\n    \n    test_info \"Exit code: $status, Output: $output\"\n    \n    # Should fail gracefully with helpful message\n    # Don't crash, show network error\n    assert_contains \"$output\" \"error\\|failed\\|network\\|connection\" \"Should indicate network issue\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# CHECKSUM VERIFICATION TESTS\n#==============================================================================\n\n@test \"E2E Update: verifies checksum before installation\" {\n    test_info \"Setting up: mock download with correct checksum\"\n    \n    # Create a mock new version script\n    local mock_new_script=\"${TEST_DIR}/mock_new_pt\"\n    cat \u003e \"$mock_new_script\" \u003c\u003c 'EOF'\n#!/usr/bin/env bash\nVERSION=\"99.0.0\"\necho \"Mock new version\"\nEOF\n    \n    # Calculate its checksum\n    local checksum\n    if command -v sha256sum \u0026\u003e/dev/null; then\n        checksum=$(sha256sum \"$mock_new_script\" | cut -d' ' -f1)\n    else\n        checksum=$(shasum -a 256 \"$mock_new_script\" | cut -d' ' -f1)\n    fi\n    test_info \"Mock script checksum: $checksum\"\n    \n    # Mock curl to return appropriate responses\n    cat \u003e \"${MOCK_BIN}/curl\" \u003c\u003c EOF\n#!/usr/bin/env bash\nif [[ \"\\$*\" == *\"url_effective\"* ]]; then\n    echo \"https://github.com/user/repo/releases/tag/v99.0.0\"\nelif [[ \"\\$*\" == *\".sha256\"* ]]; then\n    echo \"$checksum  pt\"\nelif [[ \"\\$*\" == *\"/pt\"* ]]; then\n    cat \"$mock_new_script\"\nfi\nexit 0\nEOF\n    chmod +x \"${MOCK_BIN}/curl\"\n    use_mock_bin\n    \n    test_info \"Checksum verification test setup complete\"\n    \n    # The actual update would need more mocking...\n    # This tests the infrastructure is in place\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E Update: rejects mismatched checksum\" {\n    test_info \"Setting up: mock download with WRONG checksum\"\n    \n    # Create a mock script\n    local mock_new_script=\"${TEST_DIR}/mock_bad_pt\"\n    echo '#!/bin/bash' \u003e \"$mock_new_script\"\n    echo 'VERSION=\"99.0.0\"' \u003e\u003e \"$mock_new_script\"\n    \n    # Provide WRONG checksum\n    local wrong_checksum=\"0000000000000000000000000000000000000000000000000000000000000000\"\n    \n    cat \u003e \"${MOCK_BIN}/curl\" \u003c\u003c EOF\n#!/usr/bin/env bash\nif [[ \"\\$*\" == *\"url_effective\"* ]]; then\n    echo \"https://github.com/user/repo/releases/tag/v99.0.0\"\nelif [[ \"\\$*\" == *\".sha256\"* ]]; then\n    echo \"$wrong_checksum  pt\"\nelif [[ \"\\$*\" == *\"/pt\"* ]]; then\n    cat \"$mock_new_script\"\nfi\nexit 0\nEOF\n    chmod +x \"${MOCK_BIN}/curl\"\n    use_mock_bin\n    \n    test_info \"Running update with wrong checksum (should fail)\"\n    \n    # This should be rejected\n    # Actual test depends on implementation\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# SYNTAX VALIDATION TESTS\n#==============================================================================\n\n@test \"E2E Update: rejects invalid bash syntax\" {\n    test_info \"Setting up: mock download with syntax error\"\n    \n    # Create a script with syntax error\n    local bad_script=\"${TEST_DIR}/bad_syntax.sh\"\n    cat \u003e \"$bad_script\" \u003c\u003c 'EOF'\n#!/usr/bin/env bash\nVERSION=\"99.0.0\"\nif [[ true ]]; then\n    echo \"missing fi\"\n# Note: missing 'fi' - syntax error\nEOF\n    \n    test_info \"Verifying bash -n detects syntax error\"\n    run bash -n \"$bad_script\"\n    [[ $status -ne 0 ]]\n    test_info \"bash -n correctly rejected bad syntax\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E Update: accepts valid bash syntax\" {\n    test_info \"Setting up: mock download with valid syntax\"\n    \n    local good_script=\"${TEST_DIR}/good_syntax.sh\"\n    cat \u003e \"$good_script\" \u003c\u003c 'EOF'\n#!/usr/bin/env bash\nVERSION=\"99.0.0\"\nif [[ true ]]; then\n    echo \"valid syntax\"\nfi\nEOF\n    \n    test_info \"Verifying bash -n accepts good syntax\"\n    run bash -n \"$good_script\"\n    assert_equals \"0\" \"$status\" \"Should accept valid syntax\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# ATOMIC REPLACEMENT TESTS\n#==============================================================================\n\n@test \"E2E Update: atomic replacement preserves original on failure\" {\n    test_info \"This test verifies atomic replacement behavior\"\n    \n    # Create original script\n    local original=\"${TEST_DIR}/original_script\"\n    echo '#!/bin/bash' \u003e \"$original\"\n    echo 'VERSION=\"1.0.0\"' \u003e\u003e \"$original\"\n    chmod +x \"$original\"\n    \n    # Store original content hash\n    local original_hash\n    original_hash=$(sha256sum \"$original\" 2\u003e/dev/null | cut -d' ' -f1 || shasum -a 256 \"$original\" | cut -d' ' -f1)\n    test_info \"Original hash: $original_hash\"\n    \n    # If replacement fails, original should be unchanged\n    # This is more of an integration test with the atomic_replace function\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E Update: atomic replacement sets correct permissions\" {\n    test_info \"Verifying permissions preservation\"\n    \n    local test_script=\"${TEST_DIR}/perm_test\"\n    echo '#!/bin/bash' \u003e \"$test_script\"\n    chmod 755 \"$test_script\"\n    \n    local original_perms\n    original_perms=$(stat -c '%a' \"$test_script\" 2\u003e/dev/null || stat -f '%Lp' \"$test_script\")\n    test_info \"Original permissions: $original_perms\"\n    \n    assert_equals \"755\" \"$original_perms\" \"Permissions should be 755\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# PERMISSION HANDLING TESTS\n#==============================================================================\n\n@test \"E2E Update: detects unwritable installation directory\" {\n    skip_if_root  # Root can write anywhere\n    \n    test_info \"Setting up: read-only directory\"\n    \n    local readonly_dir=\"${TEST_DIR}/readonly\"\n    mkdir -p \"$readonly_dir\"\n    \n    local test_script=\"${readonly_dir}/pt\"\n    echo '#!/bin/bash' \u003e \"$test_script\"\n    chmod +x \"$test_script\"\n    \n    # Make directory read-only\n    chmod 555 \"$readonly_dir\"\n    \n    test_info \"Verifying directory is not writable\"\n    [[ ! -w \"$readonly_dir\" ]]\n    \n    # Restore permissions for cleanup\n    chmod 755 \"$readonly_dir\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# INTEGRATION TESTS\n#==============================================================================\n\n@test \"E2E Update: full update flow with mocks\" {\n    test_info \"Full update flow integration test\"\n    \n    # This is the big integration test that simulates the entire flow:\n    # 1. Check for updates\n    # 2. Download new version\n    # 3. Verify checksum\n    # 4. Validate syntax\n    # 5. Atomic replacement\n    \n    # For safety, we don't actually replace anything\n    # Instead we verify each step would work\n    \n    test_info \"Step 1: Version check\"\n    # ... mock version check ...\n    \n    test_info \"Step 2: Download simulation\"\n    # ... verify download would succeed ...\n    \n    test_info \"Step 3: Checksum verification\"\n    # ... verify checksum logic ...\n    \n    test_info \"Step 4: Syntax validation\"\n    # ... verify syntax check ...\n    \n    test_info \"Step 5: Atomic replacement preparation\"\n    # ... verify replacement would be atomic ...\n    \n    BATS_TEST_COMPLETED=pass\n}\n```\n\n## Success Criteria\n- [ ] Version checking tested (newer, current, failure)\n- [ ] Checksum verification tested (match, mismatch, missing)\n- [ ] Syntax validation tested (valid, invalid)\n- [ ] Atomic replacement tested (success, failure preservation)\n- [ ] Permission handling tested\n- [ ] Network failure handling tested\n- [ ] All tests have detailed logging\n- [ ] No actual script replacement in tests (safety)","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:47:26.873195395-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:47:26.873195395-05:00","dependencies":[{"issue_id":"process_triage-4l7","depends_on_id":"process_triage-h2y","type":"blocks","created_at":"2026-01-14T22:50:29.765439879-05:00","created_by":"Dicklesworthstone"},{"issue_id":"process_triage-4l7","depends_on_id":"process_triage-a50","type":"blocks","created_at":"2026-01-14T22:50:29.810950859-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-4ps","title":"Add checksum verification for updates","description":"## Purpose\nVerify downloaded updates using SHA256 checksums before installation, ensuring security and integrity.\n\n## Parent Epic\nSelf-Update Mechanism (process_triage-097)\n\n## Depends On\n- Implement HTTP redirect-based version checking\n- Release automation must generate checksums (process_triage-aip)\n\n## Security Model\n1. Checksums are generated in CI (trusted environment)\n2. Published as release artifacts on GitHub\n3. Downloaded and verified locally before installation\n4. Mismatch = abort update (potential tampering)\n\n## Implementation\n\n### Checksum Download and Verification\n```bash\n#------------------------------------------------------------------------------\n# Checksum verification\n#------------------------------------------------------------------------------\n\nverify_checksum() {\n    local file=\"$1\"\n    local version=\"$2\"\n    local expected actual\n    \n    # Download expected checksum from release\n    local checksum_url=\"${RELEASES_URL}/download/v${version}/pt.sha256\"\n    \n    expected=$(curl -fsSL --connect-timeout 5 --max-time 10 \"$checksum_url\" 2\u003e/dev/null)\n    \n    if [[ -z \"$expected\" ]]; then\n        log_warn \"Could not download checksum file\"\n        log_warn \"Update will proceed WITHOUT verification\"\n        \n        # In non-interactive mode, refuse to continue\n        if [[ \"$IS_TTY\" \\!= \"true\" ]]; then\n            log_error \"Checksum verification required in non-interactive mode\"\n            return 1\n        fi\n        \n        # Ask user to confirm\n        if \\! gum_confirm \"Continue without checksum verification?\"; then\n            return 1\n        fi\n        return 0\n    fi\n    \n    # Extract just the hash (file format: \"hash  filename\")\n    expected=\"${expected%% *}\"\n    \n    # Compute actual checksum (cross-platform)\n    if command -v sha256sum \u0026\u003e/dev/null; then\n        actual=$(sha256sum \"$file\" | cut -d' ' -f1)\n    elif command -v shasum \u0026\u003e/dev/null; then\n        actual=$(shasum -a 256 \"$file\" | cut -d' ' -f1)\n    else\n        log_warn \"No SHA256 tool available, skipping verification\"\n        return 0\n    fi\n    \n    # Compare\n    if [[ \"$expected\" == \"$actual\" ]]; then\n        log_success \"Checksum verified: ${actual:0:16}...\"\n        return 0\n    else\n        log_error \"Checksum mismatch\\!\"\n        log_error \"  Expected: $expected\"\n        log_error \"  Actual:   $actual\"\n        log_error \"The downloaded file may be corrupted or tampered with.\"\n        return 1\n    fi\n}\n```\n\n### Integration with Update Flow\n```bash\ndo_update() {\n    local version=\"$1\"\n    local download_url=\"${RELEASES_URL}/download/v${version}/pt\"\n    local temp_file\n    \n    # Create temp file in same directory (for atomic move later)\n    temp_file=\"$(mktemp \"${SCRIPT_PATH}.XXXXXX\")\"\n    trap \"rm -f '$temp_file'\" EXIT\n    \n    # Download\n    log_step \"Downloading pt v${version}...\"\n    if \\! curl -fsSL --connect-timeout 10 --max-time 60 \"$download_url\" -o \"$temp_file\"; then\n        log_error \"Download failed\"\n        return 1\n    fi\n    \n    # Verify checksum\n    if \\! verify_checksum \"$temp_file\" \"$version\"; then\n        log_error \"Checksum verification failed, aborting update\"\n        return 1\n    fi\n    \n    # Continue with syntax validation and installation...\n}\n```\n\n## Cross-Platform SHA256 Tools\n| Platform | Tool |\n|----------|------|\n| Linux (most) | sha256sum |\n| macOS | shasum -a 256 |\n| BSD | sha256 |\n\nThe implementation tries sha256sum first (most common), then shasum (macOS).\n\n## Checksum File Format\nThe release will include:\n```\n# checksums.sha256 (combined)\nabc123...  pt\ndef456...  install.sh\n\n# pt.sha256 (individual - used by installer)\nabc123...  pt\n```\n\n## Success Criteria\n- [ ] Checksums downloaded from release artifacts\n- [ ] SHA256 verification works on Linux and macOS\n- [ ] Mismatch aborts update with clear message\n- [ ] Missing checksum prompts user (or fails in non-interactive)\n- [ ] Partial checksum displayed on success","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:35:02.949837945-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:35:02.949837945-05:00","dependencies":[{"issue_id":"process_triage-4ps","depends_on_id":"process_triage-nk1","type":"blocks","created_at":"2026-01-14T22:52:20.652411692-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-4r8","title":"Define telemetry schema and partitioning strategy","description":"## Task\nSpecify the complete telemetry schema using Parquet format and define the partitioning strategy for efficient storage and querying.\n\n## Background\nSection 3.3 specifies telemetry storage:\n- Storage: Parquet with per-machine partitioning\n- Partitioning: By day and host_id for fleet aggregation\n- Tables: runs, proc_samples, proc_features, proc_inference, outcomes\n\nRequired tables:\n1. **runs**: session metadata, config snapshot, schema version\n2. **proc_samples**: raw per-PID measurements at each sample time\n3. **proc_features**: derived features fed to inference\n4. **proc_inference**: posterior, evidence ledger, classification\n5. **outcomes**: action taken, result, user feedback\n\n## Deliverables\n- Parquet schema definitions for each table\n- Partitioning strategy (day + host_id)\n- Retention policy per table type\n- DuckDB views/macros for standard queries\n- Schema versioning strategy\n\n## Technical Considerations\n- Parquet enables efficient columnar queries via DuckDB\n- Batched writes during scan (not one file per process)\n- Failures should leave partial but valid Parquet files\n- Consider compression (zstd preferred)\n- Schema evolution must be backwards-compatible\n\n## Query Patterns to Support\n- Calibration curves (predicted vs actual)\n- FDR metrics over time\n- PAC-Bayes bound computation\n- Per-command-category statistics\n- Cross-session comparison","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:21:26.83404464-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:21:26.83404464-05:00"}
{"id":"process_triage-5aw","title":"Add installation test job to CI","description":"## Purpose\nAdd a CI job that tests the installer end-to-end on both Linux and macOS.\n\n## Parent Epic\nGitHub Actions CI/CD Pipeline (process_triage-68c)\n\n## Depends On\n- Create install.sh with self-refresh mechanism\n- Add BATS test job with matrix build\n\n## Why Installation Testing?\n- Verifies installer works on clean systems\n- Catches PATH issues, permission problems\n- Tests the actual user experience\n- Ensures --version and --help work post-install\n\n## Implementation\n\n### Add to ci.yml\n```yaml\n  install-test:\n    name: Installation Test (${{ matrix.os }})\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest, macos-latest]\n    \n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      \n      - name: Install Bash 5 (macOS)\n        if: runner.os == 'macOS'\n        run: |\n          brew install bash\n          echo \"/opt/homebrew/bin\" \u003e\u003e $GITHUB_PATH\n      \n      - name: Run installer\n        run: |\n          # Run installer from local file (not curl, since we're testing the branch)\n          bash install.sh\n        env:\n          PT_NO_PATH: '1'  # Don't modify shell config in CI\n      \n      - name: Verify installation\n        run: |\n          # Check executable exists\n          if [[ \\! -x \"$HOME/.local/bin/pt\" ]]; then\n            echo \"::error::pt not installed to expected location\"\n            ls -la \"$HOME/.local/bin/\" || true\n            exit 1\n          fi\n          \n          echo \"✓ pt installed successfully\"\n      \n      - name: Test --version\n        run: |\n          version=$(\"$HOME/.local/bin/pt\" --version)\n          echo \"Version output: $version\"\n          \n          if [[ \\! \"$version\" =~ ^pt\\ version\\ [0-9]+\\.[0-9]+\\.[0-9]+$ ]]; then\n            echo \"::error::Unexpected version output format\"\n            exit 1\n          fi\n          \n          echo \"✓ --version works correctly\"\n      \n      - name: Test --help\n        run: |\n          help_output=$(\"$HOME/.local/bin/pt\" --help)\n          \n          # Check for expected content\n          if [[ \"$help_output\" \\!= *\"Process Triage\"* ]]; then\n            echo \"::error::Help output missing expected content\"\n            exit 1\n          fi\n          \n          if [[ \"$help_output\" \\!= *\"scan\"* ]]; then\n            echo \"::error::Help output missing 'scan' command\"\n            exit 1\n          fi\n          \n          echo \"✓ --help works correctly\"\n      \n      - name: Test scan command\n        run: |\n          # scan should work (may find 0 candidates, that's OK)\n          \"$HOME/.local/bin/pt\" scan || {\n            echo \"::error::pt scan failed\"\n            exit 1\n          }\n          echo \"✓ scan command works\"\n        env:\n          CI: 'true'\n          NO_COLOR: '1'\n```\n\n## Environment Variables for CI\n- `PT_NO_PATH='1'`: Don't modify .bashrc/.zshrc in CI\n- `CI='true'`: pt should detect CI environment\n- `NO_COLOR='1'`: Disable colors for clean output\n\n## Success Criteria\n- [ ] Installer runs without error\n- [ ] pt installed to ~/.local/bin/\n- [ ] --version returns correct format\n- [ ] --help shows expected content\n- [ ] scan command executes without error\n- [ ] Works on both Linux and macOS","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:37:33.12590461-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:37:33.12590461-05:00","dependencies":[{"issue_id":"process_triage-5aw","depends_on_id":"process_triage-ume","type":"blocks","created_at":"2026-01-14T22:40:46.394310829-05:00","created_by":"Dicklesworthstone"},{"issue_id":"process_triage-5aw","depends_on_id":"process_triage-9ch","type":"blocks","created_at":"2026-01-14T22:40:46.441625327-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-5s5","title":"Implement Dirichlet-Multinomial posterior predictive","description":"## Task\nImplement the Dirichlet-Multinomial for categorical features.\n\n## Background\nCategorical features (command categories, state flags) use Dirichlet-Multinomial:\n- Prior: π ~ Dirichlet(α_1, ..., α_K)\n- Observation: x | π ~ Categorical(π)\n- Posterior: Dirichlet(α_1 + n_1, ..., α_K + n_K)\n- Posterior predictive: P(x=k) = (α_k + n_k) / (sum(α) + n)\n\n## Functions Needed\n- dirichlet_cat_pred(k, alpha_vec) = alpha[k] / sum(alpha)\n- log_dirichlet_cat_pred(k, alpha_vec)\n- dirichlet_update(alpha_vec, counts) → alpha_new\n- dirichlet_log_normalizer(alpha_vec) - for Bayes factors\n\n## Implementation Notes\n- log_normalizer = sum(lgamma(alpha)) - lgamma(sum(alpha))\n- Handle sparse count updates efficiently\n- K can be large (many command categories)\n\n## Test Cases\n- Uniform Dirichlet (1,1,...,1): equal probabilities\n- Concentrated Dirichlet: near-deterministic predictions\n- Update correctness\n\n## Deliverables\n- Rust functions in math/dirichlet.rs\n- Unit tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:23:31.986901565-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:23:31.986901565-05:00"}
{"id":"process_triage-5y9","title":"Implement Arrow/Parquet schema definitions and writer","description":"## Task\nImplement the Parquet telemetry infrastructure for persistent storage.\n\n## Background\nSection 3.3 specifies Parquet-first telemetry:\n- All telemetry stored in columnar Parquet format\n- Enables efficient queries via DuckDB\n- Batched writes during scan (not per-process files)\n- Schema versioning for evolution\n\nRequired schemas:\n1. **runs**: session_id, host_id, start_ts, end_ts, config_snapshot, schema_version\n2. **proc_samples**: session_id, sample_ts, pid, start_id, cpu_ticks, rss_mb, state, ...\n3. **proc_features**: session_id, pid, start_id, features (derived from samples)\n4. **proc_inference**: session_id, pid, start_id, posterior, classification, confidence, ledger\n5. **outcomes**: session_id, pid, start_id, action, result, user_feedback\n\n## Functions Needed\n- define_schema(table_name) → Arrow Schema\n- create_writer(path, schema) → BatchedWriter\n- writer.write_batch(records)\n- writer.close() → finalize file\n\n## Implementation Notes\n- Use arrow-rs and parquet crates\n- Batched writes (accumulate N records before flush)\n- Compression: zstd preferred\n- Partitioning: by day and host_id\n- Handle partial writes on crash (valid prefix)\n\n## Test Cases\n- Round-trip: write records, read back, verify equality\n- Schema evolution: old reader handles new columns\n- Crash recovery: partial file is readable\n\n## Deliverables\n- Rust module: storage/parquet.rs\n- Schema definitions: storage/schemas.rs\n- Unit and integration tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:24:31.979577565-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:24:31.979577565-05:00"}
{"id":"process_triage-68c","title":"GitHub Actions CI/CD Pipeline","description":"## Overview\nImplement a comprehensive CI/CD pipeline matching the quality standards of repo_updater and giil.\n\n## Current State\n- NO GitHub Actions workflows exist\n- No automated testing on push/PR\n- No ShellCheck linting\n- No cross-platform testing\n- No version consistency checks\n\n## Target State\nTwo workflow files:\n1. **ci.yml** - Runs on every push/PR\n2. **release.yml** - Runs on version tags\n\n## ci.yml Structure (from repo_updater pattern)\n\n### Job 1: ShellCheck (Static Analysis)\n```yaml\nshellcheck:\n  runs-on: ubuntu-latest\n  steps:\n    - uses: ludeeus/action-shellcheck@master\n      with:\n        severity: warning\n        scandir: '.'\n```\n\n### Job 2: Syntax Validation\n```yaml\nsyntax:\n  runs-on: ubuntu-latest\n  steps:\n    - run: bash -n pt\n    - run: bash -n install.sh\n```\n\n### Job 3: BATS Tests (Matrix Build)\n```yaml\ntests:\n  strategy:\n    matrix:\n      os: [ubuntu-latest, macos-latest]\n  steps:\n    - name: Install BATS\n      run: |\n        git clone https://github.com/bats-core/bats-core.git\n        cd bats-core \u0026\u0026 sudo ./install.sh /usr/local\n    - name: Run tests\n      run: bats test/\n```\n\n### Job 4: Installation Test\n```yaml\ninstall-test:\n  strategy:\n    matrix:\n      os: [ubuntu-latest, macos-latest]\n  steps:\n    - run: bash install.sh\n    - run: pt --version\n    - run: pt --help\n```\n\n### Job 5: Version Consistency\n```yaml\nversion-check:\n  steps:\n    - name: Verify VERSION matches script\n      run: |\n        file_version=$(cat VERSION)\n        script_version=$(grep '^VERSION=' pt | cut -d= -f2 | tr -d '\"')\n        [[ \"$file_version\" == \"$script_version\" ]] || exit 1\n```\n\n## Trigger Configuration\n```yaml\non:\n  push:\n    branches: [main, master]\n  pull_request:\n    branches: [main, master]\n  workflow_dispatch:  # Manual trigger\n```\n\n## Why This Structure?\n- **ShellCheck**: Catches common bash pitfalls before they reach users\n- **Syntax validation**: Ensures script is parseable (catches heredoc issues)\n- **Matrix testing**: Ensures cross-platform compatibility\n- **Version check**: Prevents release version mismatches (common source of bugs)\n- **Install test**: Validates the user experience works end-to-end\n\n## Success Criteria\n- [ ] All jobs pass on clean codebase\n- [ ] PRs are blocked if any job fails\n- [ ] Tests run on both Linux and macOS\n- [ ] Version mismatches are caught before release\n- [ ] ShellCheck warnings are addressed","status":"open","priority":1,"issue_type":"epic","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:32:43.023581917-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:32:43.023581917-05:00"}
{"id":"process_triage-6a1","title":"Implement DRO layer for distribution shift","description":"## Task\nImplement Distributionally Robust Optimization for conservative decisions under shift.\n\n## Background\nSection 4.42 specifies DRO:\n- Replace expected loss with worst-case over ambiguity set\n- Produces conservative 'don't kill unless safe' decisions\n- Activated when PPC/drift checks indicate problems\n\n## Ambiguity Set\n- Wasserstein ball around observed distribution\n- Radius determined by drift detection\n- Larger radius = more conservative\n\n## Implementation Notes\n- Use analytic dual bounds where available\n- Otherwise conservative approximations\n- Feeds gate decisions, not core posteriors\n- Log DRO adjustments in ledger\n\n## When to Apply DRO\n1. PPC fails (model misspecification)\n2. Wasserstein drift detected (section 4.24)\n3. Confidence below threshold\n4. Explicit --conservative flag\n\n## Output Structure\n{\n  \"dro_applied\": true,\n  \"reason\": \"wasserstein_drift_detected\",\n  \"ambiguity_radius\": 0.15,\n  \"original_decision\": \"kill\",\n  \"robust_decision\": \"review\",\n  \"worst_case_loss\": 45.2\n}\n\n## Deliverables\n- Rust module: inference/dro.rs\n- Ambiguity set computation\n- Worst-case loss bounds\n- Decision adjustment\n- Unit tests\n- Documentation","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:28:13.607108033-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:28:13.607108033-05:00"}
{"id":"process_triage-6jg","title":"Add decision memory tests","description":"## Purpose\nAdd tests for the decision memory system that learns from user choices.\n\n## Parent Epic\nExpanded Test Coverage (process_triage-bgd)\n\n## Key Functions to Test\n- `save_decision()`: Persist kill/spare decisions\n- `get_past_decision()`: Retrieve previous decision\n- `load_decisions_cache()`: Batch load for performance\n- `get_cached_decision()`: Fast lookup from cache\n\n## Implementation\n\n### test/test_memory.bats\n```bash\n#\\!/usr/bin/env bats\n\nsetup() {\n    # Create isolated config directory for each test\n    export CONFIG_DIR=\"${BATS_TEST_TMPDIR}/config\"\n    export DECISIONS_FILE=\"${CONFIG_DIR}/decisions.json\"\n    mkdir -p \"$CONFIG_DIR\"\n    echo '{}' \u003e \"$DECISIONS_FILE\"\n    \n    export TEST_MODE=1\n    source \"${BATS_TEST_DIRNAME}/../pt\" 2\u003e/dev/null || true\n}\n\nteardown() {\n    rm -rf \"${BATS_TEST_TMPDIR}/config\"\n}\n\n#------------------------------------------------------------------------------\n# save_decision tests\n#------------------------------------------------------------------------------\n\n@test \"save_decision: creates valid JSON\" {\n    skip_if_no_jq\n    \n    save_decision \"kill\" \"test pattern\"\n    \n    # Should be valid JSON\n    jq -e '.' \"$DECISIONS_FILE\" \u003e/dev/null\n}\n\n@test \"save_decision: stores kill decision\" {\n    skip_if_no_jq\n    \n    save_decision \"kill\" \"bun test\"\n    \n    local stored\n    stored=$(jq -r '.\"bun test\"' \"$DECISIONS_FILE\")\n    [[ \"$stored\" == \"kill\" ]]\n}\n\n@test \"save_decision: stores spare decision\" {\n    skip_if_no_jq\n    \n    save_decision \"spare\" \"gunicorn\"\n    \n    local stored\n    stored=$(jq -r '.gunicorn' \"$DECISIONS_FILE\")\n    [[ \"$stored\" == \"spare\" ]]\n}\n\n@test \"save_decision: overwrites previous decision\" {\n    skip_if_no_jq\n    \n    save_decision \"kill\" \"pattern1\"\n    save_decision \"spare\" \"pattern1\"\n    \n    local stored\n    stored=$(jq -r '.pattern1' \"$DECISIONS_FILE\")\n    [[ \"$stored\" == \"spare\" ]]\n}\n\n@test \"save_decision: handles patterns with special characters\" {\n    skip_if_no_jq\n    \n    save_decision \"kill\" \"path/to/file --flag=\\\"value\\\"\"\n    \n    # Should not corrupt JSON\n    jq -e '.' \"$DECISIONS_FILE\" \u003e/dev/null\n}\n\n@test \"save_decision: handles multiple patterns\" {\n    skip_if_no_jq\n    \n    save_decision \"kill\" \"pattern1\"\n    save_decision \"spare\" \"pattern2\"\n    save_decision \"kill\" \"pattern3\"\n    \n    local count\n    count=$(jq 'length' \"$DECISIONS_FILE\")\n    (( count == 3 ))\n}\n\n#------------------------------------------------------------------------------\n# get_past_decision tests\n#------------------------------------------------------------------------------\n\n@test \"get_past_decision: returns stored decision\" {\n    skip_if_no_jq\n    \n    echo '{\"bun test\": \"kill\"}' \u003e \"$DECISIONS_FILE\"\n    \n    local result\n    result=$(get_past_decision \"bun test\")\n    [[ \"$result\" == \"kill\" ]]\n}\n\n@test \"get_past_decision: returns unknown for missing pattern\" {\n    skip_if_no_jq\n    \n    echo '{}' \u003e \"$DECISIONS_FILE\"\n    \n    local result\n    result=$(get_past_decision \"nonexistent\")\n    [[ \"$result\" == \"unknown\" ]]\n}\n\n#------------------------------------------------------------------------------\n# Cache tests\n#------------------------------------------------------------------------------\n\n@test \"load_decisions_cache: loads all decisions\" {\n    skip_if_no_jq\n    \n    echo '{\"p1\": \"kill\", \"p2\": \"spare\", \"p3\": \"kill\"}' \u003e \"$DECISIONS_FILE\"\n    \n    load_decisions_cache\n    \n    [[ \"${DECISION_CACHE[p1]}\" == \"kill\" ]]\n    [[ \"${DECISION_CACHE[p2]}\" == \"spare\" ]]\n    [[ \"${DECISION_CACHE[p3]}\" == \"kill\" ]]\n}\n\n@test \"get_cached_decision: fast lookup\" {\n    skip_if_no_jq\n    \n    echo '{\"cached_pattern\": \"spare\"}' \u003e \"$DECISIONS_FILE\"\n    load_decisions_cache\n    \n    local result\n    result=$(get_cached_decision \"cached_pattern\")\n    [[ \"$result\" == \"spare\" ]]\n}\n\n@test \"get_cached_decision: returns unknown for missing\" {\n    skip_if_no_jq\n    \n    echo '{}' \u003e \"$DECISIONS_FILE\"\n    load_decisions_cache\n    \n    local result\n    result=$(get_cached_decision \"missing\")\n    [[ \"$result\" == \"unknown\" ]]\n}\n\n#------------------------------------------------------------------------------\n# Integration tests\n#------------------------------------------------------------------------------\n\n@test \"decision memory: affects scoring\" {\n    skip_if_no_jq\n    \n    # Save a kill decision\n    save_decision \"kill\" \"previous pattern\"\n    \n    # Score should be boosted for similar pattern\n    # This tests the integration with score_process\n}\n\n@test \"decision memory: survives script restart\" {\n    skip_if_no_jq\n    \n    save_decision \"kill\" \"persistent pattern\"\n    \n    # Clear cache (simulating restart)\n    unset DECISION_CACHE\n    declare -gA DECISION_CACHE\n    DECISION_CACHE_LOADED=false\n    \n    # Reload and verify\n    load_decisions_cache\n    [[ \"${DECISION_CACHE[persistent pattern]}\" == \"kill\" ]]\n}\n\n#------------------------------------------------------------------------------\n# Helper\n#------------------------------------------------------------------------------\n\nskip_if_no_jq() {\n    if \\! command -v jq \u0026\u003e/dev/null; then\n        skip \"jq not installed\"\n    fi\n}\n```\n\n## Success Criteria\n- [ ] save_decision creates valid JSON\n- [ ] Both kill and spare decisions stored\n- [ ] Decisions can be retrieved\n- [ ] Cache loading works\n- [ ] Fast lookup from cache works\n- [ ] Special characters handled safely\n- [ ] Unknown patterns return \"unknown\"","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:39:24.279254142-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:39:24.279254142-05:00","dependencies":[{"issue_id":"process_triage-6jg","depends_on_id":"process_triage-h2y","type":"blocks","created_at":"2026-01-14T22:40:49.312857184-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-6l1","title":"EPIC: Phase 10 - Supervisor Detection","description":"## Overview\nPhase 10 implements supervisor detection: identifying processes that are being actively managed by AI agents, IDEs, or automation systems.\n\n## Background\nThe plan specifies that supervised processes are NEVER auto-killed. Detecting supervision requires examining parent processes, environment variables, IPC channels, and file locks. Known supervisors include Claude, Codex, VS Code, tmux with agent shells, and various CI/CD runners.\n\n## Why It Matters\nKilling a supervised process could corrupt an ongoing AI workflow, lose unsaved work, or break a CI pipeline. This is a critical safety mechanism that distinguishes between 'abandoned by user' and 'managed by automation'.\n\n## Phase Scope\n1. Supervisor signature database\n2. Process ancestry analysis\n3. Environment variable inspection\n4. IPC and socket connection detection\n5. File lock and PID file analysis\n\n## Detection Methods\n- **Ancestry**: Parent or ancestor matches supervisor pattern\n- **Environment**: Variables like CLAUDE_SESSION_ID, VSCODE_PID, etc.\n- **Sockets**: Connected to known supervisor IPC paths\n- **Locks**: PID files in known automation directories\n- **Timing**: Recent activity correlated with supervisor events\n\n## Known Supervisor Patterns\n- AI agents: claude, codex, aider, cursor\n- IDEs: code, idea, eclipse, vim (with LSP)\n- Terminals: tmux, screen (when hosting agents)\n- CI/CD: jenkins, github-runner, gitlab-runner\n- Orchestrators: systemd user services, launchd agents\n\n## Output Format\nSupervisor detection produces a structured result:\n- is_supervised: bool\n- supervisor_type: string (agent|ide|ci|orchestrator|unknown)\n- supervisor_identity: string (specific supervisor name)\n- confidence: float (how certain we are)\n- evidence: list of matching signals\n\n## Success Criteria\n- All common supervisors detected reliably\n- Low false positive rate (non-supervised marked as supervised)\n- Fast detection (adds \u003c100ms to scan)\n- Extensible pattern database","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:33:57.935628704-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:34:36.235940816-05:00"}
{"id":"process_triage-6rf","title":"Define golden path UX flow","description":"## Task\nSpecify the default user experience flow that makes pt feel like 'one coherent run' rather than 'a pile of verbs'.\n\n## Background\nSection 7.0 of the plan emphasizes avoiding mode overload. The default pt behavior should be:\n1. Quick multi-sample scan (deltas, not single snapshot)\n2. Infer + generate plan (with safety gates + staged actions)\n3. Show 'Apply Plan' TUI (pre-toggled recommendations)\n4. Execute in stages (pause/throttle → verify → kill as last resort)\n5. Show 'After' diff + session summary + export/report affordances\n\nEverything else (expert verbs, flags) remains available but isn't required.\n\n## Deliverables\n- Step-by-step golden path flow document\n- State machine diagram showing transitions\n- Default behavior specification (what happens with no flags)\n- How expert mode is accessed without cluttering defaults\n\n## Technical Considerations\n- Every run gets a durable session_id and artifact directory\n- Scan-only runs still create sessions\n- Progress stages must be visible (scan → deep scan → infer → decide)\n- The flow must work for both TUI and agent CLI modes\n\n## Why This Matters\nThe 'alien artifact' quality depends on the tool feeling polished and intentional. A fragmented UX breaks the illusion and makes the tool feel like a collection of scripts rather than a coherent product.","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:20:23.677592485-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:20:23.677592485-05:00"}
{"id":"process_triage-6xm","title":"Add E2E tests for installer (install.sh)","description":"## Purpose\nCreate comprehensive end-to-end tests for install.sh to verify the installation process works correctly across different scenarios.\n\n## Parent Epic\nExpanded Test Coverage (process_triage-bgd)\n\n## Depends On\n- Test helper with mock injection (process_triage-h2y)\n- Create install.sh with self-refresh mechanism (process_triage-ume) - tests ready when feature lands\n\n## Test Scenarios\n\n### test/test_e2e_installer.bats\n\n```bash\n#!/usr/bin/env bats\n\nload 'test_helper/common'\n\nsetup() {\n    setup_test_env\n    test_start \"$BATS_TEST_NAME\" \"Installer E2E test\"\n    \n    export INSTALL_SCRIPT=\"${BATS_TEST_DIRNAME}/../install.sh\"\n    export INSTALL_DIR=\"${TEST_DIR}/install_target\"\n    mkdir -p \"$INSTALL_DIR\"\n}\n\nteardown() {\n    test_end \"$BATS_TEST_NAME\" \"${BATS_TEST_COMPLETED:-fail}\"\n    restore_path\n    teardown_test_env\n}\n\n#==============================================================================\n# BASIC INSTALLATION TESTS\n#==============================================================================\n\n@test \"Installer: script exists and is executable\" {\n    test_info \"Checking install.sh exists\"\n    \n    [[ -f \"$INSTALL_SCRIPT\" ]]\n    [[ -r \"$INSTALL_SCRIPT\" ]]\n    \n    test_info \"Verifying bash syntax\"\n    run bash -n \"$INSTALL_SCRIPT\"\n    assert_equals \"0\" \"$status\" \"install.sh should have valid syntax\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Installer: fresh install to custom directory\" {\n    test_info \"Setting up: custom DEST directory\"\n    \n    export DEST=\"$INSTALL_DIR\"\n    export PT_NO_PATH=1  # Don't modify shell config\n    \n    # Mock curl to return a valid pt script\n    local mock_pt=\"${TEST_DIR}/mock_pt\"\n    cat \u003e \"$mock_pt\" \u003c\u003c 'EOF'\n#!/usr/bin/env bash\nVERSION=\"1.0.0\"\necho \"pt - Process Triage\"\nEOF\n    \n    cat \u003e \"${MOCK_BIN}/curl\" \u003c\u003c EOF\n#!/usr/bin/env bash\nif [[ \"\\$*\" == *\"url_effective\"* ]]; then\n    echo \"https://github.com/user/repo/releases/tag/v1.0.0\"\nelif [[ \"\\$*\" == *\"VERSION\"* ]]; then\n    echo \"1.0.0\"\nelif [[ \"\\$*\" == *\"/pt\"* ]] || [[ \"\\$*\" == *\"pt\\$\"* ]]; then\n    cat \"$mock_pt\"\nfi\nexit 0\nEOF\n    chmod +x \"${MOCK_BIN}/curl\"\n    use_mock_bin\n    \n    test_info \"Running installer with DEST=$DEST\"\n    run bash \"$INSTALL_SCRIPT\"\n    \n    test_info \"Exit code: $status\"\n    test_info \"Output: $output\"\n    \n    # Should succeed\n    assert_equals \"0\" \"$status\" \"Installer should succeed\"\n    \n    # Should create pt in target directory\n    [[ -f \"${INSTALL_DIR}/pt\" ]]\n    [[ -x \"${INSTALL_DIR}/pt\" ]]\n    \n    test_info \"Verified: pt installed to $INSTALL_DIR\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Installer: upgrade existing installation\" {\n    test_info \"Setting up: existing installation\"\n    \n    export DEST=\"$INSTALL_DIR\"\n    export PT_NO_PATH=1\n    \n    # Create \"old\" version\n    cat \u003e \"${INSTALL_DIR}/pt\" \u003c\u003c 'EOF'\n#!/usr/bin/env bash\nVERSION=\"0.9.0\"\necho \"Old version\"\nEOF\n    chmod +x \"${INSTALL_DIR}/pt\"\n    \n    test_info \"Old version installed: 0.9.0\"\n    \n    # Mock curl for \"new\" version\n    local mock_new_pt=\"${TEST_DIR}/mock_new_pt\"\n    cat \u003e \"$mock_new_pt\" \u003c\u003c 'EOF'\n#!/usr/bin/env bash\nVERSION=\"1.0.0\"\necho \"New version\"\nEOF\n    \n    cat \u003e \"${MOCK_BIN}/curl\" \u003c\u003c EOF\n#!/usr/bin/env bash\nif [[ \"\\$*\" == *\"url_effective\"* ]]; then\n    echo \"https://github.com/user/repo/releases/tag/v1.0.0\"\nelif [[ \"\\$*\" == *\"VERSION\"* ]]; then\n    echo \"1.0.0\"\nelse\n    cat \"$mock_new_pt\"\nfi\nexit 0\nEOF\n    chmod +x \"${MOCK_BIN}/curl\"\n    use_mock_bin\n    \n    test_info \"Running installer (upgrade scenario)\"\n    run bash \"$INSTALL_SCRIPT\"\n    \n    # Should show upgrade message\n    # Output should mention version change\n    \n    test_info \"Verifying version was upgraded\"\n    local installed_version\n    installed_version=$(grep 'VERSION=' \"${INSTALL_DIR}/pt\" | cut -d'\"' -f2)\n    assert_equals \"1.0.0\" \"$installed_version\" \"Should upgrade to new version\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# CHECKSUM VERIFICATION TESTS\n#==============================================================================\n\n@test \"Installer: VERIFY=1 checks checksum\" {\n    test_info \"Setting up: checksum verification enabled\"\n    \n    export DEST=\"$INSTALL_DIR\"\n    export PT_NO_PATH=1\n    export VERIFY=1\n    \n    # Create mock pt and calculate real checksum\n    local mock_pt=\"${TEST_DIR}/mock_pt\"\n    cat \u003e \"$mock_pt\" \u003c\u003c 'EOF'\n#!/usr/bin/env bash\nVERSION=\"1.0.0\"\nEOF\n    \n    local real_checksum\n    real_checksum=$(sha256sum \"$mock_pt\" 2\u003e/dev/null | cut -d' ' -f1 || shasum -a 256 \"$mock_pt\" | cut -d' ' -f1)\n    test_info \"Real checksum: $real_checksum\"\n    \n    cat \u003e \"${MOCK_BIN}/curl\" \u003c\u003c EOF\n#!/usr/bin/env bash\nif [[ \"\\$*\" == *\"url_effective\"* ]]; then\n    echo \"https://github.com/user/repo/releases/tag/v1.0.0\"\nelif [[ \"\\$*\" == *\".sha256\"* ]]; then\n    echo \"$real_checksum  pt\"\nelse\n    cat \"$mock_pt\"\nfi\nexit 0\nEOF\n    chmod +x \"${MOCK_BIN}/curl\"\n    use_mock_bin\n    \n    test_info \"Running installer with VERIFY=1\"\n    run bash \"$INSTALL_SCRIPT\"\n    \n    test_info \"Exit code: $status\"\n    assert_equals \"0\" \"$status\" \"Should succeed with valid checksum\"\n    \n    # Output should mention verification\n    assert_contains \"$output\" \"verify\\|checksum\\|Checksum\" \"Should mention verification\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Installer: VERIFY=1 fails on checksum mismatch\" {\n    test_info \"Setting up: checksum mismatch scenario\"\n    \n    export DEST=\"$INSTALL_DIR\"\n    export PT_NO_PATH=1\n    export VERIFY=1\n    \n    local mock_pt=\"${TEST_DIR}/mock_pt\"\n    echo '#!/bin/bash' \u003e \"$mock_pt\"\n    \n    # Provide WRONG checksum\n    local wrong_checksum=\"deadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeef\"\n    \n    cat \u003e \"${MOCK_BIN}/curl\" \u003c\u003c EOF\n#!/usr/bin/env bash\nif [[ \"\\$*\" == *\"url_effective\"* ]]; then\n    echo \"https://github.com/user/repo/releases/tag/v1.0.0\"\nelif [[ \"\\$*\" == *\".sha256\"* ]]; then\n    echo \"$wrong_checksum  pt\"\nelse\n    cat \"$mock_pt\"\nfi\nexit 0\nEOF\n    chmod +x \"${MOCK_BIN}/curl\"\n    use_mock_bin\n    \n    test_info \"Running installer with wrong checksum\"\n    run bash \"$INSTALL_SCRIPT\"\n    \n    test_info \"Exit code: $status\"\n    \n    # Should fail\n    [[ $status -ne 0 ]]\n    \n    # Should mention checksum failure\n    assert_contains \"$output\" \"mismatch\\|fail\\|error\" \"Should indicate checksum failure\"\n    \n    # Should NOT install\n    [[ ! -f \"${INSTALL_DIR}/pt\" ]]\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# PATH MANAGEMENT TESTS\n#==============================================================================\n\n@test \"Installer: adds to PATH in bashrc\" {\n    test_info \"Setting up: bash user\"\n    \n    export DEST=\"$INSTALL_DIR\"\n    export SHELL=\"/bin/bash\"\n    export HOME=\"$TEST_DIR\"\n    \n    # Create .bashrc\n    touch \"${HOME}/.bashrc\"\n    \n    # Mock curl\n    local mock_pt=\"${TEST_DIR}/mock_pt\"\n    echo '#!/bin/bash' \u003e \"$mock_pt\"\n    echo 'VERSION=\"1.0.0\"' \u003e\u003e \"$mock_pt\"\n    \n    cat \u003e \"${MOCK_BIN}/curl\" \u003c\u003c EOF\n#!/usr/bin/env bash\ncat \"$mock_pt\"\nexit 0\nEOF\n    chmod +x \"${MOCK_BIN}/curl\"\n    use_mock_bin\n    \n    test_info \"Running installer (should modify .bashrc)\"\n    run bash \"$INSTALL_SCRIPT\"\n    \n    # Check .bashrc was modified\n    if [[ -f \"${HOME}/.bashrc\" ]]; then\n        test_info \".bashrc contents:\"\n        cat \"${HOME}/.bashrc\"\n        \n        # Should contain PATH export\n        grep -q \"$INSTALL_DIR\" \"${HOME}/.bashrc\" || true\n    fi\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Installer: PT_NO_PATH=1 skips PATH modification\" {\n    test_info \"Setting up: PT_NO_PATH=1\"\n    \n    export DEST=\"$INSTALL_DIR\"\n    export PT_NO_PATH=1\n    export HOME=\"$TEST_DIR\"\n    \n    touch \"${HOME}/.bashrc\"\n    local original_content=\"# Original bashrc\"\n    echo \"$original_content\" \u003e \"${HOME}/.bashrc\"\n    \n    # Mock curl\n    local mock_pt=\"${TEST_DIR}/mock_pt\"\n    echo '#!/bin/bash' \u003e \"$mock_pt\"\n    \n    cat \u003e \"${MOCK_BIN}/curl\" \u003c\u003c EOF\n#!/usr/bin/env bash\ncat \"$mock_pt\"\nexit 0\nEOF\n    chmod +x \"${MOCK_BIN}/curl\"\n    use_mock_bin\n    \n    test_info \"Running installer with PT_NO_PATH=1\"\n    run bash \"$INSTALL_SCRIPT\"\n    \n    test_info \"Verifying .bashrc unchanged\"\n    local final_content\n    final_content=$(cat \"${HOME}/.bashrc\")\n    assert_equals \"$original_content\" \"$final_content\" \".bashrc should be unchanged\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# ERROR HANDLING TESTS\n#==============================================================================\n\n@test \"Installer: handles network failure gracefully\" {\n    test_info \"Setting up: network failure simulation\"\n    \n    export DEST=\"$INSTALL_DIR\"\n    export PT_NO_PATH=1\n    \n    # Mock curl to fail\n    create_mock_command \"curl\" \"Connection refused\" 1\n    use_mock_bin\n    \n    test_info \"Running installer (should fail gracefully)\"\n    run bash \"$INSTALL_SCRIPT\"\n    \n    test_info \"Exit code: $status\"\n    \n    # Should fail\n    [[ $status -ne 0 ]]\n    \n    # Should show helpful error\n    assert_contains \"$output\" \"error\\|fail\\|download\" \"Should indicate download failure\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Installer: specific version via PT_VERSION\" {\n    test_info \"Setting up: specific version installation\"\n    \n    export DEST=\"$INSTALL_DIR\"\n    export PT_NO_PATH=1\n    export PT_VERSION=\"1.2.3\"\n    \n    local mock_pt=\"${TEST_DIR}/mock_pt\"\n    cat \u003e \"$mock_pt\" \u003c\u003c 'EOF'\n#!/usr/bin/env bash\nVERSION=\"1.2.3\"\nEOF\n    \n    cat \u003e \"${MOCK_BIN}/curl\" \u003c\u003c EOF\n#!/usr/bin/env bash\n# Should request specific version, not latest\nif [[ \"\\$*\" == *\"1.2.3\"* ]]; then\n    cat \"$mock_pt\"\n    exit 0\nelse\n    exit 1\nfi\nEOF\n    chmod +x \"${MOCK_BIN}/curl\"\n    use_mock_bin\n    \n    test_info \"Running installer with PT_VERSION=1.2.3\"\n    run bash \"$INSTALL_SCRIPT\"\n    \n    # Verify correct version installed\n    if [[ -f \"${INSTALL_DIR}/pt\" ]]; then\n        local installed_version\n        installed_version=$(grep 'VERSION=' \"${INSTALL_DIR}/pt\" | cut -d'\"' -f2)\n        test_info \"Installed version: $installed_version\"\n    fi\n    \n    BATS_TEST_COMPLETED=pass\n}\n```\n\n## Success Criteria\n- [ ] Fresh install tested\n- [ ] Upgrade scenario tested\n- [ ] Checksum verification tested (pass and fail)\n- [ ] PATH management tested for bash/zsh\n- [ ] PT_NO_PATH option tested\n- [ ] Network failure handled gracefully\n- [ ] Specific version installation tested\n- [ ] All tests have detailed logging","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:49:13.558932389-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:49:13.558932389-05:00","dependencies":[{"issue_id":"process_triage-6xm","depends_on_id":"process_triage-h2y","type":"blocks","created_at":"2026-01-14T22:50:30.559722077-05:00","created_by":"Dicklesworthstone"},{"issue_id":"process_triage-6xm","depends_on_id":"process_triage-ume","type":"blocks","created_at":"2026-01-14T22:50:30.603353657-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-71t","title":"Implement tool runner with timeouts and caps","description":"## Task\nImplement a robust tool runner that executes external commands with safety controls.\n\n## Background\npt runs many external tools (ps, lsof, perf, etc.). The runner must:\n- Enforce timeouts (tools can hang)\n- Cap output size (tools can produce excessive output)\n- Handle tool failures gracefully\n- Apply backpressure when system is loaded\n- Track overhead budget\n\n## Requirements\n- Timeout per command (configurable, default 30s)\n- Output size cap (default 10MB)\n- Parallel execution limit\n- Resource tracking (time, memory used by tools)\n- Graceful cancellation\n\n## Functions Needed\n- run_tool(cmd, args, timeout, max_output) → Result\u003cOutput, Error\u003e\n- run_tools_parallel(tools, max_parallel) → Vec\u003cResult\u003e\n- ToolRunner::new(budget) → runner with shared budget\n- runner.run(cmd) → checks budget before running\n\n## Implementation Notes\n- Use tokio for async execution\n- SIGTERM then SIGKILL on timeout\n- Stream output to avoid memory issues\n- Track cumulative overhead against budget\n- Log all tool invocations for debugging\n\n## Safety Considerations\n- Never run tools that could modify system state\n- Validate command paths (avoid injection)\n- nice/ionice tools to limit impact\n- Kill orphaned tool processes on cleanup\n\n## Deliverables\n- Rust module: collect/tool_runner.rs\n- Unit tests with mock commands\n- Integration tests with real tools\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:24:59.86274462-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:24:59.86274462-05:00"}
{"id":"process_triage-72j","title":"EPIC: Phase 9 - Shadow Mode","description":"## Overview\nPhase 9 implements shadow mode: passive observation that collects data and updates beliefs without taking any action.\n\n## Background\nShadow mode lets pt run continuously in the background, observing process behavior over time. This builds better priors, detects patterns, and enables the Hawkes/BOCPD time-series models to function properly. The plan specifies this as preparation for dormant daemon mode.\n\n## Why It Matters\nMany processes only reveal their nature over time. A build process looks identical to an abandoned process for the first hour. Shadow mode collects longitudinal data that transforms inference accuracy. It also validates the model against ground truth (processes that eventually get killed by users or exit naturally).\n\n## Phase Scope\n1. Continuous monitoring daemon\n2. Observation storage in telemetry DB\n3. Belief state persistence and update\n4. Event correlation across time\n5. Model validation framework\n\n## Key Components\n- Background scanner (configurable interval)\n- State tracker (process lifecycle monitoring)\n- Event logger (structured observations)\n- Prior updater (incremental Bayesian updates)\n- Validation reporter (predicted vs actual outcomes)\n\n## Operating Modes\n- **Silent**: Observe only, no output\n- **Advisory**: Observe + emit recommendations (no action)\n- **Notify**: Advisory + desktop/email notifications for high-confidence findings\n\n## Dependencies\n- Phase 3: Evidence collection\n- Phase 4: Inference engine\n- Phase 5: Decision theory (for recommendations)\n\n## Success Criteria\n- Shadow daemon runs reliably for days\n- Observations stored efficiently\n- Priors improve over time (measured)\n- Model validation produces accuracy metrics","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:33:57.335812791-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:34:33.802091115-05:00"}
{"id":"process_triage-7h8","title":"Implement natural language explanation generator","description":"## Overview\nGenerate natural language explanations of why processes are flagged or spared.\n\n## Background\nNot all users want to see raw math. The plan calls for human-readable explanations that translate Bayesian reasoning into plain English. These explanations appear in the default TUI and in agent output.\n\n## Why It Matters\nNatural language explanations make pt accessible to users who don't know statistics. 'This process scores high because it's been idle for 3 days with no file activity' is immediately understandable, whereas 'Posterior P(C=abandoned|x) = 0.87' requires expertise.\n\n## Technical Approach\n1. Template-based sentence generation\n2. Rank evidence by Bayes factor contribution\n3. Select top 3 contributors for summary\n4. Generate contextual hedging based on confidence\n5. Adapt language to confidence level\n\n## Template Structure\n- **High confidence (\u003e0.9)**: 'This process is almost certainly [state] because [evidence]'\n- **Medium confidence (0.7-0.9)**: 'This process appears to be [state], mainly due to [evidence]'\n- **Low confidence (0.5-0.7)**: 'This process might be [state]; notable signals include [evidence]'\n- **Uncertain (\u003c0.5)**: 'Insufficient evidence to classify this process; [mixed signals]'\n\n## Evidence Phrasing\n- Age: 'running for X days' / 'recently started'\n- CPU: 'using almost no CPU' / 'actively computing'\n- Memory: 'holding X GB but not using it' / 'memory usage normal'\n- FDs: 'no file activity in X hours' / 'actively reading/writing'\n- Network: 'no network connections' / 'listening on port X'\n\n## Success Criteria\n- Explanations grammatically correct\n- Top contributors accurately identified\n- Confidence reflected in language hedging\n- Explanations match actual evidence","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:32:04.925509399-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:32:49.853219331-05:00"}
{"id":"process_triage-7i0","title":"Add PATH management to installer","description":"## Purpose\nAutomatically add the installation directory to the user's PATH if not already present.\n\n## Parent Epic\nInstallation Infrastructure (process_triage-n0r)\n\n## Depends On\n- Add cross-platform mktemp and download functions\n\n## Shell Detection\n\n```bash\ndetect_shell() {\n    local shell_name\n    \n    # Check $SHELL environment variable\n    shell_name=\"${SHELL##*/}\"\n    \n    # Validate it's a known shell\n    case \"$shell_name\" in\n        bash|zsh|fish|sh)\n            echo \"$shell_name\"\n            ;;\n        *)\n            # Fallback: check what's running\n            if [[ -n \"${BASH_VERSION:-}\" ]]; then\n                echo \"bash\"\n            elif [[ -n \"${ZSH_VERSION:-}\" ]]; then\n                echo \"zsh\"\n            else\n                echo \"bash\"  # Default assumption\n            fi\n            ;;\n    esac\n}\n```\n\n## Shell Config Files\n\n```bash\nget_shell_config() {\n    local shell_name=\"$1\"\n    \n    case \"$shell_name\" in\n        bash)\n            # Prefer .bashrc for interactive, .bash_profile for login\n            if [[ -f \"$HOME/.bashrc\" ]]; then\n                echo \"$HOME/.bashrc\"\n            elif [[ -f \"$HOME/.bash_profile\" ]]; then\n                echo \"$HOME/.bash_profile\"\n            else\n                echo \"$HOME/.bashrc\"  # Create it\n            fi\n            ;;\n        zsh)\n            echo \"$HOME/.zshrc\"\n            ;;\n        fish)\n            echo \"$HOME/.config/fish/config.fish\"\n            ;;\n        *)\n            echo \"$HOME/.profile\"\n            ;;\n    esac\n}\n```\n\n## PATH Addition\n\n```bash\nadd_to_path() {\n    local install_dir=\"$1\"\n    \n    # Check if already in PATH\n    if [[ \":$PATH:\" == *\":$install_dir:\"* ]]; then\n        log_info \"$install_dir already in PATH\"\n        return 0\n    fi\n    \n    # Detect shell and config file\n    local shell_name config_file\n    shell_name=$(detect_shell)\n    config_file=$(get_shell_config \"$shell_name\")\n    \n    log_step \"Adding $install_dir to PATH in $config_file\"\n    \n    # Create directory for fish config if needed\n    if [[ \"$shell_name\" == \"fish\" ]]; then\n        mkdir -p \"${config_file%/*}\"\n    fi\n    \n    # Add PATH export (idempotent - check first)\n    local path_line\n    case \"$shell_name\" in\n        fish)\n            path_line=\"set -gx PATH \\\"$install_dir\\\" \\$PATH\"\n            ;;\n        *)\n            path_line=\"export PATH=\\\"$install_dir:\\$PATH\\\"\"\n            ;;\n    esac\n    \n    # Check if already added (avoid duplicates)\n    if [[ -f \"$config_file\" ]] \u0026\u0026 grep -qF \"$install_dir\" \"$config_file\"; then\n        log_info \"PATH already configured in $config_file\"\n        return 0\n    fi\n    \n    # Add to config\n    {\n        echo \"\"\n        echo \"# Added by pt installer\"\n        echo \"$path_line\"\n    } \u003e\u003e \"$config_file\"\n    \n    log_success \"Added to $config_file\"\n    log_info \"Run 'source $config_file' or start a new terminal.\"\n}\n```\n\n## Skip Option\n\n```bash\n# In main():\nif [[ \"${PT_NO_PATH:-}\" \\!= \"1\" ]]; then\n    add_to_path \"$install_dir\"\nelse\n    log_info \"Skipping PATH modification (PT_NO_PATH=1)\"\nfi\n```\n\n## Success Criteria\n- [ ] Detects bash, zsh, fish correctly\n- [ ] Uses correct config file for each shell\n- [ ] Doesn't add duplicates\n- [ ] Creates fish config directory if needed\n- [ ] PT_NO_PATH=1 skips PATH modification\n- [ ] Clear instructions to activate changes","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:36:32.47100567-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:36:32.47100567-05:00","dependencies":[{"issue_id":"process_triage-7i0","depends_on_id":"process_triage-c57","type":"blocks","created_at":"2026-01-14T22:40:45.552787909-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-7ku","title":"Create release.yml workflow","description":"## Purpose\nCreate the release workflow that triggers on version tags and creates GitHub releases with all artifacts.\n\n## Parent Epic\nRelease Automation with Checksums (process_triage-aip)\n\n## Depends On\n- Create VERSION file as single source of truth\n- Create ci.yml with ShellCheck job (CI must exist first)\n\n## Trigger Configuration\n```yaml\non:\n  push:\n    tags:\n      - 'v*'  # v1.0.0, v1.2.3, etc.\n```\n\n## Implementation\n\n### .github/workflows/release.yml\n```yaml\nname: Release\n\non:\n  push:\n    tags:\n      - 'v*'\n\npermissions:\n  contents: write  # Needed to create releases\n\njobs:\n  release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      \n      - name: Extract version from tag\n        id: version\n        run: |\n          # Tag is refs/tags/v1.2.3 → extract 1.2.3\n          tag_version=${GITHUB_REF#refs/tags/v}\n          echo \"version=$tag_version\" \u003e\u003e $GITHUB_OUTPUT\n          echo \"Releasing version: $tag_version\"\n      \n      - name: Validate version matches script\n        run: |\n          tag_version=\"${{ steps.version.outputs.version }}\"\n          script_version=$(grep '^VERSION=' pt | head -1 | cut -d'\"' -f2)\n          \n          if [[ \"$tag_version\" \\!= \"$script_version\" ]]; then\n            echo \"::error::Tag version ($tag_version) doesn't match script version ($script_version)\"\n            echo \"\"\n            echo \"To fix: Update VERSION constant in pt to $tag_version\"\n            exit 1\n          fi\n          \n          echo \"✓ Version validated: $tag_version\"\n      \n      - name: Generate checksums\n        run: |\n          # Combined checksums file\n          sha256sum pt install.sh \u003e checksums.sha256\n          \n          # Individual checksum files (for installer)\n          sha256sum pt | tee pt.sha256\n          sha256sum install.sh | tee install.sh.sha256\n          \n          echo \"\"\n          echo \"Generated checksums:\"\n          cat checksums.sha256\n      \n      - name: Create Release\n        uses: softprops/action-gh-release@v1\n        with:\n          name: \"pt v${{ steps.version.outputs.version }}\"\n          draft: false\n          prerelease: false\n          files: |\n            pt\n            install.sh\n            checksums.sha256\n            pt.sha256\n            install.sh.sha256\n          body: |\n            ## Installation\n            \n            \\`\\`\\`bash\n            curl -fsSL https://raw.githubusercontent.com/${{ github.repository }}/main/install.sh | bash\n            \\`\\`\\`\n            \n            ### With checksum verification\n            \\`\\`\\`bash\n            VERIFY=1 curl -fsSL https://raw.githubusercontent.com/${{ github.repository }}/main/install.sh | bash\n            \\`\\`\\`\n            \n            ## Manual Verification\n            \\`\\`\\`bash\n            # Download\n            curl -fsSL https://github.com/${{ github.repository }}/releases/download/v${{ steps.version.outputs.version }}/pt -o pt\n            \n            # Verify checksum\n            echo \"$(curl -fsSL https://github.com/${{ github.repository }}/releases/download/v${{ steps.version.outputs.version }}/pt.sha256)\" | sha256sum -c -\n            \n            # Install\n            chmod +x pt \u0026\u0026 mv pt ~/.local/bin/\n            \\`\\`\\`\n            \n            ## What's New\n            \n            See [CHANGELOG](https://github.com/${{ github.repository }}/blob/main/CHANGELOG.md) for details.\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n```\n\n## Release Process (for developers)\n```bash\n# 1. Update VERSION in pt script\n# 2. Update VERSION file\n# 3. Commit changes\ngit add -A \u0026\u0026 git commit -m \"Bump version to 1.1.0\"\n\n# 4. Create and push tag\ngit tag v1.1.0\ngit push origin main --tags\n\n# 5. GitHub Action automatically:\n#    - Validates version\n#    - Generates checksums\n#    - Creates release with artifacts\n```\n\n## Success Criteria\n- [ ] release.yml created\n- [ ] Triggers on v* tags\n- [ ] Version validation prevents mismatches\n- [ ] Checksums generated correctly\n- [ ] Release created with all artifacts\n- [ ] Release notes include install instructions","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:39:21.422180653-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:39:21.422180653-05:00","dependencies":[{"issue_id":"process_triage-7ku","depends_on_id":"process_triage-nk1","type":"blocks","created_at":"2026-01-14T22:40:47.995394333-05:00","created_by":"Dicklesworthstone"},{"issue_id":"process_triage-7ku","depends_on_id":"process_triage-i5r","type":"blocks","created_at":"2026-01-14T22:40:48.059595257-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-7pn","title":"EPIC: Phase 7 - UX Refinement and Galaxy-Brain Mode","description":"## Overview\nPhase 7 delivers the premium user experience: rich evidence display, galaxy-brain mathematical transparency mode, and polished TUI interactions.\n\n## Background\nThe plan specifies that pt should provide 'galaxy-brain mode' for users who want to understand the full mathematical reasoning behind decisions. This includes showing prior parameters, likelihood contributions, posterior updates, and decision-theoretic calculations in human-readable form.\n\n## Why It Matters\nTransparency builds trust. Power users and developers need to understand WHY a process was flagged. Galaxy-brain mode transforms pt from a black box into an educational tool that explains Bayesian inference in context. This also aids debugging and parameter tuning.\n\n## Phase Scope\n1. Evidence ledger display (interactive drill-down)\n2. Galaxy-brain mode implementation (full math transparency)\n3. TUI polish (animations, colors, responsive layout)\n4. Explanation generation (natural language summaries)\n5. Help system integration\n\n## Key Deliverables\n- Evidence panel showing all collected signals with weights\n- Mathematical breakdown on demand (posterior calculation steps)\n- Natural language explanations (\"This process scores high because...\")\n- Color-coded confidence indicators\n- Responsive TUI that adapts to terminal size\n\n## Dependencies\n- Phase 3: Evidence collection (data to display)\n- Phase 4: Inference engine (math to explain)\n- Phase 5: Decision theory (thresholds and losses to show)\n\n## Success Criteria\n- Galaxy-brain mode shows complete math trace\n- Evidence ledger is navigable and searchable\n- Explanations are accurate and helpful\n- TUI is responsive and visually polished","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:31:16.598467928-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:31:56.518641759-05:00"}
{"id":"process_triage-7ra","title":"Implement environment and IPC supervision detection","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:34:56.605373199-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:34:56.605373199-05:00"}
{"id":"process_triage-82j","title":"Implement HTTP redirect-based version checking","description":"## Purpose\nImplement version checking that uses HTTP redirects instead of GitHub API, avoiding rate limits and proxy issues.\n\n## Parent Epic\nSelf-Update Mechanism (process_triage-097)\n\n## Depends On\n- Create VERSION file as single source of truth\n\n## Why Not GitHub API?\nFrom repo_updater's design rationale:\n1. **Rate Limits**: GitHub API has strict rate limits for unauthenticated requests\n2. **Proxy Issues**: Corporate proxies often block API calls but allow web traffic\n3. **Simplicity**: Redirect probing is simpler with fewer failure modes\n4. **No Auth Needed**: Works without tokens\n\n## Implementation\n\n### The Redirect Trick\nGitHub's `/releases/latest` redirects to the actual release URL:\n```\nhttps://github.com/USER/REPO/releases/latest\n  → 302 Redirect →\nhttps://github.com/USER/REPO/releases/tag/v1.2.3\n```\n\nWe can extract the version from the final URL.\n\n### Code Implementation\n```bash\n#------------------------------------------------------------------------------\n# Version checking (no GitHub API needed)\n#------------------------------------------------------------------------------\n\nGITHUB_REPO=\"Dicklesworthstone/process_triage\"\nRELEASES_URL=\"https://github.com/${GITHUB_REPO}/releases\"\n\nget_latest_version() {\n    local effective_url\n    \n    # Follow redirects and get final URL\n    # -o /dev/null: discard body\n    # -w '%{url_effective}': print final URL\n    # -L: follow redirects\n    # --connect-timeout: don't hang forever\n    effective_url=$(curl -fsSL -o /dev/null -w '%{url_effective}' \\\n        --connect-timeout 5 --max-time 10 \\\n        \"${RELEASES_URL}/latest\" 2\u003e/dev/null)\n    \n    if [[ -z \"$effective_url\" ]]; then\n        log_debug \"Could not fetch latest release URL\"\n        return 1\n    fi\n    \n    # Extract version from URL: .../releases/tag/v1.2.3 → 1.2.3\n    local version=\"${effective_url##*/}\"  # Get last path component\n    version=\"${version#v}\"                 # Remove 'v' prefix if present\n    \n    if [[ \\! \"$version\" =~ ^[0-9]+\\.[0-9]+\\.[0-9]+$ ]]; then\n        log_debug \"Invalid version format: $version\"\n        return 1\n    fi\n    \n    printf '%s' \"$version\"\n}\n\ncheck_for_update() {\n    local current=\"$VERSION\"\n    local latest\n    \n    latest=$(get_latest_version) || {\n        log_debug \"Could not check for updates\"\n        return 1\n    }\n    \n    if version_gt \"$latest\" \"$current\"; then\n        printf '%s' \"$latest\"\n        return 0\n    else\n        return 1  # No update available\n    fi\n}\n\n# Semantic version comparison\nversion_gt() {\n    local v1=\"$1\" v2=\"$2\"\n    \n    # Use sort -V if available (GNU coreutils)\n    if printf '%s\\n' \"$v1\" \"$v2\" | sort -V \u0026\u003e/dev/null; then\n        [[ \"$(printf '%s\\n' \"$v1\" \"$v2\" | sort -V | tail -n1)\" == \"$v1\" \u0026\u0026 \"$v1\" \\!= \"$v2\" ]]\n    else\n        # Fallback: simple string comparison (works for most cases)\n        [[ \"$v1\" \u003e \"$v2\" ]]\n    fi\n}\n```\n\n### Usage in Update Command\n```bash\ncmd_update() {\n    local check_only=false\n    [[ \"${1:-}\" == \"--check\" ]] \u0026\u0026 check_only=true\n    \n    log_step \"Checking for updates...\"\n    \n    local latest\n    if latest=$(check_for_update); then\n        log_info \"Update available: ${VERSION} → ${latest}\"\n        \n        if [[ \"$check_only\" == \"true\" ]]; then\n            return 0\n        fi\n        \n        # Continue with download and install...\n    else\n        log_success \"Already on latest version ($VERSION)\"\n        return 0\n    fi\n}\n```\n\n## Error Handling\n- Network timeout: Return gracefully, don't block user\n- Invalid URL: Log debug message, return error\n- Invalid version format: Log debug, return error\n\n## Success Criteria\n- [ ] Version check works without GitHub API\n- [ ] Handles network timeouts gracefully\n- [ ] Extracts version correctly from redirect URL\n- [ ] version_gt() compares semver correctly\n- [ ] Works through corporate proxies","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:35:01.53043535-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:35:01.53043535-05:00","dependencies":[{"issue_id":"process_triage-82j","depends_on_id":"process_triage-nk1","type":"blocks","created_at":"2026-01-14T22:40:44.531713761-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-8f6","title":"Define galaxy-brain mode contract","description":"## Task\nSpecify the 'galaxy-brain mode' interface that exposes the full mathematical transparency of the inference engine.\n\n## Background\nSection 7.8 defines galaxy-brain mode as the 'alien artifact' transparency feature:\n- Toggle via keybinding (g) in TUI or --galaxy-brain flag\n- Shows all the scary math with concrete numeric impact on decisions\n- Serves dual purposes: educational/fun and debuggable\n\nRequired math cards:\n1. **Posterior core**: log P(C|x) breakdown with all terms\n2. **Time-varying hazard**: Regime hazards with Gamma posteriors\n3. **Conformal interval**: Runtime/CPU prediction intervals\n4. **Conformal class set**: Classification prediction sets with p-values\n5. **e-values / e-FDR**: Anytime-valid selection\n6. **Alpha-investing**: Online budget state\n7. **VOI**: Value of information for next best probe\n\n## Deliverables\n- JSON schema for galaxy_brain.cards[] structure\n- Required fields per card: id, title, equations, values, intuition\n- Stable card IDs (posterior_core, hazard_time_varying, etc.)\n- TUI rendering specification (equations + numbers)\n- CLI output format\n- Report tab specification\n- KaTeX/MathJax equation format\n\n## Technical Considerations\n- Cards share same schema across TUI, CLI, and report\n- values object contains concrete computed numbers\n- intuition provides one-line explanation\n- Must be possible to regenerate from stored inference\n- Consider caching for responsive TUI switching","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:22:32.653460928-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:22:32.653460928-05:00"}
{"id":"process_triage-8hb","title":"Implement dry-run mode","description":"## Overview\nImplement dry-run mode that simulates all actions without executing them.\n\n## Background\nThe plan specifies a --dry-run flag that runs the full pipeline—scan, score, recommend—but stops before executing any kills. This allows users to preview what would happen without risk.\n\n## Why It Matters\nDry-run mode enables:\n1. Testing: Verify configuration without consequences\n2. Learning: See what pt would do in your environment\n3. Auditing: Generate reports for review before approval\n4. Scripting: Check candidates programmatically without action\n\n## Technical Approach\n1. Add --dry-run flag to CLI\n2. Execute full pipeline up to action phase\n3. Generate action plan but don't execute\n4. Output what would have happened\n5. Log dry-run as distinct event type\n\n## Dry-Run Output\n- Full candidate list with scores\n- Recommended actions for each\n- Expected outcomes (success probability)\n- Policy checks that would apply\n- Any warnings or blockers\n\n## Output Formats\n- Interactive: Show in TUI with '[DRY-RUN]' banner\n- JSON: Full action plan for programmatic use\n- Summary: Count and top candidates only\n\n## Behavioral Guarantees\n- No signals sent to any process\n- No state modified (except log entry for dry-run)\n- Read-only /proc access only\n- No network calls (except telemetry if enabled)\n\n## Success Criteria\n- --dry-run produces identical recommendations to real run\n- No side effects from dry-run\n- Output clearly marked as dry-run\n- Supports all output formats","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:33:01.862448356-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:33:51.580128996-05:00"}
{"id":"process_triage-8n3","title":"Define redaction and hashing policy for sensitive data","description":"## Task\nSpecify the privacy-preserving policy for handling sensitive data in telemetry and reports.\n\n## Background\nSection 3.4 specifies redaction requirements:\n- Command lines may contain secrets, tokens, paths\n- Working directories reveal project structure\n- Environment variables contain credentials\n- Network endpoints reveal infrastructure\n\nThe policy must balance:\n- Debuggability (need enough info to understand issues)\n- Privacy (don't leak secrets)\n- Shareability (bundles should be safe to share)\n\n## Deliverables\n- Redaction rules specification (what gets redacted)\n- Hashing policy (consistent hashing for pattern matching)\n- Per-export-profile redaction levels:\n  - minimal: plan + summary only\n  - safe: includes derived features, redacts raw strings\n  - forensic: includes more raw data, optional encryption\n- Token/secret detection patterns\n- Path normalization rules\n\n## Technical Considerations\n- Hashing must be deterministic (same string = same hash)\n- Hash function should be fast (FNV-1a or similar)\n- Redaction happens at write time, not query time\n- Some fields need both raw (for inference) and redacted (for persistence)\n- Environment variable filtering (allow-list vs deny-list)\n\n## Examples\n- /home/user/secret-project/src → [HOME]/[HASH:a1b2]/src\n- API_KEY=sk-12345... → API_KEY=[REDACTED]\n- --token=abc123 → --token=[REDACTED]","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:21:27.913698034-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:21:27.913698034-05:00"}
{"id":"process_triage-8ng","title":"Add section markers and reorganize code","description":"## Purpose\nAdd clear section markers to pt script and reorganize functions following the patterns from repo_updater.\n\n## Parent Epic\nCode Organization \u0026 Standards (process_triage-a6q)\n\n## Current Structure (pt - 579 lines)\nThe script has implicit sections but no clear markers:\n- Lines 1-29: Version and config\n- Lines 35-64: ensure_gum()\n- Lines 70-95: Utility functions\n- etc.\n\n## Target Structure with Section Markers\n\n```bash\n#\\!/usr/bin/env bash\n#\n# pt - Process Triage\n# Interactive zombie/abandoned process killer\n#\n# https://github.com/Dicklesworthstone/process_triage\n#\n\n#==============================================================================\n# SECTION 1: VERSION AND CONSTANTS\n#==============================================================================\n\nVERSION=\"1.0.0\"\nGITHUB_REPO=\"Dicklesworthstone/process_triage\"\n\n#------------------------------------------------------------------------------\n# Scoring thresholds\n#------------------------------------------------------------------------------\n\nTHRESHOLD_KILL=50\nTHRESHOLD_REVIEW=20\n\n#==============================================================================\n# SECTION 2: CONFIGURATION\n#==============================================================================\n\n#------------------------------------------------------------------------------\n# XDG Base Directory paths\n#------------------------------------------------------------------------------\n\nXDG_CONFIG_HOME=\"${XDG_CONFIG_HOME:-$HOME/.config}\"\nCONFIG_DIR=\"${PROCESS_TRIAGE_CONFIG:-$XDG_CONFIG_HOME/process_triage}\"\nDECISIONS_FILE=\"$CONFIG_DIR/decisions.json\"\nLOG_FILE=\"$CONFIG_DIR/triage.log\"\n\n#==============================================================================\n# SECTION 3: TERMINAL DETECTION AND COLORS\n#==============================================================================\n\n#------------------------------------------------------------------------------\n# TTY and color detection\n#------------------------------------------------------------------------------\n\nIS_TTY=false\n[[ -t 2 ]] \u0026\u0026 IS_TTY=true\n\nUSE_COLOR=true\nif [[ \"$IS_TTY\" \\!= \"true\" ]] || [[ -n \"${NO_COLOR:-}\" ]]; then\n    USE_COLOR=false\nfi\n\n#------------------------------------------------------------------------------\n# ANSI color codes\n#------------------------------------------------------------------------------\n\nif [[ \"$USE_COLOR\" == \"true\" ]]; then\n    RED='\\033[0;31m'\n    # ... etc\nfi\n\n#==============================================================================\n# SECTION 4: LOGGING FUNCTIONS\n#==============================================================================\n\nlog_info() { ... }\nlog_success() { ... }\nlog_warn() { ... }\nlog_error() { ... }\nlog_step() { ... }\nlog_debug() { ... }\n\n#==============================================================================\n# SECTION 5: UTILITY FUNCTIONS\n#==============================================================================\n\nformat_duration() { ... }\nformat_memory() { ... }\n\n#==============================================================================\n# SECTION 6: DEPENDENCY MANAGEMENT\n#==============================================================================\n\nensure_gum() { ... }\nensure_config() { ... }\n\n#==============================================================================\n# SECTION 7: GUM WRAPPERS (with ANSI fallback)\n#==============================================================================\n\ngum_style() { ... }\ngum_confirm() { ... }\ngum_choose() { ... }\ngum_spin() { ... }\n\n#==============================================================================\n# SECTION 8: DECISION MEMORY\n#==============================================================================\n\nnormalize_pattern() { ... }\nsave_decision() { ... }\nget_past_decision() { ... }\nload_decisions_cache() { ... }\nget_cached_decision() { ... }\n\n#==============================================================================\n# SECTION 9: PROCESS SCORING\n#==============================================================================\n\nscore_process() { ... }\n\n#==============================================================================\n# SECTION 10: PROCESS COLLECTION\n#==============================================================================\n\ncollect_candidates() { ... }\n\n#==============================================================================\n# SECTION 11: UI COMPONENTS\n#==============================================================================\n\nshow_header() { ... }\nshow_system_stats() { ... }\nformat_row() { ... }\n\n#==============================================================================\n# SECTION 12: COMMAND HANDLERS\n#==============================================================================\n\ncmd_scan() { ... }\ncmd_run() { ... }\ncmd_history() { ... }\ncmd_clear() { ... }\ncmd_update() { ... }\ncmd_help() { ... }\n\n#==============================================================================\n# SECTION 13: SELF-UPDATE\n#==============================================================================\n\nget_latest_version() { ... }\ncheck_for_update() { ... }\nverify_checksum() { ... }\nvalidate_script() { ... }\natomic_replace() { ... }\ndo_update() { ... }\n\n#==============================================================================\n# SECTION 14: ENTRY POINT\n#==============================================================================\n\nmain() { ... }\n\nmain \"$@\"\n```\n\n## Benefits\n1. **Navigation**: Jump to sections by searching for \"SECTION N\"\n2. **Understanding**: Clear boundaries between concerns\n3. **Maintenance**: Easy to find where to add new code\n4. **Documentation**: Self-documenting structure\n\n## Success Criteria\n- [ ] All sections have clear markers\n- [ ] Subsections have dashed markers\n- [ ] Functions grouped logically\n- [ ] No orphan code between sections\n- [ ] Section numbers are sequential","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:40:15.844282709-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:40:15.844282709-05:00"}
{"id":"process_triage-8z2","title":"Implement rate limiting for kill operations","description":"## Overview\nImplement rate limiting to prevent runaway kills and provide circuit breaker protection.\n\n## Background\nThe plan specifies rate limits: max 10 kills per minute, 100 per hour, configurable per policy.json. This prevents scenarios where a bug causes pt to kill processes in a loop, or a user accidentally confirms a dangerous batch.\n\n## Why It Matters\nWithout rate limits, a single mistake could cascade. Rate limiting provides time to notice and stop problematic behavior before it causes widespread damage. It also smooths system impact of batch kills.\n\n## Technical Approach\n1. Implement sliding window rate limiter\n2. Track: per-minute, per-hour, per-session counters\n3. Check limits before each action\n4. Provide clear feedback when rate limited\n5. Cooldown mode when limits approached\n\n## Rate Limit Configuration (policy.json)\n- kills_per_minute: 10 (default)\n- kills_per_hour: 100 (default)\n- kills_per_session: 500 (default)\n- cooldown_seconds: 60 (mandatory pause when 80% of limit reached)\n\n## Rate Limit Response\n- 0-80% of limit: Normal operation\n- 80-100% of limit: Warning, suggest cooldown\n- At limit: Block with message, suggest --force or wait\n- --force flag: Override with explicit acknowledgment (logged)\n\n## Sliding Window Algorithm\nUse token bucket or sliding log for smooth limiting (not fixed windows that allow bursts at boundaries).\n\n## Success Criteria\n- All rate limits enforced\n- Smooth limiting (no boundary bursts)\n- Clear user feedback at each threshold\n- Override mechanism for emergencies","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:32:59.904508903-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:33:49.140151911-05:00"}
{"id":"process_triage-9ch","title":"Add BATS test job with matrix build","description":"## Purpose\nAdd a CI job that runs BATS tests on both Linux and macOS to ensure cross-platform compatibility.\n\n## Parent Epic\nGitHub Actions CI/CD Pipeline (process_triage-68c)\n\n## Depends On\n- Add bash syntax validation job to CI\n\n## Why Matrix Build?\n- pt should work on both Linux and macOS\n- Some bash features differ between GNU (Linux) and BSD (macOS)\n- macOS ships with bash 3.2 by default (we need 4.0+)\n\n## Implementation\n\n### Add to ci.yml\n```yaml\n  tests:\n    name: Tests (${{ matrix.os }})\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest, macos-latest]\n    \n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      \n      - name: Install Bash 5 (macOS)\n        if: runner.os == 'macOS'\n        run: |\n          brew install bash\n          echo \"/opt/homebrew/bin\" \u003e\u003e $GITHUB_PATH\n          # Verify version\n          /opt/homebrew/bin/bash --version\n      \n      - name: Install BATS\n        run: |\n          git clone --depth 1 https://github.com/bats-core/bats-core.git\n          cd bats-core\n          sudo ./install.sh /usr/local\n      \n      - name: Install gum (for integration tests)\n        run: |\n          if [[ \"$RUNNER_OS\" == \"Linux\" ]]; then\n            sudo mkdir -p /etc/apt/keyrings\n            curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg\n            echo \"deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *\" | sudo tee /etc/apt/sources.list.d/charm.list\n            sudo apt update \u0026\u0026 sudo apt install -y gum\n          else\n            brew install gum\n          fi\n        continue-on-error: true  # Tests should work without gum too\n      \n      - name: Run BATS tests\n        run: |\n          bats --tap test/\n        env:\n          TERM: xterm-256color\n      \n      - name: Upload test results\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: test-results-${{ matrix.os }}\n          path: test/\n          retention-days: 14\n```\n\n## macOS Bash Version Issue\nmacOS ships with bash 3.2 (ancient, from 2007) due to licensing.\nWe need bash 4.0+ for:\n- Associative arrays (`declare -A`)\n- `mapfile` / `readarray`\n- Various modern features\n\nSolution: Install bash 5 via Homebrew on macOS runners.\n\n## Success Criteria\n- [ ] Tests run on ubuntu-latest\n- [ ] Tests run on macos-latest\n- [ ] Bash 5 installed on macOS\n- [ ] BATS installed and working\n- [ ] Test results uploaded as artifacts\n- [ ] Tests pass on both platforms","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:37:31.856147324-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:37:31.856147324-05:00","dependencies":[{"issue_id":"process_triage-9ch","depends_on_id":"process_triage-omq","type":"blocks","created_at":"2026-01-14T22:40:46.309822855-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-9jo","title":"Add structured error messages with remediation","description":"## Purpose\nAdd a consistent error message format that includes the problem and a suggested fix.\n\n## Parent Epic\nCode Organization \u0026 Standards (process_triage-a6q)\n\n## Depends On\n- Implement log_* functions with emoji prefixes\n\n## Current State\n```bash\nlog_error \"Failed to install gum\"\n# User doesn't know what to do next\n```\n\n## Target State\n```bash\nerror_with_fix \"gum installation failed\" \\\n    \"Package manager not found or installation rejected\" \\\n    \"Install gum manually: brew install gum (or apt install gum)\"\n\n# Output:\n# ✗ gum installation failed\n#   Reason: Package manager not found or installation rejected\n#   Fix: Install gum manually: brew install gum (or apt install gum)\n```\n\n## Implementation\n\n### Error Functions\n```bash\n#------------------------------------------------------------------------------\n# Structured error messages\n#------------------------------------------------------------------------------\n\n# Full error with reason and fix\nerror_with_fix() {\n    local category=\"$1\"\n    local reason=\"$2\"\n    local fix=\"$3\"\n    \n    log_error \"$category\"\n    printf '  %bReason:%b %s\\n' \"$DIM\" \"$RESET\" \"$reason\" \u003e\u00262\n    printf '  %bFix:%b %s\\n' \"$DIM\" \"$RESET\" \"$fix\" \u003e\u00262\n}\n\n# Error with just a fix suggestion\nerror_with_hint() {\n    local message=\"$1\"\n    local hint=\"$2\"\n    \n    log_error \"$message\"\n    printf '  %bHint:%b %s\\n' \"$DIM\" \"$RESET\" \"$hint\" \u003e\u00262\n}\n\n# Error for permission issues\nerror_permission() {\n    local path=\"$1\"\n    local action=\"${2:-write to}\"\n    \n    error_with_fix \"Permission denied\" \\\n        \"Cannot $action $path\" \\\n        \"Try with sudo, or use a different location\"\n}\n\n# Error for missing dependency\nerror_missing_dep() {\n    local dep=\"$1\"\n    local install_cmd=\"$2\"\n    \n    error_with_fix \"$dep not found\" \\\n        \"$dep is required but not installed\" \\\n        \"Install it with: $install_cmd\"\n}\n```\n\n### Usage Examples\n```bash\n# Network error\nerror_with_fix \"Update check failed\" \\\n    \"Could not reach GitHub (timeout or DNS)\" \\\n    \"Check your internet connection and try again\"\n\n# Permission error\nerror_permission \"/usr/local/bin/pt\" \"write to\"\n\n# Missing dependency\nerror_missing_dep \"jq\" \"apt install jq (or brew install jq)\"\n\n# Version mismatch\nerror_with_hint \"Version mismatch\" \\\n    \"Update the VERSION file to match the script, or vice versa\"\n```\n\n## Migration\nReplace all bare log_error calls with structured errors where a fix is possible:\n```bash\n# Before\nlog_error \"Download failed\"\n\n# After\nerror_with_fix \"Download failed\" \\\n    \"Network request timed out after 30 seconds\" \\\n    \"Check your connection and try: pt update --force\"\n```\n\n## Success Criteria\n- [ ] error_with_fix function implemented\n- [ ] error_with_hint function implemented\n- [ ] Convenience functions for common errors\n- [ ] All actionable errors include remediation\n- [ ] Consistent formatting across all errors","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:40:17.037471047-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:40:17.037471047-05:00","dependencies":[{"issue_id":"process_triage-9jo","depends_on_id":"process_triage-vpb","type":"blocks","created_at":"2026-01-14T22:40:50.714269143-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-9x1","title":"Implement BOCPD for regime change detection","description":"## Task\nImplement Bayesian Online Change-Point Detection for detecting regime shifts.\n\n## Background\nSection 4.7b specifies BOCPD:\n- Run-length recursion with conjugate updates\n- Maintains posterior over change points\n- Detects when process behavior changes significantly\n\n## Use Cases\n- Detect when process went from active to stuck\n- Identify transition points in CPU/IO patterns\n- Detect when process entered bad state\n\n## Algorithm\n1. Maintain run-length distribution r_t\n2. At each time: predict, observe, update\n3. P(r_t | x_{1:t}) ∝ P(x_t | r_t) × [P(r_t | r_{t-1}) × P(r_{t-1} | x_{1:t-1})]\n4. Predict next observation given run length\n\n## Implementation Notes\n- Use conjugate updates for efficiency\n- Hazard function for change-point prior (e.g., geometric)\n- Maintain only recent run lengths (pruning)\n- Optional CTW integration for discrete sequences\n\n## Output Structure\n{\n  \"changepoints\": [\n    {\"time_s\": 1200, \"confidence\": 0.85, \"before\": \"active\", \"after\": \"stalled\"}\n  ],\n  \"current_run_length\": 3600,\n  \"regime_posterior\": {\"active\": 0.1, \"stalled\": 0.9}\n}\n\n## Integration with Core\n- Change-points provide temporal evidence\n- Recent change to bad state increases P(abandoned)\n- Stable run in good state increases P(useful)\n\n## Deliverables\n- Rust module: inference/bocpd.rs\n- Run-length posterior computation\n- Change-point detection\n- Unit tests\n- Documentation","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:27:18.448855138-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:27:18.448855138-05:00"}
{"id":"process_triage-a50","title":"Add 'pt update' command to CLI","description":"## Purpose\nAdd the update command to pt's CLI interface, integrating all the update infrastructure.\n\n## Parent Epic\nSelf-Update Mechanism (process_triage-097)\n\n## Depends On\n- Implement atomic file replacement (final step in chain)\n\n## CLI Interface\n\n### Commands\n```bash\npt update           # Check and install updates\npt update --check   # Check only, don't install\npt update --force   # Update even if on latest version (re-install)\n```\n\n### Help Text Addition\n```\n  update          Check for and install updates\n    --check       Check only, don't install\n    --force       Force re-installation of current version\n```\n\n## Implementation\n\n### Command Handler\n```bash\ncmd_update() {\n    local check_only=false\n    local force=false\n    \n    # Parse arguments\n    while [[ $# -gt 0 ]]; do\n        case \"$1\" in\n            --check|-c)\n                check_only=true\n                shift\n                ;;\n            --force|-f)\n                force=true\n                shift\n                ;;\n            *)\n                log_error \"Unknown option: $1\"\n                return 1\n                ;;\n        esac\n    done\n    \n    show_header\n    \n    log_step \"Checking for updates...\"\n    \n    local latest\n    if latest=$(check_for_update); then\n        log_info \"Update available: ${VERSION} → ${latest}\"\n        \n        if [[ \"$check_only\" == \"true\" ]]; then\n            log_info \"Run 'pt update' to install.\"\n            return 0\n        fi\n        \n        # Confirm update\n        if [[ \"$IS_TTY\" == \"true\" ]]; then\n            if \\! gum_confirm \"Install update?\"; then\n                log_info \"Update cancelled.\"\n                return 0\n            fi\n        fi\n        \n        # Do the update\n        do_update \"$latest\"\n        \n    elif [[ \"$force\" == \"true\" ]]; then\n        log_info \"Forcing re-installation of v${VERSION}\"\n        do_update \"$VERSION\"\n        \n    else\n        log_success \"Already on latest version ($VERSION)\"\n    fi\n}\n```\n\n### Integration in Main\n```bash\nmain() {\n    ensure_gum\n    ensure_config\n    \n    case \"${1:-}\" in\n        run|\"\")      shift 2\u003e/dev/null || true; cmd_run \"$@\" ;;\n        scan)         shift; cmd_scan \"$@\" ;;\n        history)      shift; cmd_history \"$@\" ;;\n        clear)        shift; cmd_clear \"$@\" ;;\n        update)       shift; cmd_update \"$@\" ;;  # ← Add this\n        help|-h|--help)\n            cmd_help\n            ;;\n        version|-v|--version)\n            printf 'pt version %s\\n' \"$VERSION\"\n            ;;\n        *)\n            log_error \"Unknown command: $1\"\n            log_info \"Run 'pt help' for usage.\"\n            exit 1\n            ;;\n    esac\n}\n```\n\n### Update Output Example\n```\n╭─────────────────────────────────────────────╮\n│  Process Triage v1.0.0                      │\n╰─────────────────────────────────────────────╯\n\n→ Checking for updates...\nℹ Update available: 1.0.0 → 1.1.0\n\nInstall update? [Y/n] y\n\n→ Downloading pt v1.1.0...\n✓ Checksum verified: a3f2b8c9d4e5...\n✓ Script validation passed\n→ Installing update...\n✓ Updated to pt v1.1.0\n\nℹ Run 'pt --version' to verify.\n```\n\n## Error Cases\n- Network error: \"Could not check for updates. Check your connection.\"\n- Checksum mismatch: \"Update aborted: checksum verification failed\"\n- Permission denied: \"Cannot write to /path. Try with sudo.\"\n- Syntax invalid: \"Downloaded file failed validation, aborting\"\n\n## Success Criteria\n- [ ] `pt update` checks and installs\n- [ ] `pt update --check` only checks\n- [ ] `pt update --force` re-installs current version\n- [ ] Clear progress messages\n- [ ] Graceful error handling\n- [ ] Non-interactive mode works (no prompts)","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:36:30.202582141-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:36:30.202582141-05:00","dependencies":[{"issue_id":"process_triage-a50","depends_on_id":"process_triage-or6","type":"blocks","created_at":"2026-01-14T22:40:44.705233949-05:00","created_by":"Dicklesworthstone"},{"issue_id":"process_triage-a50","depends_on_id":"process_triage-82j","type":"blocks","created_at":"2026-01-14T22:52:21.603008448-05:00","created_by":"Dicklesworthstone"},{"issue_id":"process_triage-a50","depends_on_id":"process_triage-4ps","type":"blocks","created_at":"2026-01-14T22:52:21.646799818-05:00","created_by":"Dicklesworthstone"},{"issue_id":"process_triage-a50","depends_on_id":"process_triage-3v6","type":"blocks","created_at":"2026-01-14T22:52:21.691273765-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-a6q","title":"Code Organization \u0026 Standards","description":"## Overview\nRefactor pt to follow the code organization and standards patterns established in repo_updater and giil.\n\n## Current State\n- pt is 579 lines with minimal section organization\n- No clear section markers\n- Function naming is inconsistent\n- Exit codes are not well-defined\n- Error messages lack remediation hints\n\n## Target State\nClean, well-organized codebase with:\n1. Clear section markers\n2. Semantic function naming\n3. Defined exit codes\n4. Structured error messages\n5. XDG compliance improvements\n\n## Section Marker Pattern (from repo_updater)\n```bash\n#==============================================================================\n# SECTION 1: VERSION AND CONSTANTS\n#==============================================================================\n\nVERSION=\"1.0.0\"\nGITHUB_REPO=\"Dicklesworthstone/process_triage\"\n\n#------------------------------------------------------------------------------\n# Configuration paths\n#------------------------------------------------------------------------------\n\nCONFIG_DIR=\"${PROCESS_TRIAGE_CONFIG:-${XDG_CONFIG_HOME:-$HOME/.config}/process_triage}\"\n\n#==============================================================================\n# SECTION 2: ANSI COLOR DEFINITIONS\n#==============================================================================\n# ...\n```\n\n## Semantic Function Naming Convention\n| Prefix | Purpose | Example |\n|--------|---------|---------|\n| cmd_* | CLI command handlers | cmd_scan, cmd_run, cmd_update |\n| log_* | Logging functions | log_info, log_error, log_warn |\n| ensure_* | Dependency checks | ensure_gum, ensure_config |\n| format_* | Output formatting | format_duration, format_row |\n| gum_* | Gum wrappers | gum_confirm, gum_choose |\n\n## Exit Code Scheme\n```bash\n# Success\nEXIT_SUCCESS=0\n\n# User/usage errors (1-9)\nEXIT_USAGE_ERROR=1        # Bad CLI arguments\nEXIT_NO_CANDIDATES=2      # No processes to review\n\n# Dependency errors (10-19)\nEXIT_MISSING_GUM=10       # gum not installed and can't auto-install\nEXIT_MISSING_JQ=11        # jq not available (optional, warn only)\n\n# Operation errors (20-29)\nEXIT_KILL_FAILED=20       # Some processes couldn't be killed\nEXIT_PERMISSION=21        # Permission denied\n\n# Update errors (30-39)\nEXIT_UPDATE_FAILED=30     # Self-update failed\nEXIT_CHECKSUM_MISMATCH=31 # Downloaded file failed verification\n\n# Internal errors (90+)\nEXIT_INTERNAL=90          # Bug in pt\n```\n\n## Structured Error Messages (from giil pattern)\n```bash\nerror_with_fix() {\n    local category=\"$1\"\n    local reason=\"$2\"\n    local fix=\"$3\"\n    \n    log_error \"$category\"\n    printf '  Reason: %s\\n' \"$reason\" \u003e\u00262\n    printf '  Fix: %s\\n' \"$fix\" \u003e\u00262\n}\n\n# Usage:\nerror_with_fix \"Permission denied\" \\\n    \"Cannot write to /usr/local/bin\" \\\n    \"Run with sudo or install to ~/.local/bin\"\n```\n\n## XDG Compliance (Current vs Target)\n\n### Current\n```bash\nCONFIG_DIR=\"${PROCESS_TRIAGE_CONFIG:-${XDG_CONFIG_HOME:-$HOME/.config}/process_triage}\"\n```\n\n### Target (more robust)\n```bash\n# Resolve with validation\nresolve_xdg_path() {\n    local var=\"$1\"\n    local default=\"$2\"\n    local value=\"${\\!var:-}\"\n    \n    if [[ -n \"$value\" ]]; then\n        # Validate it's an absolute path\n        if [[ \"$value\" \\!= /* ]]; then\n            log_warn \"$var must be absolute path, using default\"\n            value=\"$default\"\n        fi\n    else\n        value=\"$default\"\n    fi\n    \n    echo \"$value\"\n}\n\nXDG_CONFIG_HOME=\"$(resolve_xdg_path XDG_CONFIG_HOME \"$HOME/.config\")\"\nXDG_STATE_HOME=\"$(resolve_xdg_path XDG_STATE_HOME \"$HOME/.local/state\")\"\nXDG_CACHE_HOME=\"$(resolve_xdg_path XDG_CACHE_HOME \"$HOME/.cache\")\"\n\nCONFIG_DIR=\"$XDG_CONFIG_HOME/process_triage\"\nSTATE_DIR=\"$XDG_STATE_HOME/process_triage\"   # For logs\nCACHE_DIR=\"$XDG_CACHE_HOME/process_triage\"   # For temp files\n```\n\n## set -uo pipefail (NOT set -e)\nFrom repo_updater's rationale:\n```bash\nset -uo pipefail  # NOT set -e because:\n# 1. output=$(failing_cmd); exit_code=$? would exit before capturing exit_code\n# 2. repos must continue processing after individual failures\n# 3. Explicit error handling is more predictable\n```\n\n## Success Criteria\n- [ ] Clear section markers for all code regions\n- [ ] Consistent function naming with semantic prefixes\n- [ ] Defined exit codes for all error conditions\n- [ ] Error messages include remediation hints\n- [ ] Full XDG Base Directory compliance\n- [ ] Code passes ShellCheck with no warnings","status":"open","priority":2,"issue_type":"epic","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:32:45.552785018-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:32:45.552785018-05:00"}
{"id":"process_triage-agz","title":"Define capabilities cache schema","description":"## Task\nSpecify the schema for caching detected system capabilities and tool availability.\n\n## Background\nThe wrapper (pt bash) performs capability discovery and passes results to pt-core. This enables:\n- Core to make decisions based on available tools\n- Graceful degradation when tools are missing\n- User awareness of what's available vs missing\n- Conditional probe selection\n\npt agent capabilities returns:\n- Platform info (OS, kernel, container status)\n- Data sources (procfs, sysfs, perf, eBPF, etc.)\n- Supervisors detected (systemd, launchd, pm2, Docker)\n- Available actions (kill, pause, renice, cgroup ops)\n- Permission level (own user, sudo, root)\n- Resource limits (overhead budget, probe limits)\n- Feature flags (galaxy-brain, community signatures)\n\n## Deliverables\n- JSON schema for capabilities cache\n- Detection protocol for each capability\n- Version information for detected tools\n- Safe fallbacks when tools missing\n- Refresh/invalidation strategy\n- Per-action capability requirements\n\n## Technical Considerations\n- Cache location: ~/.cache/pt/capabilities.json\n- Include detection timestamp for staleness\n- Some capabilities are runtime-dependent (sudo may work sometimes)\n- Container detection affects many capabilities\n- macOS SIP affects tracing capabilities","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:22:33.600415656-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:22:33.600415656-05:00"}
{"id":"process_triage-aip","title":"Release Automation with Checksums","description":"## Overview\nImplement automated release workflow that generates checksums and creates GitHub releases with all artifacts.\n\n## Current State\n- No release automation\n- No checksums generated\n- Manual release process (if any)\n- No verification infrastructure for users\n\n## Target State\nAutomated release on git tag push:\n```bash\ngit tag v1.1.0\ngit push origin v1.1.0\n# → GitHub Action creates release with all artifacts\n```\n\n## release.yml Structure\n\n### Trigger\n```yaml\non:\n  push:\n    tags:\n      - 'v*'  # Triggers on v1.0.0, v1.2.3, etc.\n```\n\n### Steps\n\n#### 1. Version Validation\n```yaml\n- name: Validate version\n  run: |\n    tag_version=${GITHUB_REF#refs/tags/v}\n    script_version=$(grep '^VERSION=' pt | cut -d= -f2 | tr -d '\"')\n    if [[ \"$tag_version\" \\!= \"$script_version\" ]]; then\n      echo \"Tag ($tag_version) doesn't match script ($script_version)\"\n      exit 1\n    fi\n```\n\n#### 2. Checksum Generation\n```yaml\n- name: Generate checksums\n  run: |\n    sha256sum pt install.sh \u003e checksums.sha256\n    sha256sum pt \u003e pt.sha256\n    sha256sum install.sh \u003e install.sh.sha256\n    cat checksums.sha256\n```\n\n#### 3. Create Release\n```yaml\n- name: Create GitHub Release\n  uses: softprops/action-gh-release@v1\n  with:\n    files: |\n      pt\n      install.sh\n      checksums.sha256\n      pt.sha256\n      install.sh.sha256\n    body: |\n      ## Installation\n      \\`\\`\\`bash\n      curl -fsSL https://raw.githubusercontent.com/.../install.sh | bash\n      \\`\\`\\`\n      \n      ## Verification\n      \\`\\`\\`bash\n      echo \"$(curl -fsSL .../pt.sha256)  pt\" | sha256sum -c -\n      \\`\\`\\`\n```\n\n## Release Artifacts\n| File | Purpose |\n|------|---------|\n| pt | Main executable |\n| install.sh | Installation script |\n| checksums.sha256 | All checksums in one file |\n| pt.sha256 | Just pt checksum (for install.sh) |\n| install.sh.sha256 | Just installer checksum |\n\n## Why Individual Checksum Files?\n- **pt.sha256**: Used by install.sh for verification\n- **install.sh.sha256**: For users who want to verify installer\n- **checksums.sha256**: Combined file for convenience\n\n## Security Considerations\n- Checksums are generated in CI (not locally) for reproducibility\n- Tag must match script version (prevents accidental releases)\n- Users can verify before running: `curl ... | sha256sum -c -`\n\n## Success Criteria\n- [ ] Tags trigger release workflow\n- [ ] Version mismatch blocks release\n- [ ] All artifacts are uploaded\n- [ ] Checksums are correct and verifiable\n- [ ] Release notes include install/verify instructions","status":"open","priority":1,"issue_type":"epic","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:32:44.230616595-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:32:44.230616595-05:00"}
{"id":"process_triage-b9x","title":"Create bundled signature library (50+ processes)","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:34:58.359408421-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:34:58.359408421-05:00"}
{"id":"process_triage-bg5","title":"Create policy.json schema for loss matrix and guardrails","description":"## Task\nDefine the JSON schema for policy.json which contains the decision-theoretic loss matrix and safety guardrails.\n\n## Background\nSection 5.1 specifies the loss matrix:\n- useful: keep=0, kill=100\n- useful-but-bad: keep=10, kill=20\n- abandoned: keep=30, kill=1\n- zombie: keep=50, kill=1\n\nBut policy.json is broader - it defines:\n1. Loss matrix for all actions (keep, pause, throttle, kill)\n2. Safety guardrails (protected processes, rate limits)\n3. Robot mode gates (min posterior, max blast radius, etc.)\n4. FDR/alpha-investing parameters\n5. Data-loss gate rules (open write handles)\n\n## Deliverables\n- JSON Schema for policy.json\n- Default policy with conservative values\n- Loss matrix specification\n- Guardrail specification (protected patterns, denylists)\n- Robot mode parameters specification\n- FDR control parameters\n\n## Technical Considerations\n- Loss values should be interpretable (not arbitrary magic numbers)\n- Guardrails must be regex-capable for process matching\n- Robot mode gates must be independently configurable\n- Support policy inheritance (org policy + user overrides)\n\n## Example Structure\n{\n  \"schema_version\": \"1.0\",\n  \"loss_matrix\": {\n    \"useful\": {\"keep\": 0, \"pause\": 5, \"throttle\": 8, \"kill\": 100},\n    ...\n  },\n  \"guardrails\": {\n    \"protected_patterns\": [\"systemd\", \"sshd\", \"init\", ...],\n    \"never_kill_ppid\": [1],\n    \"max_kills_per_run\": 10\n  },\n  \"robot_mode\": {\n    \"min_posterior\": 0.95,\n    \"max_blast_radius_mb\": 4096,\n    \"require_known_signature\": false,\n    \"fdr_alpha\": 0.05\n  }\n}","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:20:58.606639601-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:20:58.606639601-05:00"}
{"id":"process_triage-bgd","title":"Expanded Test Coverage","description":"## Overview\nSignificantly expand the BATS test suite to cover all major functionality and match the testing standards of repo_updater (70+ tests).\n\n## Current State\n- Only 8 basic tests in test/pt.bats\n- Tests cover: help, version, unknown command, scan, history, clear\n- NO tests for: scoring system, pattern normalization, decision memory, kill logic\n- No TAP output support documented\n- No mock injection patterns\n\n## Target State\nComprehensive test suite covering:\n1. **Unit tests**: Individual function testing\n2. **Integration tests**: Feature interaction testing\n3. **E2E tests**: Full workflow testing\n\n## Test Categories to Add\n\n### 1. Scoring System Tests\n```bash\n@test \"score_process: age \u003e 1 week gets +50\" {\n    # Test the scoring heuristics\n}\n\n@test \"score_process: orphaned process (PPID=1) gets +25\" {\n    # Test orphan detection\n}\n\n@test \"score_process: stuck test runner gets +40\" {\n    # Test pattern matching for bun test, jest, pytest\n}\n\n@test \"score_process: system service gets -200 (protected)\" {\n    # Test protection mechanism\n}\n```\n\n### 2. Pattern Normalization Tests\n```bash\n@test \"normalize_pattern: removes PIDs\" {\n    result=$(normalize_pattern \"node 12345 server.js\")\n    [[ \"$result\" != *\"12345\"* ]]\n}\n\n@test \"normalize_pattern: normalizes ports\" {\n    result=$(normalize_pattern \"--port=3000\")\n    [[ \"$result\" == *\"--port=PORT\"* ]]\n}\n\n@test \"normalize_pattern: normalizes UUIDs\" {\n    result=$(normalize_pattern \"abc-550e8400-e29b-41d4-a716-446655440000-xyz\")\n    [[ \"$result\" == *\"UUID\"* ]]\n}\n```\n\n### 3. Decision Memory Tests\n```bash\n@test \"save_decision: creates valid JSON\" {\n    save_decision \"kill\" \"test pattern\"\n    jq -e '.\"test pattern\"' \"$CONFIG_DIR/decisions.json\"\n}\n\n@test \"get_cached_decision: returns saved decision\" {\n    save_decision \"spare\" \"gunicorn\"\n    result=$(get_cached_decision \"gunicorn\")\n    [[ \"$result\" == \"spare\" ]]\n}\n```\n\n### 4. Process Collection Tests\n```bash\n@test \"collect_candidates: filters by minimum age\" {\n    # Mock ps output and verify filtering\n}\n\n@test \"collect_candidates: excludes system services\" {\n    # Verify systemd, sshd, etc. are excluded\n}\n```\n\n## Mock Injection Pattern (from repo_updater)\n```bash\nsetup() {\n    TEST_DIR=\"$(mktemp -d)\"\n    mkdir -p \"$TEST_DIR/mock_bin\"\n    \n    # Create mock ps command\n    cat \u003e \"$TEST_DIR/mock_bin/ps\" \u003c\u003c 'EOF'\n#!/bin/bash\necho \"12345|1|100000|512|bun test --watch\"\necho \"23456|1000|200000|1024|next dev\"\nEOF\n    chmod +x \"$TEST_DIR/mock_bin/ps\"\n}\n\n@test \"scoring with mocked ps\" {\n    PATH=\"$TEST_DIR/mock_bin:$PATH\" run pt scan\n    # Verify output\n}\n```\n\n## TAP Output Support\n```bash\n# Run with TAP output for CI\nbats --tap test/pt.bats\n\n# Example TAP output:\n# 1..8\n# ok 1 pt --help shows usage\n# ok 2 pt help shows usage\n# ...\n```\n\n## Conditional Skips\n```bash\n@test \"interactive mode requires gum\" {\n    if ! command -v gum \u0026\u003e/dev/null; then\n        skip \"gum not installed\"\n    fi\n    # Test interactive features\n}\n```\n\n## Test File Organization\n```\ntest/\n├── pt.bats              # Main test file (expanded)\n├── test_scoring.bats    # Scoring system tests\n├── test_patterns.bats   # Pattern normalization tests\n├── test_memory.bats     # Decision memory tests\n├── test_commands.bats   # CLI command tests\n└── test_helper/\n    └── common.bash      # Shared setup/teardown\n```\n\n## Success Criteria\n- [ ] 30+ tests covering all major functionality\n- [ ] All scoring heuristics have test coverage\n- [ ] Pattern normalization is thoroughly tested\n- [ ] Decision memory persistence is tested\n- [ ] Mock injection enables isolated testing\n- [ ] Tests pass on both Linux and macOS","status":"open","priority":2,"issue_type":"epic","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:32:44.489765064-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:32:44.489765064-05:00"}
{"id":"process_triage-bxx","title":"Implement network connection collection","description":"## Task\nImplement collection of network connection information per process.\n\n## Background\nNetwork connections provide evidence about process state:\n- Active connections suggest useful work\n- Many ESTABLISHED connections increase kill cost\n- Listening ports have dependents\n- Connection state changes over time\n\n## Data to Collect\nPer process:\n- Socket count (TCP, UDP, Unix)\n- Connection states (ESTABLISHED, LISTEN, TIME_WAIT, etc.)\n- Local/remote addresses and ports\n- Socket backlog (for listening sockets)\n- Bytes sent/received (if available)\n\n## Tools\n**Linux**:\n- ss (preferred, faster than netstat)\n- lsof -i (fallback)\n- /proc/net/tcp, /proc/net/udp (raw)\n- nethogs (per-process bandwidth)\n\n**macOS**:\n- netstat -p tcp\n- lsof -i\n- nettop (bandwidth)\n\n## Implementation Notes\n- Parse ss/netstat output efficiently\n- Join with PID information\n- Handle missing pid for some connections\n- Consider sampling for high-frequency data\n\n## Output Structure\n{\n  \"pid\": 1234,\n  \"connections\": [\n    {\"proto\": \"tcp\", \"state\": \"ESTABLISHED\", \"local\": \"10.0.0.1:8080\", \"remote\": \"10.0.0.2:54321\"}\n  ],\n  \"listen_ports\": [8080, 443],\n  \"socket_count\": {\"tcp\": 5, \"udp\": 1, \"unix\": 3}\n}\n\n## Deliverables\n- Rust module: collect/network.rs\n- Platform-specific parsers\n- Unit tests\n- Documentation","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:26:04.474195663-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:26:04.474195663-05:00"}
{"id":"process_triage-c57","title":"Add cross-platform mktemp and download functions","description":"## Purpose\nImplement cross-platform utilities for temp directories and file downloads that work on both Linux and macOS.\n\n## Parent Epic\nInstallation Infrastructure (process_triage-n0r)\n\n## Depends On\n- Create install.sh with self-refresh mechanism\n\n## Cross-Platform mktemp\n\n### The Problem\n```bash\n# GNU mktemp (Linux) - works\nmktemp -d\n\n# BSD mktemp (macOS) - requires template\nmktemp -d          # May fail\nmktemp -d -t name  # Works\n```\n\n### Solution\n```bash\nmktemp_dir() {\n    local dir\n    \n    # Try GNU style first (Linux)\n    dir=$(mktemp -d 2\u003e/dev/null) \u0026\u0026 { echo \"$dir\"; return 0; }\n    \n    # BSD style with -t (macOS)\n    dir=$(mktemp -d -t pt 2\u003e/dev/null) \u0026\u0026 { echo \"$dir\"; return 0; }\n    \n    # BSD style with explicit template\n    dir=$(mktemp -d -t pt.XXXXXXXXXX 2\u003e/dev/null) \u0026\u0026 { echo \"$dir\"; return 0; }\n    \n    # Manual fallback\n    dir=\"/tmp/pt.$$.$(date +%s)\"\n    mkdir -p \"$dir\" \u0026\u0026 { echo \"$dir\"; return 0; }\n    \n    log_error \"Failed to create temporary directory\"\n    return 1\n}\n```\n\n## Download Function\n\n### Support Both curl and wget\n```bash\ndownload() {\n    local url=\"$1\"\n    local output=\"$2\"\n    \n    if command -v curl \u0026\u003e/dev/null; then\n        curl -fsSL --connect-timeout 10 --max-time 120 \"$url\" -o \"$output\"\n    elif command -v wget \u0026\u003e/dev/null; then\n        wget -q --timeout=10 -O \"$output\" \"$url\"\n    else\n        log_error \"Neither curl nor wget available\"\n        log_error \"Install curl: apt install curl (or brew install curl)\"\n        return 1\n    fi\n}\n```\n\n### Download with Progress (Optional)\n```bash\ndownload_with_progress() {\n    local url=\"$1\"\n    local output=\"$2\"\n    local description=\"${3:-Downloading}\"\n    \n    if [[ \"$GUM_AVAILABLE\" == \"true\" ]]; then\n        gum spin --spinner dot --title \"$description\" -- \\\n            curl -fsSL \"$url\" -o \"$output\"\n    else\n        log_step \"$description\"\n        download \"$url\" \"$output\"\n    fi\n}\n```\n\n## Cache-Busting\n\n### The Problem\nCDNs cache files. Fresh releases may not be immediately available.\n\n### Solution\n```bash\nappend_cache_buster() {\n    local url=\"$1\"\n    local timestamp=$(date +%s)\n    \n    if [[ \"$url\" == *\"?\"* ]]; then\n        echo \"${url}\u0026cb=${timestamp}\"\n    else\n        echo \"${url}?cb=${timestamp}\"\n    fi\n}\n\n# Usage\ndownload \"$(append_cache_buster \"$SCRIPT_URL\")\" \"$temp_file\"\n```\n\n## SHA256 Cross-Platform\n\n```bash\nsha256_file() {\n    local file=\"$1\"\n    \n    if command -v sha256sum \u0026\u003e/dev/null; then\n        sha256sum \"$file\" | cut -d' ' -f1\n    elif command -v shasum \u0026\u003e/dev/null; then\n        shasum -a 256 \"$file\" | cut -d' ' -f1\n    elif command -v openssl \u0026\u003e/dev/null; then\n        openssl dgst -sha256 \"$file\" | awk '{print $2}'\n    else\n        log_warn \"No SHA256 tool available\"\n        return 1\n    fi\n}\n```\n\n## Success Criteria\n- [ ] mktemp_dir works on Linux and macOS\n- [ ] download supports curl and wget\n- [ ] Cache-busting prevents stale downloads\n- [ ] SHA256 works on all platforms\n- [ ] Clear errors when tools unavailable","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:36:32.273129077-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:36:32.273129077-05:00","dependencies":[{"issue_id":"process_triage-c57","depends_on_id":"process_triage-ume","type":"blocks","created_at":"2026-01-14T22:40:45.41003931-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-ch7","title":"Add ANSI fallback when gum unavailable","description":"## Purpose\nImplement ANSI-based fallback UI when gum is not installed, ensuring pt works everywhere while looking best where possible.\n\n## Parent Epic\nConsole Output Styling Enhancement (process_triage-y8e)\n\n## Depends On\n- Add TTY detection and NO_COLOR support\n- Implement log_* functions with emoji prefixes\n\n## Current State\npt calls `ensure_gum()` which auto-installs gum. If installation fails:\n- Script exits with error\n- No graceful degradation\n\n## Target Behavior\n1. Try to use gum if available\n2. Fall back to ANSI if gum unavailable\n3. Fall back to plain text if no TTY\n\n## Implementation\n\n### 1. Wrapper Functions for Gum Features\n\n#### gum_style (banners, styled text)\n```bash\ngum_style() {\n    local text=\"$1\"\n    local border=\"${2:-rounded}\"\n    local color=\"${3:-212}\"\n    \n    if [[ \"$GUM_AVAILABLE\" == \"true\" ]]; then\n        gum style --border \"$border\" --border-foreground \"$color\" --padding \"0 2\" \"$text\"\n    else\n        # ANSI fallback - simple box\n        local width=$(( ${#text} + 4 ))\n        local border_line=\"$(printf '─%.0s' $(seq 1 $width))\"\n        printf '%b\\n' \"${MAGENTA}╭${border_line}╮${RESET}\"\n        printf '%b\\n' \"${MAGENTA}│${RESET}  $text  ${MAGENTA}│${RESET}\"\n        printf '%b\\n' \"${MAGENTA}╰${border_line}╯${RESET}\"\n    fi\n}\n```\n\n#### gum_confirm (yes/no prompts)\n```bash\ngum_confirm() {\n    local prompt=\"$1\"\n    local default=\"${2:-true}\"\n    \n    if [[ \"$GUM_AVAILABLE\" == \"true\" ]]; then\n        gum confirm \"$prompt\"\n        return $?\n    else\n        # ANSI fallback\n        local yn_prompt\n        if [[ \"$default\" == \"true\" ]]; then\n            yn_prompt=\"[Y/n]\"\n        else\n            yn_prompt=\"[y/N]\"\n        fi\n        \n        printf '%s %s ' \"$prompt\" \"$yn_prompt\" \u003e\u00262\n        local response\n        read -r response\n        \n        case \"${response,,}\" in\n            y|yes) return 0 ;;\n            n|no)  return 1 ;;\n            \"\")    [[ \"$default\" == \"true\" ]] \u0026\u0026 return 0 || return 1 ;;\n            *)     return 1 ;;\n        esac\n    fi\n}\n```\n\n#### gum_choose (multi-select)\n```bash\ngum_choose() {\n    local -a items=(\"$@\")\n    \n    if [[ \"$GUM_AVAILABLE\" == \"true\" ]]; then\n        printf '%s\\n' \"${items[@]}\" | gum choose --no-limit\n    else\n        # ANSI fallback - numbered list with manual selection\n        log_info \"Select items (space-separated numbers, or 'all'):\"\n        local i=1\n        for item in \"${items[@]}\"; do\n            printf '  %d) %s\\n' \"$i\" \"$item\" \u003e\u00262\n            ((i++))\n        done\n        \n        printf 'Selection: ' \u003e\u00262\n        local selection\n        read -r selection\n        \n        if [[ \"$selection\" == \"all\" ]]; then\n            printf '%s\\n' \"${items[@]}\"\n        else\n            for num in $selection; do\n                if [[ \"$num\" =~ ^[0-9]+$ ]] \u0026\u0026 (( num \u003e= 1 \u0026\u0026 num \u003c= ${#items[@]} )); then\n                    printf '%s\\n' \"${items[num-1]}\"\n                fi\n            done\n        fi\n    fi\n}\n```\n\n#### gum_spin (spinners)\n```bash\ngum_spin() {\n    local title=\"$1\"\n    shift\n    \n    if [[ \"$GUM_AVAILABLE\" == \"true\" ]]; then\n        gum spin --spinner dot --title \"$title\" -- \"$@\"\n    else\n        # ANSI fallback - just show message and run command\n        log_step \"$title\"\n        \"$@\"\n    fi\n}\n```\n\n### 2. Update ensure_gum() to be Optional\n```bash\nensure_gum() {\n    if command -v gum \u0026\u003e/dev/null; then\n        GUM_AVAILABLE=true\n        return 0\n    fi\n    \n    # Try to install, but don't fail if we can't\n    log_info \"gum not found, attempting to install for better UI...\"\n    \n    if install_gum 2\u003e/dev/null; then\n        GUM_AVAILABLE=true\n        log_success \"gum installed successfully\"\n    else\n        GUM_AVAILABLE=false\n        log_warn \"Could not install gum, using fallback UI\"\n    fi\n}\n```\n\n## Success Criteria\n- [ ] All gum features have ANSI fallbacks\n- [ ] pt works without gum installed\n- [ ] Fallback UI is functional (not just pretty)\n- [ ] Multi-select works in fallback mode\n- [ ] Confirmation prompts work in fallback mode","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:35:01.321160838-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:35:01.321160838-05:00","dependencies":[{"issue_id":"process_triage-ch7","depends_on_id":"process_triage-18z","type":"blocks","created_at":"2026-01-14T22:40:43.739406679-05:00","created_by":"Dicklesworthstone"},{"issue_id":"process_triage-ch7","depends_on_id":"process_triage-vpb","type":"blocks","created_at":"2026-01-14T22:40:43.772309983-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-cki","title":"Implement deep scan via /proc inspection","description":"## Task\nImplement deep scan that extracts detailed per-process information from /proc filesystem.\n\n## Background\nDeep scan provides richer evidence than quick scan:\n- IO statistics (read/write bytes, syscalls)\n- Scheduler statistics (wait time, run time)\n- Memory details (shared, private, swap)\n- File descriptors (count, types, open files)\n- Network connections (sockets, states)\n- Environment variables (when permitted)\n- Wait channel (wchan)\n- Cgroup membership\n\n## Data Sources\n- /proc/[pid]/io: read_bytes, write_bytes, syscr, syscw\n- /proc/[pid]/schedstat: run_time, wait_time, timeslices\n- /proc/[pid]/sched: nr_switches, nr_voluntary_switches\n- /proc/[pid]/statm: shared, text, data pages\n- /proc/[pid]/fd/: file descriptor enumeration\n- /proc/[pid]/net/: network namespace info\n- /proc/[pid]/wchan: wait channel (what's blocking)\n- /proc/[pid]/cgroup: cgroup membership\n- /proc/[pid]/environ: environment (with permission)\n\n## Implementation Notes\n- Read files with timeout (hung /proc reads are possible)\n- Handle permission denied gracefully\n- Parse each file type correctly\n- Batch reads for efficiency\n- Consider sampling interval for deltas\n\n## Platform Considerations\n- Linux-only (macOS has no /proc)\n- Container visibility varies\n- Some files require CAP_SYS_PTRACE\n\n## Test Cases\n- Parse known /proc files correctly\n- Handle missing/permission-denied files\n- Performance: \u003c100ms per process\n\n## Deliverables\n- Rust module: collect/deep_scan.rs\n- Per-file parsers: collect/proc_parsers.rs\n- Unit tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:24:59.194422138-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:24:59.194422138-05:00"}
{"id":"process_triage-cpm","title":"Implement alpha-investing online safety budget","description":"## Task\nImplement alpha-investing for long-term FDR safety across repeated scans.\n\n## Background\nSection 4.40 and 5.11 specify alpha-investing:\n- Maintain error budget over time\n- Spend budget on high-confidence kills\n- Replenish on discoveries\n\nWealth update:\nW_i = W_{i-1} - α_i + ω (if discovery)\nW_i = W_{i-1} - α_i (otherwise)\n\n## Purpose\n- Prevent error accumulation from repeated scans\n- Allow aggressive action when evidence is strong\n- Provide formal long-run FDR bound\n\n## Implementation Notes\n- Initialize wealth W_0 from policy\n- Choose α_i ≤ W_{i-1} based on evidence strength\n- Track wealth across sessions\n- Never allow W \u003c 0 (clamp)\n- Persist wealth state for continuity\n\n## Integration with e-Values\n- Use e-processes for sequential evidence\n- Update wealth with e-FDR control\n- Optional stopping remains valid\n\n## Output Structure\n{\n  \"alpha_investing\": {\n    \"W_prev\": 0.12,\n    \"alpha_spend\": 0.01,\n    \"omega_reward\": 0.03,\n    \"W_next\": 0.14,\n    \"budget_state\": \"healthy\"\n  }\n}\n\n## Galaxy-Brain Card\nalpha_investing card shows wealth update equation and current state\n\n## Deliverables\n- Rust module: decision/alpha_invest.rs\n- Wealth persistence across sessions\n- Spend policy\n- Unit tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:29:16.042128794-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:29:16.042128794-05:00"}
{"id":"process_triage-cr2","title":"Implement file descriptor collection","description":"## Task\nImplement collection of file descriptor information per process.\n\n## Background\nFile descriptors reveal:\n- What files are open (data-loss risk)\n- Database connections (sqlite WAL, etc.)\n- Lock files held\n- Pipes and communication channels\n- Open write handles (critical for safety gates)\n\n## Data to Collect\nPer process:\n- FD count (total, by type)\n- Open files (paths, modes)\n- Pipes (connected processes)\n- Sockets (type, state)\n- Special: sqlite WAL/journal, git locks, package manager locks\n\n## Data Sources\n**Linux**:\n- /proc/[pid]/fd/ (symlinks)\n- /proc/[pid]/fdinfo/ (detailed info)\n- lsof (richer but slower)\n\n**macOS**:\n- lsof -p [pid]\n\n## Implementation Notes\n- Reading /proc/[pid]/fd requires permissions\n- Symlink resolution for actual paths\n- Pattern matching for critical files:\n  - *.sqlite-wal, *.sqlite-journal\n  - .git/index.lock, .git/*.lock\n  - /var/lib/dpkg/lock, /var/cache/apt/archives/lock\n- Separate 'open for write' FDs (critical for safety)\n\n## Output Structure\n{\n  \"pid\": 1234,\n  \"fd_count\": 47,\n  \"fd_by_type\": {\"regular\": 10, \"socket\": 20, \"pipe\": 5, \"other\": 12},\n  \"open_files\": [{\"path\": \"/tmp/data.db\", \"mode\": \"rw\"}],\n  \"critical_open_writes\": [{\"path\": \"/tmp/data.db-wal\", \"type\": \"sqlite_wal\"}]\n}\n\n## Deliverables\n- Rust module: collect/fd.rs\n- Critical file pattern database\n- Unit tests\n- Documentation","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:26:05.653819181-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:26:05.653819181-05:00"}
{"id":"process_triage-ctb","title":"Implement risk-sensitive control (CVaR)","description":"## Task\nImplement risk-sensitive decision making using CVaR.\n\n## Background\nSection 5.1 specifies:\n- Replace E[L] with coherent risk measure\n- CVaR penalizes tail outcomes\n- Prevents rare catastrophic false kills\n\n## CVaR Definition\nCVaR_α(L) = min_η { η + (1/(1-α)) E[(L-η)_+] }\n\nAt α=0.95, this is the expected loss in the worst 5% of cases.\n\n## Purpose\n- Protect against rare but catastrophic errors\n- More conservative than expected value\n- Essential for --robot mode\n\n## Implementation Notes\n- Compute posterior distribution of loss\n- Find CVaR via optimization or closed-form\n- Use CVaR instead of E[L] when risk-sensitive\n- Log adjustment for transparency\n\n## When to Apply\n- Robot mode (always)\n- Low confidence decisions\n- High blast radius candidates\n- Policy configuration\n\n## Output Structure\n{\n  \"risk_sensitive\": {\n    \"expected_loss\": 6.4,\n    \"cvar_95\": 25.2,\n    \"risk_adjusted_action\": \"review\",\n    \"reason\": \"High CVaR despite low expected loss\"\n  }\n}\n\n## Deliverables\n- Rust module: decision/cvar.rs\n- CVaR computation\n- Risk-adjusted decisions\n- Unit tests\n- Documentation","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:29:19.02146516-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:29:19.02146516-05:00"}
{"id":"process_triage-d31","title":"Implement quick scan via ps parsing","description":"## Task\nImplement the quick scan that collects basic process information via ps.\n\n## Background\nQuick scan is the first stage of evidence collection:\n- Fast (\u003c1s)\n- Low overhead\n- Available everywhere (ps is universal)\n- Provides enough for initial classification\n\n## Data to Collect\nPer process:\n- pid, ppid, uid, user\n- comm, cmd (full command line)\n- state (R, S, D, Z, T)\n- cpu% (instantaneous)\n- rss (resident set size)\n- vsz (virtual size)\n- tty (controlling terminal)\n- start_time (for start_id computation)\n- etimes (elapsed time in seconds)\n\n## Implementation Notes\n- Use ps with custom format string for efficiency\n- Parse output into structured records\n- Compute start_id from start_time (epoch.pid format)\n- Handle command line truncation\n- Normalize whitespace in commands\n\n## Platform Considerations\n- Linux: ps from procps-ng\n- macOS: BSD ps with slightly different options\n- Detect platform and adjust format string\n\n## Test Cases\n- Parse known ps output correctly\n- Handle edge cases (no tty, zombie state)\n- Performance: \u003c1s for 1000 processes\n\n## Deliverables\n- Rust module: collect/quick_scan.rs\n- Platform-specific ps format strings\n- Unit tests with sample ps output\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:24:33.449059895-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:24:33.449059895-05:00"}
{"id":"process_triage-d7s","title":"Implement belief propagation on PPID trees","description":"## Task\nImplement exact belief propagation for coupled inference on process trees.\n\n## Background\nSection 4.37 specifies belief propagation:\n- PPID relationships form a forest (tree per init-rooted subtree)\n- Process states may be correlated (parent stuck → children stuck)\n- Sum-product message passing yields exact marginals on trees\n\n## Coupled Prior\nP(S_u, S_v) ∝ exp(J × 1{S_u = S_v})\n\nWhen J \u003e 0, adjacent processes prefer same state. This captures:\n- Process group stuck together\n- Worker pool all abandoned\n\n## Algorithm\n1. Build PPID forest from process list\n2. Root each tree at init (PID 1) descendants\n3. Pass messages from leaves to roots\n4. Pass messages from roots to leaves\n5. Compute marginals from incoming messages\n\n## Implementation Notes\n- Use log-domain for numerical stability\n- Handle single-node trees (no coupling)\n- Cache messages for efficiency\n- Consider non-tree couplings (loopy BP) later\n\n## Output Structure\n{\n  \"tree_inference\": {\n    \"trees\": [{\"root\": 1234, \"nodes\": [1234, 2345, 3456]}],\n    \"coupled_posteriors\": {\n      \"1234\": {\"abandoned\": 0.9, ...},\n      \"2345\": {\"abandoned\": 0.85, ...}\n    }\n  }\n}\n\n## Deliverables\n- Rust module: inference/belief_prop.rs\n- Tree construction from PPID\n- Message passing algorithm\n- Unit tests\n- Documentation","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:27:45.375444602-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:27:45.375444602-05:00"}
{"id":"process_triage-d88","title":"Implement expected loss computation and SPRT threshold","description":"## Task\nImplement expected loss decision and SPRT-style kill threshold.\n\n## Background\nSection 5.1-5.2 specify:\na* = argmin_a Σ_C L(a,C) P(C|x)\n\nLoss matrix from plan:\n- useful: keep=0, kill=100\n- useful-but-bad: keep=10, kill=20\n- abandoned: keep=30, kill=1\n- zombie: keep=50, kill=1\n\nSPRT threshold (Section 5.2):\nkill if log[P(abandoned|x)/P(useful|x)] \u003e log[(L(kill,useful)-L(keep,useful))/(L(keep,abandoned)-L(kill,abandoned))]\n\n## Implementation Notes\n- Load loss matrix from policy.json\n- Compute expected loss per action\n- Find minimum-loss action\n- Compute SPRT threshold from loss matrix\n- Compare posterior odds to threshold\n\n## Actions to Consider\n- keep: do nothing\n- pause: SIGSTOP + observe\n- throttle: cgroup CPU limit\n- kill: SIGTERM → SIGKILL\n\n## Output Structure\n{\n  \"expected_loss\": {\"keep\": 28.2, \"pause\": 15.1, \"throttle\": 12.3, \"kill\": 6.4},\n  \"optimal_action\": \"kill\",\n  \"sprt_threshold\": 0.9,\n  \"posterior_odds\": 31.3,\n  \"threshold_crossed\": true\n}\n\n## Deliverables\n- Rust module: decision/expected_loss.rs\n- Loss matrix loading\n- SPRT threshold computation\n- Unit tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:28:41.768671314-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:28:41.768671314-05:00"}
{"id":"process_triage-dj9","title":"Implement responsive TUI layout system","description":"## Overview\nBuild a responsive TUI layout system that adapts to terminal dimensions.\n\n## Background\nThe plan specifies a premium TUI experience with multiple panels: process list, evidence detail, action preview, and status bar. This must work in terminals from 80x24 to ultra-wide displays.\n\n## Why It Matters\nUsers run pt in varied environments: tiny SSH sessions, tmux panes, full-screen terminals. A responsive layout ensures information is accessible regardless of terminal size, without horizontal scrolling or truncation that loses critical data.\n\n## Technical Approach\n1. Implement layout engine with flexible panel sizing\n2. Define breakpoints (minimal, compact, standard, wide)\n3. Support panel collapse/expand based on space\n4. Maintain readable minimum widths\n5. Use Ratatui's constraint-based layout system\n\n## Layout Modes\n- **Minimal (80x24)**: Single panel, tab navigation\n- **Compact (120x30)**: Process list + detail split\n- **Standard (160x40)**: Three-panel layout\n- **Wide (200+)**: Full layout with side panels\n\n## Panel Priority (when space constrained)\n1. Process list (always visible, minimum 40 cols)\n2. Status bar (always visible, 1 row)\n3. Evidence summary (collapse to icons if needed)\n4. Action preview (hide in minimal mode)\n5. Galaxy-brain panel (wide mode only)\n\n## Responsive Behaviors\n- Text truncation with ellipsis\n- Column hiding based on width\n- Row consolidation for height\n- Scroll indicators when content exceeds view\n\n## Success Criteria\n- Layout adapts smoothly to resize\n- No horizontal scrolling required\n- All modes functional and usable\n- Transitions between modes clean","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:32:05.86241288-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:32:50.642350528-05:00"}
{"id":"process_triage-dna","title":"Add version consistency check to CI","description":"## Purpose\nAdd a CI job that verifies the VERSION file matches the VERSION constant in the pt script.\n\n## Parent Epic\nGitHub Actions CI/CD Pipeline (process_triage-68c)\n\n## Depends On\n- Create VERSION file as single source of truth\n\n## Why This Check?\nCommon release bug: update VERSION file but forget to update script (or vice versa).\n- CI catches this before merge\n- Release workflow also checks this before publishing\n\n## Implementation\n\n### Add to ci.yml\n```yaml\n  version-check:\n    name: Version Consistency\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      \n      - name: Check VERSION file exists\n        run: |\n          if [[ \\! -f VERSION ]]; then\n            echo \"::error::VERSION file not found\"\n            exit 1\n          fi\n      \n      - name: Verify version consistency\n        run: |\n          file_version=$(cat VERSION | tr -d '\\n')\n          script_version=$(grep '^VERSION=' pt | head -1 | cut -d'\"' -f2)\n          \n          echo \"VERSION file: $file_version\"\n          echo \"pt script:    $script_version\"\n          \n          if [[ \"$file_version\" \\!= \"$script_version\" ]]; then\n            echo \"\"\n            echo \"::error::Version mismatch\\!\"\n            echo \"VERSION file contains: $file_version\"\n            echo \"pt script contains:    $script_version\"\n            echo \"\"\n            echo \"Please update both to match.\"\n            exit 1\n          fi\n          \n          echo \"✓ Versions match: $file_version\"\n      \n      - name: Validate version format\n        run: |\n          version=$(cat VERSION | tr -d '\\n')\n          \n          # Check semver format (X.Y.Z)\n          if [[ \\! \"$version\" =~ ^[0-9]+\\.[0-9]+\\.[0-9]+$ ]]; then\n            echo \"::error::Invalid version format: $version\"\n            echo \"Expected: X.Y.Z (e.g., 1.2.3)\"\n            exit 1\n          fi\n          \n          echo \"✓ Version format valid: $version\"\n```\n\n## Error Output\nGitHub Actions `::error::` syntax creates annotations visible in PR UI:\n- Red error badge\n- Clickable link to the check\n- Clear message about what's wrong\n\n## Success Criteria\n- [ ] Job checks VERSION file exists\n- [ ] Job compares VERSION file to script constant\n- [ ] Job validates semver format\n- [ ] Clear error messages on mismatch\n- [ ] PR blocked if versions don't match","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:37:32.920319677-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:37:32.920319677-05:00","dependencies":[{"issue_id":"process_triage-dna","depends_on_id":"process_triage-nk1","type":"blocks","created_at":"2026-01-14T22:40:46.352321011-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-dvi","title":"EPIC: Phase 8 - Safety, Policy, and Guardrails","description":"## Overview\nPhase 8 implements safety guardrails, policy enforcement, and audit logging to ensure pt operates within defined boundaries.\n\n## Background\nThe plan specifies that policy.json defines hard limits that cannot be overridden: protected process patterns, maximum concurrent kills, require_human_for_supervised, and loss matrix bounds. This phase implements the enforcement layer.\n\n## Why It Matters\nSafety guardrails prevent catastrophic mistakes. Even with perfect inference, bugs or misconfigurations could cause pt to recommend killing critical processes. Policy enforcement provides defense in depth.\n\n## Phase Scope\n1. Policy.json enforcement engine\n2. Protected process pattern matching\n3. Rate limiting (max concurrent kills, cooldown periods)\n4. Audit logging with tamper detection\n5. Dry-run mode implementation\n6. Integration with system security (SELinux/AppArmor awareness)\n\n## Key Safety Mechanisms\n- **Protected patterns**: Regex list of never-kill processes (systemd, sshd, docker, etc.)\n- **Rate limits**: Max 10 kills per minute, 100 per hour (configurable)\n- **Supervisor protection**: Block auto-kill on supervised processes\n- **Loss bounds**: Reject action if expected loss exceeds threshold\n- **Audit trail**: Append-only log with cryptographic checksums\n\n## Dependencies\n- Phase 1: policy.json schema definition\n- Phase 5: Decision theory (loss calculations)\n- Phase 6: Action execution (enforcement point)\n\n## Success Criteria\n- Protected processes cannot be killed regardless of score\n- Rate limits enforced and reported\n- Audit log captures all decisions and actions\n- Dry-run mode produces accurate predictions\n- Policy violations logged with context","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:31:17.252578771-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:31:57.152376572-05:00"}
{"id":"process_triage-e48","title":"Implement core posterior computation P(C|x)","description":"## Task\nImplement the central posterior computation that combines all evidence sources.\n\n## Background\nSection 4.3 specifies:\nP(C|x) ∝ P(C) × Π_j P(x_j|C)\n\nlog P(C|x) = log P(C) + Σ_j log P(x_j|C) - log_normalizer\n\nEvidence terms include:\n- CPU occupancy (Beta-Binomial)\n- Runtime (Gamma)\n- Orphan status (Beta-Bernoulli)\n- State flags (Dirichlet-Categorical)\n- Command category (Dirichlet-Categorical)\n- TTY activity (Beta-Bernoulli)\n- Network activity (Beta-Bernoulli)\n\n## Implementation Notes\n- Load priors from priors.json\n- Compute each log-likelihood term\n- Sum terms per class\n- Apply log_sum_exp normalization\n- Store both unnormalized and normalized\n\n## Conditional Independence Caveat\nThe product assumes conditional independence. To avoid overconfidence:\n- Use n_eff for correlated features\n- Consider feature collapsing for redundant signals\n- Apply conservative calibration\n\n## Output Structure\n{\n  \"posterior\": {\"useful\": 0.03, \"useful_bad\": 0.02, \"abandoned\": 0.94, \"zombie\": 0.01},\n  \"log_posterior\": {...},\n  \"log_odds_abandoned_useful\": 3.45,\n  \"evidence_terms\": [\n    {\"feature\": \"cpu\", \"log_lik\": {\"useful\": -2.1, \"abandoned\": 0.5, ...}},\n    ...\n  ]\n}\n\n## Deliverables\n- Rust module: inference/posterior.rs\n- Integration with priors.json loading\n- Unit tests with known posteriors\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:26:40.466437834-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:26:40.466437834-05:00"}
{"id":"process_triage-e4y","title":"Add console styling system tests","description":"## Purpose\nCreate tests to verify the console styling system works correctly across different terminal environments.\n\n## Parent Epic\nConsole Output Styling Enhancement (process_triage-y8e)\n\n## Depends On\n- Add TTY detection and NO_COLOR support (process_triage-18z)\n- Implement log_* functions with emoji prefixes (process_triage-vpb)\n- Add ANSI fallback when gum unavailable (process_triage-ch7)\n\n## Why This Is Important\nThe styling system has multiple code paths:\n1. TTY with gum → full styling\n2. TTY without gum → ANSI fallback\n3. Non-TTY (pipe) → no styling\n4. NO_COLOR set → no colors\n5. CI environment → minimal styling\n\nEach path must be tested to ensure correct behavior.\n\n## Test Scenarios\n\n### test/test_console_styling.bats\n\n```bash\n#!/usr/bin/env bats\n\nload 'test_helper/common'\n\nsetup() {\n    setup_test_env\n    test_start \"$BATS_TEST_NAME\" \"Console styling test\"\n    export PT_SCRIPT=\"${BATS_TEST_DIRNAME}/../pt\"\n}\n\nteardown() {\n    test_end \"$BATS_TEST_NAME\" \"${BATS_TEST_COMPLETED:-fail}\"\n    restore_path\n    teardown_test_env\n}\n\n#==============================================================================\n# TTY DETECTION TESTS\n#==============================================================================\n\n@test \"Styling: detects TTY correctly\" {\n    test_info \"Testing TTY detection\"\n    \n    # When run directly (not piped), should detect TTY\n    # This is tricky to test because BATS output is piped\n    \n    # Test the detection logic directly by sourcing\n    source \"$PT_SCRIPT\" 2\u003e/dev/null || true\n    \n    test_info \"IS_TTY should be set based on terminal\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Styling: piped output disables colors\" {\n    test_info \"Testing piped output detection\"\n    \n    create_mock_ps \"$(mock_ps_with_stuck_test)\"\n    use_mock_bin\n    \n    # Pipe through cat to simulate non-TTY\n    output=$(\"$PT_SCRIPT\" scan 2\u003e\u00261 | cat)\n    \n    test_info \"Checking for absence of escape codes in piped output\"\n    \n    # Should NOT contain ANSI escape codes when piped\n    # Note: escape code is \\033 or \\e\n    if [[ \"$output\" == *$'\\033'* ]]; then\n        test_warn \"Found escape codes in piped output\"\n        # This might be acceptable if stderr is still TTY\n    fi\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# NO_COLOR SUPPORT TESTS\n#==============================================================================\n\n@test \"Styling: NO_COLOR=1 disables all colors\" {\n    test_info \"Testing NO_COLOR support\"\n    \n    export NO_COLOR=1\n    create_mock_ps \"$(mock_ps_with_stuck_test)\"\n    use_mock_bin\n    \n    test_info \"Running pt scan with NO_COLOR=1\"\n    run \"$PT_SCRIPT\" scan\n    \n    test_info \"Output: $output\"\n    \n    # Should NOT contain ANSI escape sequences\n    assert_not_contains \"$output\" $'\\033[' \"Should not contain ANSI codes\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Styling: NO_COLOR=0 still disables colors (presence matters, not value)\" {\n    test_info \"Testing NO_COLOR=0 (any value disables)\"\n    \n    # Per no-color.org spec, presence of variable matters, not value\n    export NO_COLOR=0\n    create_mock_ps \"$(mock_ps_with_stuck_test)\"\n    use_mock_bin\n    \n    run \"$PT_SCRIPT\" scan\n    \n    # Should still be disabled (NO_COLOR is set)\n    # This depends on implementation following the spec\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Styling: unset NO_COLOR allows colors\" {\n    test_info \"Testing without NO_COLOR\"\n    \n    unset NO_COLOR\n    create_mock_ps \"$(mock_ps_with_stuck_test)\"\n    use_mock_bin\n    \n    # This test is tricky because BATS captures output\n    # Colors would appear in TTY but not in captured output\n    \n    test_info \"Running without NO_COLOR\"\n    run \"$PT_SCRIPT\" scan\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# CI ENVIRONMENT TESTS\n#==============================================================================\n\n@test \"Styling: CI=true modifies behavior\" {\n    test_info \"Testing CI environment detection\"\n    \n    export CI=true\n    create_mock_ps \"$(mock_ps_with_stuck_test)\"\n    use_mock_bin\n    \n    test_info \"Running pt scan with CI=true\"\n    run \"$PT_SCRIPT\" scan\n    \n    # In CI, should work without interactive elements\n    assert_equals \"0\" \"$status\" \"Should succeed in CI\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Styling: GITHUB_ACTIONS=true detected as CI\" {\n    test_info \"Testing GitHub Actions detection\"\n    \n    export GITHUB_ACTIONS=true\n    create_mock_ps \"$(mock_ps_with_stuck_test)\"\n    use_mock_bin\n    \n    run \"$PT_SCRIPT\" scan\n    \n    assert_equals \"0\" \"$status\" \"Should succeed in GitHub Actions\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# GUM AVAILABILITY TESTS\n#==============================================================================\n\n@test \"Styling: works without gum installed\" {\n    test_info \"Testing fallback when gum unavailable\"\n    \n    # Hide gum from PATH\n    mkdir -p \"${MOCK_BIN}\"\n    cat \u003e \"${MOCK_BIN}/gum\" \u003c\u003c 'EOF'\n#!/bin/bash\nexit 127  # Command not found\nEOF\n    chmod +x \"${MOCK_BIN}/gum\"\n    \n    # Also remove real gum from PATH\n    export PATH=\"${MOCK_BIN}:/usr/bin:/bin\"\n    \n    create_mock_ps \"$(mock_ps_with_stuck_test)\"\n    \n    test_info \"Running pt scan without gum\"\n    run \"$PT_SCRIPT\" scan\n    \n    # Should still work using ANSI fallback\n    # Might show warning about gum\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Styling: gum_confirm falls back to read\" {\n    test_info \"Testing gum_confirm fallback\"\n    \n    # This tests the wrapper function directly\n    # Hide gum\n    export PATH=\"/usr/bin:/bin\"\n    export GUM_AVAILABLE=false\n    \n    # The fallback should use read for input\n    # This is hard to test automatically\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# LOG FUNCTION TESTS\n#==============================================================================\n\n@test \"Styling: log_info outputs to stderr\" {\n    test_info \"Testing log_info output stream\"\n    \n    # Source the script to get functions\n    source \"$PT_SCRIPT\" 2\u003e/dev/null || true\n    \n    # If log_info is available, test it\n    if declare -f log_info \u003e/dev/null 2\u003e\u00261; then\n        # Capture stderr separately\n        local stderr_output\n        stderr_output=$(log_info \"test message\" 2\u003e\u00261 \u003e/dev/null)\n        \n        test_info \"stderr output: $stderr_output\"\n        assert_contains \"$stderr_output\" \"test message\" \"Should output to stderr\"\n    else\n        test_warn \"log_info not yet implemented\"\n    fi\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Styling: log_error includes error indicator\" {\n    test_info \"Testing log_error formatting\"\n    \n    source \"$PT_SCRIPT\" 2\u003e/dev/null || true\n    \n    if declare -f log_error \u003e/dev/null 2\u003e\u00261; then\n        local output\n        output=$(log_error \"test error\" 2\u003e\u00261)\n        \n        # Should include error indicator (✗ or [ERROR] etc)\n        test_info \"Error output: $output\"\n    fi\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Styling: log_success includes success indicator\" {\n    test_info \"Testing log_success formatting\"\n    \n    source \"$PT_SCRIPT\" 2\u003e/dev/null || true\n    \n    if declare -f log_success \u003e/dev/null 2\u003e\u00261; then\n        local output\n        output=$(log_success \"test success\" 2\u003e\u00261)\n        \n        # Should include success indicator (✓ or [OK] etc)\n        test_info \"Success output: $output\"\n    fi\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# COLOR CODE TESTS\n#==============================================================================\n\n@test \"Styling: color variables defined when USE_COLOR=true\" {\n    test_info \"Testing color variable definitions\"\n    \n    unset NO_COLOR\n    export USE_COLOR=true\n    \n    source \"$PT_SCRIPT\" 2\u003e/dev/null || true\n    \n    # Check color variables are set\n    if [[ -n \"${RED:-}\" ]]; then\n        test_info \"RED is defined: ${RED@Q}\"\n        # Should contain escape code\n        [[ \"$RED\" == *\"033\"* ]] || [[ \"$RED\" == *\"e[\"* ]]\n    fi\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"Styling: color variables empty when USE_COLOR=false\" {\n    test_info \"Testing color variables disabled\"\n    \n    export NO_COLOR=1\n    \n    source \"$PT_SCRIPT\" 2\u003e/dev/null || true\n    \n    # Color variables should be empty\n    if [[ -z \"${RED:-}\" ]] || [[ \"$RED\" == \"\" ]]; then\n        test_info \"RED is correctly empty when colors disabled\"\n    fi\n    \n    BATS_TEST_COMPLETED=pass\n}\n```\n\n## Success Criteria\n- [ ] TTY detection tested\n- [ ] Piped output tested\n- [ ] NO_COLOR support tested (various values)\n- [ ] CI environment detection tested\n- [ ] Gum availability/fallback tested\n- [ ] Log functions tested (stderr, formatting)\n- [ ] Color variable states tested\n- [ ] All tests have detailed logging","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:49:14.0288411-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:49:14.0288411-05:00","dependencies":[{"issue_id":"process_triage-e4y","depends_on_id":"process_triage-ch7","type":"blocks","created_at":"2026-01-14T22:50:31.747722531-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-ed3","title":"EPIC: Phase 11 - Pattern and Signature Library","description":"## Overview\nPhase 11 builds a signature library for known process types with pre-calibrated priors and specialized detection logic.\n\n## Background\nThe plan specifies bundled signatures for common processes: test runners, dev servers, build tools, databases, etc. Each signature includes characteristic patterns, expected lifetimes, typical resource usage, and calibrated Bayesian priors.\n\n## Why It Matters\nGeneric priors work but specialized priors are much more accurate. A signature for 'jest test runner' knows that tests typically complete in minutes, not hours, and that high CPU during execution is normal. This domain knowledge dramatically improves inference accuracy.\n\n## Phase Scope\n1. Signature schema definition\n2. Core signature library (50+ common processes)\n3. Signature matching engine\n4. Prior override system\n5. Community signature format\n\n## Signature Schema\n- pattern: Regex matching command/exe\n- category: test_runner|dev_server|build_tool|database|...\n- expected_lifetime: {min, typical, max} in seconds\n- resource_profile: {cpu: normal_range, memory: normal_range}\n- priors: {abandoned: Beta(a,b), zombie: Beta(a,b), ...}\n- detection_hints: Special signals for this process type\n- kill_safety: {safe_to_term: bool, needs_drain: bool, ...}\n\n## Bundled Signatures (Examples)\n- Test runners: jest, pytest, bats, go test, cargo test\n- Dev servers: next dev, vite, webpack-dev-server, rails s\n- Build tools: make, cargo build, npm run build, gcc/clang\n- Databases: postgres, mysql, redis, mongodb\n- Agent shells: claude, codex, aider processes\n\n## Matching Priority\n1. Exact command match\n2. Exe path match\n3. Argument pattern match\n4. Generic category fallback\n\n## Success Criteria\n- 50+ signatures for common dev tools\n- Signature matching fast and accurate\n- Priors improve inference accuracy (measured)\n- Community contribution path documented","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:33:59.015590401-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:34:37.093784929-05:00"}
{"id":"process_triage-f5o","title":"Implement progress event emission system","description":"## Task\nImplement the progress event system that reports collection stages to TUI and agent CLI.\n\n## Background\nBoth TUI and agent CLI need to show progress:\n- scan_started, scan_progress, scan_complete\n- deep_scan_started, deep_scan_progress, deep_scan_complete\n- infer_started, infer_complete\n- decide_started, decide_complete\n- plan_ready\n\nEvents enable:\n- TUI progress visualization\n- pt agent tail --format jsonl streaming\n- Timeout detection (no events = hung)\n\n## Event Structure\n{\n  \"event\": \"scan_progress\",\n  \"timestamp\": \"2025-01-15T14:30:22Z\",\n  \"session_id\": \"abc123\",\n  \"phase\": \"quick_scan\",\n  \"progress\": {\"current\": 150, \"total\": 312},\n  \"details\": {\"pids_scanned\": 150}\n}\n\n## Implementation Notes\n- Use channels for event dispatch\n- Support multiple subscribers (TUI, file, network)\n- Events should be cheap (not slow down collection)\n- Include timing information for performance analysis\n\n## Event Types\n- session_started, session_ended\n- quick_scan_{started,progress,complete}\n- deep_scan_{started,progress,complete}\n- inference_{started,progress,complete}\n- decision_{started,complete}\n- action_{started,complete,failed}\n- plan_ready\n\n## Deliverables\n- Rust module: events/mod.rs\n- Event type definitions\n- Event emitter trait and implementations\n- JSONL formatter for CLI\n- Unit tests","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:25:00.809156731-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:25:00.809156731-05:00"}
{"id":"process_triage-fk7","title":"Implement macOS-specific collection","description":"## Task\nImplement evidence collection for macOS platform.\n\n## Background\nmacOS has no /proc filesystem and uses different tools:\n- fs_usage: filesystem activity tracing\n- sample/spindump: stack sampling\n- nettop: network connections per process\n- powermetrics: power and performance metrics\n- lsof: file descriptors\n- vm_stat: memory statistics\n\n## Data Collection Approach\n1. Quick scan: BSD ps (different flags than Linux)\n2. Deep scan: lsof, netstat, sysctl\n3. Maximal: sample, fs_usage (may require SIP disable)\n\n## SIP Considerations\nSystem Integrity Protection limits tracing:\n- dtruss may not work\n- Some tools require entitlements\n- Detect SIP status and adjust capabilities\n\n## Implementation Notes\n- Platform detection at startup\n- Separate collection modules per platform\n- Abstract interface for cross-platform code\n- Handle tool unavailability gracefully\n\n## macOS-specific Features\n- Activity Monitor integration info\n- launchd service detection\n- XPC service identification\n- Spotlight/mds process handling\n\n## Deliverables\n- Rust module: collect/macos.rs\n- Platform abstraction layer\n- Unit tests with mocked macOS output\n- Documentation","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:25:38.296463105-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:25:38.296463105-05:00"}
{"id":"process_triage-g7w","title":"Define command and CWD category taxonomies","description":"## Task\nDefine the taxonomies for categorizing processes by command type and working directory.\n\n## Background\nProcess classification uses Dirichlet-Categorical priors over command categories:\n- Command categories affect prior probabilities\n- CWD categories provide context for interpretation\n- Categories feed into the inference as evidence\n\nCommand categories (from plan examples):\n- test: bun test, jest, pytest, mocha\n- devserver: next dev, vite, webpack dev\n- agent: claude, codex, copilot, gemini\n- server: gunicorn, nginx, apache\n- daemon: systemd, cron, docker\n- build: webpack, esbuild, tsc\n- editor: code, vim, emacs\n- shell: bash, zsh, fish\n\nCWD categories:\n- project: /home/user/projects/*\n- system: /usr, /var, /etc\n- temp: /tmp, /var/tmp\n- home: ~\n\n## Deliverables\n- Command category taxonomy with examples\n- CWD category taxonomy with path patterns\n- Mapping rules (regex/glob patterns to categories)\n- Prior probability adjustments per category\n- Unknown/other category handling\n- Extensibility for user-defined categories\n\n## Technical Considerations\n- Categories must be mutually exclusive\n- Pattern matching order matters (most specific first)\n- Consider hierarchical categories (test/unit, test/integration)\n- Categories are features, not final classifications","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:22:34.833425814-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:22:34.833425814-05:00"}
{"id":"process_triage-gic","title":"Implement protected process pattern matching","description":"## Overview\nImplement pattern matching system for protected processes that cannot be killed regardless of score.\n\n## Background\nThe plan specifies a protected_patterns list in policy.json containing regex patterns for critical system processes: systemd, sshd, dbus-daemon, dockerd, containerd, cron, etc. These must NEVER be flagged or killable.\n\n## Why It Matters\nSystem stability depends on certain processes. Accidentally killing sshd would lock users out of remote systems. Killing systemd would crash the machine. Protected patterns provide an inviolable safety net.\n\n## Technical Approach\n1. Compile protected patterns to regex at startup\n2. Check patterns against: command, exe path, comm name\n3. Block at scan phase (don't even score protected processes)\n4. Provide clear feedback when pattern matches\n5. Support both inclusion and exclusion patterns\n\n## Default Protected Patterns\n- System init: systemd, /sbin/init\n- Session management: sshd, login, agetty\n- D-Bus: dbus-daemon, dbus-broker\n- Containers: dockerd, containerd, runc\n- Scheduling: cron, atd, systemd-timer\n- Networking: NetworkManager, dhclient\n- Logging: rsyslog, journald\n- Security: polkitd, sssd\n\n## Pattern Matching Order\n1. Check protected_patterns first (whitelist)\n2. If protected, skip scoring entirely\n3. Log protection matches in debug mode\n4. Never show protected processes in candidate list\n\n## Success Criteria\n- All default protected processes never flagged\n- Custom patterns in policy.json respected\n- Pattern matching is fast (compiled regex)\n- Clear logging when protection triggered","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:32:59.029160297-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:33:48.50823088-05:00"}
{"id":"process_triage-h2y","title":"Add test helper with mock injection","description":"## Purpose\nCreate a test helper file with shared setup, teardown, mock injection utilities, and **comprehensive logging** for debugging test failures.\n\n## Parent Epic\nExpanded Test Coverage (process_triage-bgd)\n\n## CRITICAL: Test Logging Requirements\nAll test utilities must provide detailed logging:\n- Every test should output what it's testing and expected outcome\n- All mock setups should log what they're mocking\n- Failures should include full context (expected vs actual, relevant state)\n- Use TAP-compatible output for CI integration\n\n## Implementation\n\n### test/test_helper/common.bash\n```bash\n#!/usr/bin/env bash\n# Test helper functions for pt BATS tests\n# Provides: setup/teardown, mocks, assertions, logging\n\n#==============================================================================\n# TEST LOGGING\n#==============================================================================\n# All test output should be detailed and debuggable\n\nTEST_LOG_LEVEL=${TEST_LOG_LEVEL:-info}  # debug, info, warn, error\n\ntest_log() {\n    local level=\"$1\"\n    shift\n    local msg=\"$*\"\n    local timestamp=\"$(date '+%H:%M:%S.%3N')\"\n    \n    case \"$level\" in\n        debug) [[ \"$TEST_LOG_LEVEL\" == \"debug\" ]] \u0026\u0026 echo \"# [$timestamp] DEBUG: $msg\" ;;\n        info)  echo \"# [$timestamp] INFO:  $msg\" ;;\n        warn)  echo \"# [$timestamp] WARN:  $msg\" \u003e\u00262 ;;\n        error) echo \"# [$timestamp] ERROR: $msg\" \u003e\u00262 ;;\n    esac\n}\n\ntest_debug() { test_log debug \"$@\"; }\ntest_info()  { test_log info \"$@\"; }\ntest_warn()  { test_log warn \"$@\"; }\ntest_error() { test_log error \"$@\"; }\n\n# Log test start with description\ntest_start() {\n    local test_name=\"$1\"\n    local description=\"$2\"\n    test_info \"=== START: $test_name ===\"\n    test_info \"Testing: $description\"\n}\n\n# Log test completion with result\ntest_end() {\n    local test_name=\"$1\"\n    local status=\"$2\"\n    if [[ \"$status\" == \"pass\" ]]; then\n        test_info \"=== PASS: $test_name ===\"\n    else\n        test_error \"=== FAIL: $test_name ===\"\n    fi\n}\n\n#==============================================================================\n# TEST ENVIRONMENT SETUP\n#==============================================================================\n\nsetup_test_env() {\n    test_debug \"Setting up test environment...\"\n    \n    # Create isolated directories\n    export TEST_DIR=\"${BATS_TEST_TMPDIR}/test_env\"\n    export CONFIG_DIR=\"${TEST_DIR}/config\"\n    export MOCK_BIN=\"${TEST_DIR}/mock_bin\"\n    export TEST_LOG_FILE=\"${TEST_DIR}/test.log\"\n    \n    mkdir -p \"$CONFIG_DIR\" \"$MOCK_BIN\"\n    \n    # Initialize empty decisions file\n    echo '{}' \u003e \"${CONFIG_DIR}/decisions.json\"\n    \n    # Set test mode flags\n    export TEST_MODE=1\n    export CI=true\n    export NO_COLOR=1\n    \n    test_debug \"TEST_DIR=$TEST_DIR\"\n    test_debug \"CONFIG_DIR=$CONFIG_DIR\"\n    test_debug \"MOCK_BIN=$MOCK_BIN\"\n    \n    test_info \"Test environment ready\"\n}\n\nteardown_test_env() {\n    test_debug \"Tearing down test environment...\"\n    \n    # Log any test artifacts before cleanup\n    if [[ -f \"$TEST_LOG_FILE\" ]]; then\n        test_debug \"Test log contents:\"\n        cat \"$TEST_LOG_FILE\" | while read line; do\n            test_debug \"  $line\"\n        done\n    fi\n    \n    rm -rf \"${BATS_TEST_TMPDIR}/test_env\"\n    test_debug \"Cleanup complete\"\n}\n\n#==============================================================================\n# MOCK CREATION UTILITIES\n#==============================================================================\n\n# Create a mock command that outputs predefined text\n# Usage: create_mock_command name output [exit_code]\ncreate_mock_command() {\n    local name=\"$1\"\n    local output=\"$2\"\n    local exit_code=\"${3:-0}\"\n    \n    test_debug \"Creating mock command: $name (exit=$exit_code)\"\n    test_debug \"Mock output: ${output:0:100}...\"\n    \n    cat \u003e \"${MOCK_BIN}/${name}\" \u003c\u003c EOF\n#!/usr/bin/env bash\ncat \u003c\u003c 'MOCK_OUTPUT'\n${output}\nMOCK_OUTPUT\nexit ${exit_code}\nEOF\n    chmod +x \"${MOCK_BIN}/${name}\"\n    \n    test_info \"Mock '$name' created at ${MOCK_BIN}/${name}\"\n}\n\n# Create mock ps command with specific process output\ncreate_mock_ps() {\n    local processes=\"$1\"\n    test_info \"Creating mock ps with $(echo \"$processes\" | wc -l) processes\"\n    create_mock_command \"ps\" \"$processes\"\n}\n\n# Create mock curl that returns specific content\ncreate_mock_curl() {\n    local content=\"$1\"\n    local exit_code=\"${2:-0}\"\n    test_info \"Creating mock curl (exit=$exit_code, content_len=${#content})\"\n    create_mock_command \"curl\" \"$content\" \"$exit_code\"\n}\n\n# Create mock curl that simulates redirect for version checking\ncreate_mock_curl_redirect() {\n    local final_url=\"$1\"\n    test_info \"Creating mock curl redirect to: $final_url\"\n    \n    cat \u003e \"${MOCK_BIN}/curl\" \u003c\u003c EOF\n#!/usr/bin/env bash\n# Mock curl that handles -w '%{url_effective}'\nif [[ \"$*\" == *\"url_effective\"* ]]; then\n    echo \"$final_url\"\nelse\n    # Default behavior\n    cat /dev/null\nfi\nexit 0\nEOF\n    chmod +x \"${MOCK_BIN}/curl\"\n}\n\n#==============================================================================\n# MOCK PROCESS DATA GENERATORS\n#==============================================================================\n\n# Generate a mock process line in pt's expected format\n# Usage: mock_process PID PPID AGE_SECS MEM_MB \"command\"\nmock_process() {\n    local pid=\"$1\"\n    local ppid=\"$2\"\n    local age=\"$3\"\n    local mem=\"$4\"\n    local cmd=\"$5\"\n    \n    test_debug \"mock_process: pid=$pid ppid=$ppid age=$age mem=$mem cmd='$cmd'\"\n    printf '%s|%s|%s|%s|%s\\n' \"$pid\" \"$ppid\" \"$age\" \"$mem\" \"$cmd\"\n}\n\n# Pre-built scenarios\nmock_ps_with_stuck_test() {\n    local age=\"${1:-7200}\"  # 2 hours default\n    test_info \"Generating stuck test scenario (age=$age)\"\n    mock_process 12345 1000 \"$age\" 512 \"bun test --watch\"\n}\n\nmock_ps_with_orphan() {\n    test_info \"Generating orphan process scenario\"\n    mock_process 23456 1 86400 256 \"orphaned process\"\n}\n\nmock_ps_with_dev_server() {\n    local age=\"${1:-259200}\"  # 3 days default\n    test_info \"Generating old dev server scenario (age=$age)\"\n    mock_process 34567 1000 \"$age\" 128 \"next dev --port 3000\"\n}\n\nmock_ps_with_protected() {\n    test_info \"Generating protected process scenario\"\n    mock_process 1 0 9999999 100 \"/usr/lib/systemd/systemd\"\n}\n\nmock_ps_with_agent_shell() {\n    local age=\"${1:-90000}\"  # ~25 hours default\n    test_info \"Generating agent shell scenario (age=$age)\"\n    mock_process 45678 1000 \"$age\" 200 \"/bin/bash -c claude assistant\"\n}\n\n# Complex scenario with multiple process types\nmock_ps_mixed_scenario() {\n    test_info \"Generating mixed scenario with multiple process types\"\n    {\n        mock_process 10001 1000 3601 512 \"bun test --watch\"           # Stuck test\n        mock_process 10002 1 172800 256 \"orphaned background task\"    # Orphan + old\n        mock_process 10003 1000 259200 128 \"next dev --port 3000\"     # Old dev server\n        mock_process 10004 1000 90000 200 \"/bin/bash -c claude\"       # Agent shell\n        mock_process 10005 1000 1800 64 \"vim file.txt\"                # Normal (recent)\n        mock_process 1 0 9999999 100 \"/usr/lib/systemd/systemd\"       # Protected\n    }\n}\n\n#==============================================================================\n# ASSERTION HELPERS\n#==============================================================================\n\n# Assert score is within expected range\nassert_score_range() {\n    local actual=\"$1\"\n    local min=\"$2\"\n    local max=\"$3\"\n    local context=\"${4:-}\"\n    \n    test_debug \"assert_score_range: actual=$actual expected=[$min-$max] context='$context'\"\n    \n    if (( actual \u003c min || actual \u003e max )); then\n        test_error \"Score out of range\"\n        test_error \"  Expected: $min to $max\"\n        test_error \"  Actual:   $actual\"\n        [[ -n \"$context\" ]] \u0026\u0026 test_error \"  Context:  $context\"\n        return 1\n    fi\n    \n    test_debug \"Score $actual is within range [$min-$max] ✓\"\n    return 0\n}\n\n# Assert string contains substring\nassert_contains() {\n    local haystack=\"$1\"\n    local needle=\"$2\"\n    local context=\"${3:-}\"\n    \n    test_debug \"assert_contains: looking for '$needle' in '${haystack:0:50}...'\"\n    \n    if [[ \"$haystack\" != *\"$needle\"* ]]; then\n        test_error \"String does not contain expected substring\"\n        test_error \"  Looking for: '$needle'\"\n        test_error \"  In string:   '${haystack:0:200}'\"\n        [[ -n \"$context\" ]] \u0026\u0026 test_error \"  Context:     $context\"\n        return 1\n    fi\n    \n    test_debug \"Found '$needle' in string ✓\"\n    return 0\n}\n\n# Assert string does not contain substring\nassert_not_contains() {\n    local haystack=\"$1\"\n    local needle=\"$2\"\n    local context=\"${3:-}\"\n    \n    test_debug \"assert_not_contains: checking '$needle' absent from '${haystack:0:50}...'\"\n    \n    if [[ \"$haystack\" == *\"$needle\"* ]]; then\n        test_error \"String contains unexpected substring\"\n        test_error \"  Should not contain: '$needle'\"\n        test_error \"  But found in:       '${haystack:0:200}'\"\n        [[ -n \"$context\" ]] \u0026\u0026 test_error \"  Context:            $context\"\n        return 1\n    fi\n    \n    test_debug \"Confirmed '$needle' absent ✓\"\n    return 0\n}\n\n# Assert equality with detailed diff\nassert_equals() {\n    local expected=\"$1\"\n    local actual=\"$2\"\n    local context=\"${3:-}\"\n    \n    test_debug \"assert_equals: comparing values\"\n    \n    if [[ \"$expected\" != \"$actual\" ]]; then\n        test_error \"Values not equal\"\n        test_error \"  Expected: '$expected'\"\n        test_error \"  Actual:   '$actual'\"\n        [[ -n \"$context\" ]] \u0026\u0026 test_error \"  Context:  $context\"\n        return 1\n    fi\n    \n    test_debug \"Values match: '$expected' ✓\"\n    return 0\n}\n\n# Assert command succeeds\nassert_success() {\n    local cmd=\"$1\"\n    local context=\"${2:-}\"\n    \n    test_debug \"assert_success: running '$cmd'\"\n    \n    local output exit_code\n    output=\"$(eval \"$cmd\" 2\u003e\u00261)\"\n    exit_code=$?\n    \n    if [[ $exit_code -ne 0 ]]; then\n        test_error \"Command failed (expected success)\"\n        test_error \"  Command:   $cmd\"\n        test_error \"  Exit code: $exit_code\"\n        test_error \"  Output:    $output\"\n        [[ -n \"$context\" ]] \u0026\u0026 test_error \"  Context:   $context\"\n        return 1\n    fi\n    \n    test_debug \"Command succeeded (exit=0) ✓\"\n    echo \"$output\"\n    return 0\n}\n\n# Assert command fails\nassert_fails() {\n    local cmd=\"$1\"\n    local expected_exit=\"${2:-}\"\n    local context=\"${3:-}\"\n    \n    test_debug \"assert_fails: running '$cmd'\"\n    \n    local output exit_code\n    output=\"$(eval \"$cmd\" 2\u003e\u00261)\"\n    exit_code=$?\n    \n    if [[ $exit_code -eq 0 ]]; then\n        test_error \"Command succeeded (expected failure)\"\n        test_error \"  Command: $cmd\"\n        test_error \"  Output:  $output\"\n        [[ -n \"$context\" ]] \u0026\u0026 test_error \"  Context: $context\"\n        return 1\n    fi\n    \n    if [[ -n \"$expected_exit\" ]] \u0026\u0026 [[ $exit_code -ne $expected_exit ]]; then\n        test_error \"Wrong exit code\"\n        test_error \"  Expected: $expected_exit\"\n        test_error \"  Actual:   $exit_code\"\n        return 1\n    fi\n    \n    test_debug \"Command failed as expected (exit=$exit_code) ✓\"\n    echo \"$output\"\n    return 0\n}\n\n#==============================================================================\n# SKIP HELPERS\n#==============================================================================\n\nskip_if_no_jq() {\n    if ! command -v jq \u0026\u003e/dev/null; then\n        test_warn \"Skipping: jq not installed\"\n        skip \"jq not installed\"\n    fi\n}\n\nskip_if_no_gum() {\n    if ! command -v gum \u0026\u003e/dev/null; then\n        test_warn \"Skipping: gum not installed\"\n        skip \"gum not installed\"\n    fi\n}\n\nskip_if_ci() {\n    if [[ -n \"${CI:-}\" ]]; then\n        test_warn \"Skipping: CI environment\"\n        skip \"Skipped in CI environment\"\n    fi\n}\n\nskip_if_root() {\n    if [[ $EUID -eq 0 ]]; then\n        test_warn \"Skipping: running as root\"\n        skip \"Skipped when running as root\"\n    fi\n}\n\n#==============================================================================\n# PATH MANIPULATION FOR MOCKS\n#==============================================================================\n\nuse_mock_bin() {\n    test_info \"Injecting mock bin into PATH\"\n    test_debug \"MOCK_BIN=$MOCK_BIN\"\n    export ORIGINAL_PATH=\"$PATH\"\n    export PATH=\"${MOCK_BIN}:${PATH}\"\n    test_debug \"New PATH: $PATH\"\n}\n\nrestore_path() {\n    if [[ -n \"${ORIGINAL_PATH:-}\" ]]; then\n        test_debug \"Restoring original PATH\"\n        export PATH=\"$ORIGINAL_PATH\"\n        unset ORIGINAL_PATH\n    fi\n}\n\n#==============================================================================\n# FILE COMPARISON UTILITIES\n#==============================================================================\n\n# Create a snapshot of a file for comparison\nsnapshot_file() {\n    local file=\"$1\"\n    local snapshot_name=\"$2\"\n    \n    if [[ -f \"$file\" ]]; then\n        cp \"$file\" \"${TEST_DIR}/${snapshot_name}.snapshot\"\n        test_debug \"Created snapshot: $snapshot_name\"\n    else\n        test_warn \"Cannot snapshot: $file does not exist\"\n    fi\n}\n\n# Compare file with snapshot\ncompare_with_snapshot() {\n    local file=\"$1\"\n    local snapshot_name=\"$2\"\n    local snapshot=\"${TEST_DIR}/${snapshot_name}.snapshot\"\n    \n    if [[ ! -f \"$snapshot\" ]]; then\n        test_error \"Snapshot not found: $snapshot_name\"\n        return 1\n    fi\n    \n    if diff -q \"$file\" \"$snapshot\" \u003e/dev/null 2\u003e\u00261; then\n        test_debug \"File matches snapshot: $snapshot_name ✓\"\n        return 0\n    else\n        test_error \"File differs from snapshot: $snapshot_name\"\n        test_error \"Diff:\"\n        diff \"$snapshot\" \"$file\" | while read line; do\n            test_error \"  $line\"\n        done\n        return 1\n    fi\n}\n\n#==============================================================================\n# TIMING UTILITIES\n#==============================================================================\n\n# Time a command and report duration\ntime_command() {\n    local description=\"$1\"\n    shift\n    local cmd=\"$*\"\n    \n    local start end duration\n    start=$(date +%s%3N)\n    eval \"$cmd\"\n    local exit_code=$?\n    end=$(date +%s%3N)\n    duration=$((end - start))\n    \n    test_info \"$description completed in ${duration}ms (exit=$exit_code)\"\n    return $exit_code\n}\n```\n\n## Success Criteria\n- [ ] Test logging provides TAP-compatible output\n- [ ] All test utilities log their actions\n- [ ] Mock creation is logged with details\n- [ ] Assertion failures include full context\n- [ ] Setup/teardown logging aids debugging\n- [ ] PATH manipulation is logged and reversible\n- [ ] Timing utilities available for performance tests","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:39:24.535919856-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:45:56.061384895-05:00"}
{"id":"process_triage-hxh","title":"Implement Hawkes process layer for bursty events","description":"## Task\nImplement Hawkes process modeling for self-exciting event streams (syscalls, IO, network).\n\n## Background\nSection 4.19 specifies Hawkes processes:\n- Model syscalls/IO/network as self-exciting point processes\n- Events trigger more events (bursts)\n- Exponential kernels: λ(t) = μ + Σ_{t_i\u003ct} α exp(-β(t-t_i))\n- Closed-form likelihood for exponential kernels\n\n## Purpose\nHawkes features detect:\n- Pathological burst patterns (tight loops)\n- Normal work patterns vs stuck spinning\n- Cross-excitation between CPU and IO\n\n## Implementation Notes\n- Fit parameters via fast EM/MLE\n- Produce deterministic summaries (branching ratio, burst intensity)\n- Feed summaries to closed-form core as features\n- Not used directly for posteriors\n\n## Output Structure\n{\n  \"hawkes_summary\": {\n    \"baseline_rate\": 10.5,\n    \"excitation_alpha\": 0.8,\n    \"decay_beta\": 2.0,\n    \"branching_ratio\": 0.4,\n    \"burst_intensity\": \"moderate\"\n  }\n}\n\n## Integration with Core\n- High branching ratio → boost P(useful_bad) (tight loop)\n- Low rate with bursts → normal work pattern\n- Extreme bursts → anomaly signal\n\n## Deliverables\n- Rust module: inference/hawkes.rs\n- Parameter estimation\n- Feature extraction\n- Unit tests\n- Documentation","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:27:17.054020558-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:27:17.054020558-05:00"}
{"id":"process_triage-i5r","title":"Create ci.yml with ShellCheck job","description":"## Purpose\nCreate the CI workflow file with ShellCheck static analysis as the first quality gate.\n\n## Parent Epic\nGitHub Actions CI/CD Pipeline (process_triage-68c)\n\n## Why ShellCheck First?\nShellCheck catches common bash issues:\n- Unquoted variables (`$var` vs `\"$var\"`)\n- Deprecated syntax\n- Portability issues\n- Common mistakes (SC2086, SC2046, etc.)\n\nRunning it first provides fast feedback before running longer tests.\n\n## Implementation\n\n### .github/workflows/ci.yml\n```yaml\nname: CI\n\non:\n  push:\n    branches: [main, master]\n  pull_request:\n    branches: [main, master]\n  workflow_dispatch:  # Allow manual trigger\n\njobs:\n  shellcheck:\n    name: ShellCheck\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      \n      - name: Run ShellCheck\n        uses: ludeeus/action-shellcheck@master\n        with:\n          severity: warning\n          scandir: '.'\n          additional_files: 'pt install.sh'\n        env:\n          SHELLCHECK_OPTS: '-e SC2155 -e SC2034'\n```\n\n## ShellCheck Exclusions\n\n### SC2155: Declare and assign separately\n```bash\n# SC2155 warns about this:\nlocal foo=\"$(command)\"\n\n# Wants this instead:\nlocal foo\nfoo=\"$(command)\"\n```\nWe exclude this because the combined form is more readable and the risk is minimal.\n\n### SC2034: Variable appears unused\nThis fires on variables used in heredocs or sourced files. Exclude to reduce noise.\n\n## Severity Levels\n- **error**: Script will likely fail\n- **warning**: Potential issues (our threshold)\n- **info**: Style suggestions\n- **style**: Purely cosmetic\n\nSetting `severity: warning` catches real issues without being overly pedantic.\n\n## Success Criteria\n- [ ] ci.yml created in .github/workflows/\n- [ ] ShellCheck job runs on push/PR\n- [ ] Appropriate exclusions configured\n- [ ] Passes on current codebase (or issues fixed)","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:37:30.873339841-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:37:30.873339841-05:00"}
{"id":"process_triage-iau","title":"EPIC: Phase 2 - Math Utilities Foundation","description":"## Overview\nThis epic covers the implementation of all mathematical primitives needed by the Bayesian inference engine. These are the building blocks that make the 'alien artifact' inference possible.\n\n## Background \u0026 Context\nThe inference engine (Section 4) uses closed-form Bayesian computation throughout:\n- Beta-Binomial for CPU occupancy\n- Beta-Bernoulli for binary features (orphan, TTY, net)\n- Dirichlet-Multinomial for categorical features\n- Gamma for hazard rates and runtime\n- Bayes factors for model comparison\n\nAll math must be numerically stable, auditable, and efficient.\n\n## Why This Matters\n- **Correctness**: Numerical instability leads to wrong classifications\n- **Auditability**: Galaxy-brain mode requires exact math display\n- **Performance**: Inference runs on every process; math must be fast\n- **Testability**: Math functions are deterministic and unit-testable\n\n## Scope\n1. Beta distribution utilities (PDF, CDF, inverse CDF)\n2. Beta-Binomial posterior predictive\n3. Beta-Bernoulli posterior predictive\n4. Dirichlet-Multinomial posterior predictive\n5. Gamma PDF and posterior updates\n6. Log-sum-exp and other stability primitives\n7. Bayes factor computation\n8. Log-odds and posterior computation\n9. Arrow/Parquet schema definitions\n10. Batched Parquet writer\n\n## Success Criteria\n- All functions pass unit tests with known values\n- Numerical stability verified for extreme inputs\n- Performance benchmarks meet requirements (\u003c1ms per process)\n- Functions match documented equations exactly\n\n## Technical Constraints\n- Pure Rust implementation (no external math libraries for core)\n- Use log-domain everywhere to prevent underflow\n- Consider SIMD for batched operations","status":"open","priority":0,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:23:03.095279519-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:23:03.095279519-05:00"}
{"id":"process_triage-isy","title":"Implement shadow mode model validation framework","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:34:49.110234888-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:34:49.110234888-05:00"}
{"id":"process_triage-jqi","title":"Define agent/robot CLI contract","description":"## Task\nSpecify the complete contract for the agent CLI interface (pt agent subcommand) that AI agents will consume.\n\n## Background\nSection 3.5 specifies the agent CLI surface:\n- pt agent plan (generate plan)\n- pt agent explain (detailed evidence)\n- pt agent apply (execute actions)\n- pt agent sessions/show/status/tail (session management)\n- pt agent export/report (artifacts)\n- pt agent inbox (daemon escalations)\n- pt agent watch (background monitoring)\n- pt agent fleet (multi-host)\n- pt agent snapshot (one-shot recon)\n- pt agent capabilities (what can we do)\n- pt agent verify (confirm outcomes)\n- pt agent diff (before/after comparison)\n\n## Deliverables\n- Complete flag specification per subcommand\n- JSON schema for each output type\n- Session continuity semantics\n- Resumability contract (--resume behavior)\n- Token-efficiency controls (--compact, --fields, etc.)\n- Pre-toggled plan semantics\n- Safety gate behavior\n\n## Technical Considerations\n- Output must be machine-parseable (JSON primary)\n- Prose summaries available via --include-prose\n- Galaxy-brain math available via --galaxy-brain\n- Every response includes schema_version\n- Session IDs enable multi-call workflows\n\n## Critical Fields (Always Present)\nPer candidate:\n- pid, start_id, uid, cmd_short\n- classification, posterior, confidence\n- blast_radius (always), reversibility (always)\n- supervisor (always), uncertainty (always)\n- recommended_action, action_rationale","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:21:28.649391694-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:21:28.649391694-05:00"}
{"id":"process_triage-kyl","title":"Implement staged action execution protocol","description":"## Task\nImplement the protocol for safely executing action plans.\n\n## Background\nSection 6 specifies staged execution:\n1. Acquire pt lock\n2. Revalidate target identity\n3. Execute action\n4. Verify outcome\n5. Log everything\n6. Release lock\n\n## Execution Stages\nFor each action in plan:\n1. **Pre-flight**: Verify identity, check permissions, verify not protected\n2. **Execute**: Run the action (signal, cgroup op, etc.)\n3. **Wait**: Allow action to take effect\n4. **Verify**: Check outcome (process state, resource freed)\n5. **Log**: Record action and outcome\n6. **Handle failure**: Consult recovery tree\n\n## Identity Revalidation\nCheck immediately before action:\n- pid exists\n- start_id matches (process is same)\n- uid matches (no privilege escalation)\nIf mismatch: abort and report\n\n## Implementation Notes\n- Use tokio for async execution\n- Timeouts on all operations\n- Graceful cancellation support\n- Transaction-like semantics (log intent before action)\n\n## Output Structure\n{\n  \"execution_result\": {\n    \"actions_attempted\": 3,\n    \"actions_succeeded\": 2,\n    \"actions_failed\": 1,\n    \"outcomes\": [\n      {\"target\": {...}, \"action\": \"kill\", \"result\": \"success\", \"time_ms\": 150},\n      {\"target\": {...}, \"action\": \"kill\", \"result\": \"identity_mismatch\", \"details\": \"...\"\n      }\n    ]\n  }\n}\n\n## Deliverables\n- Rust module: action/executor.rs\n- Staged execution logic\n- Identity revalidation\n- Unit tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:29:48.779315736-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:29:48.779315736-05:00"}
{"id":"process_triage-kze","title":"Define package architecture: pt wrapper vs pt-core monolith","description":"## Task\nDefine the clear boundary between:\n- **pt (bash wrapper/installer)**: Handles installation, capability discovery, environment detection, and launches pt-core\n- **pt-core (Rust monolith)**: The actual implementation containing scan/deep-scan/infer/decide/ui/agent/duck/bundle/report/daemon\n\n## Background\nThe plan calls for a two-tier architecture where bash handles the messy platform-specific installation and capability discovery, while Rust handles the computationally intensive inference and UX. This separation:\n1. Allows the wrapper to degrade gracefully on any platform\n2. Keeps the core focused and testable\n3. Enables the core to assume capabilities are known (passed via manifest)\n\n## Deliverables\n- Document which responsibilities belong to pt (bash)\n- Document which responsibilities belong to pt-core (Rust)\n- Define the interface between them (capabilities manifest format)\n- Define version coordination between wrapper and core\n\n## Technical Considerations\n- Wrapper must detect OS, package manager, available tools\n- Wrapper should attempt maximal tool installation (see Phase 3a)\n- Wrapper passes capabilities manifest to core via CLI flag or env\n- Core should have a standalone mode for testing without wrapper\n\n## Acceptance Criteria\n- Clear specification document exists\n- Capabilities manifest schema is defined\n- Both teams (if multiple) can work independently against the interface","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:20:22.103055986-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:20:22.103055986-05:00"}
{"id":"process_triage-m99","title":"Implement Beta-Bernoulli posterior predictive","description":"## Task\nImplement the Beta-Bernoulli posterior predictive for binary features.\n\n## Background\nBinary features (orphan, TTY, net activity) use Beta-Bernoulli:\n- Prior: p ~ Beta(a, b)\n- Observation: x | p ~ Bernoulli(p)\n- Posterior: Beta(a + x, b + 1 - x)\n- Posterior predictive: P(x_new=1) = (a + k) / (a + b + n)\n\nwhere k is sum of observed successes and n is total observations.\n\n## Functions Needed\n- beta_bernoulli_pred(x, a, b) = a/(a+b) if x=1, else b/(a+b)\n- log_beta_bernoulli_pred(x, a, b)\n- beta_bernoulli_update(a, b, x) → (a_new, b_new)\n\n## Implementation Notes\n- Very simple but must be log-stable\n- Used heavily in posterior computation\n- a/(a+b) can underflow for very small a,b\n\n## Test Cases\n- Uniform prior (1,1): 50/50 prediction\n- Strong prior (100,1): nearly certain prediction\n- Update correctness: sequential updates = batch update\n\n## Deliverables\n- Rust functions in math/beta_bernoulli.rs\n- Unit tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:23:31.238037193-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:23:31.238037193-05:00"}
{"id":"process_triage-maq","title":"Implement process signature schema and matcher","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:34:57.645107988-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:34:57.645107988-05:00"}
{"id":"process_triage-mty","title":"Implement supervisor detection integration in action phase","description":"## Overview\nIntegrate supervisor detection results into action execution planning.\n\n## Background\nBefore executing kill actions, we must detect whether processes are being actively supervised by agents (Claude, Codex, etc.). The plan specifies that supervised processes should NEVER be auto-killed in non-interactive modes, and require explicit user override in interactive mode.\n\n## Why It Matters\nKilling a process that an AI agent is actively managing could corrupt a multi-step workflow, lose valuable work, or cause cascade failures in automated systems. This is a critical safety mechanism.\n\n## Technical Approach\n1. Parse supervisor detection results from Phase 10 components\n2. Annotate action plans with supervisor status\n3. Block auto-actions on supervised processes (policy.json: require_human_for_supervised)\n4. Add supervisor warning to confirmation prompts\n5. Log supervisor overrides with full context\n\n## Integration Points\n- Reads supervisor detection results from deep scan\n- Modifies action plan generation to include supervisor metadata\n- Hooks into confirmation dialog system\n- Integrates with policy.json guardrails\n\n## Success Criteria\n- Supervised processes clearly marked in action plans\n- Auto-kill blocked when supervisor detected\n- Override path requires explicit confirmation\n- Full audit trail of supervisor-related decisions","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:31:15.055151789-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:31:54.009721679-05:00"}
{"id":"process_triage-myq","title":"Implement evidence ledger generation","description":"## Task\nImplement the evidence ledger that explains each feature's contribution to the classification.\n\n## Background\nSection 7.1-7.2 specify explainability requirements:\n- Show posterior, Bayes factors, evidence contributions, confidence\n- Top 3 Bayes factors should be highlighted\n- Evidence glyphs for I/O, CPU, TTY, orphan, etc.\n\nThe ledger enables:\n- Galaxy-brain mode visualization\n- 'Why' summaries for users\n- Debugging of unexpected classifications\n\n## Ledger Structure\nPer process:\n{\n  \"pid\": 1234,\n  \"classification\": \"abandoned\",\n  \"posterior\": {...},\n  \"confidence\": \"high\",\n  \"bayes_factors\": [\n    {\"feature\": \"tty_detached\", \"bf\": 15.2, \"direction\": \"toward_abandoned\", \"strength\": \"strong\"},\n    {\"feature\": \"cpu_pattern\", \"bf\": 8.4, ...},\n    {\"feature\": \"orphan\", \"bf\": 3.1, ...}\n  ],\n  \"top_evidence\": [\"No TTY for 4h\", \"CPU at 98% for 2h\", \"Orphaned (PPID=1)\"],\n  \"evidence_glyphs\": {\"io\": \"⚡\", \"cpu\": \"🔥\", \"tty\": \"💀\", \"orphan\": \"👻\"},\n  \"why_summary\": \"Process has no controlling terminal, high sustained CPU, and was orphaned. Strong evidence of stuck test runner.\"\n}\n\n## Implementation Notes\n- Compute Bayes factors from log-likelihood differences\n- Sort by BF magnitude\n- Generate human-readable summaries\n- Map features to glyphs consistently\n\n## Deliverables\n- Rust module: inference/ledger.rs\n- Glyph mapping table\n- Summary generation logic\n- Unit tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:26:41.547041418-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:26:41.547041418-05:00"}
{"id":"process_triage-n0r","title":"Installation Infrastructure","description":"## Overview\nCreate a professional installation script (install.sh) that matches the quality of repo_updater and giil installers.\n\n## Current State\n- README suggests manual: `git clone` + `ln -s`\n- No one-liner installation\n- No checksum verification option\n- No PATH management\n- No upgrade detection\n\n## Target State\nA polished installer supporting:\n```bash\n# One-liner install (like giil/repo_updater)\ncurl -fsSL https://raw.githubusercontent.com/USER/process_triage/main/install.sh | bash\n\n# With verification\nVERIFY=1 curl -fsSL .../install.sh | bash\n\n# Custom location\nDEST=/custom/path curl -fsSL .../install.sh | bash\n\n# System-wide\nPT_SYSTEM=1 curl -fsSL .../install.sh | bash\n```\n\n## Key Features (from repo_updater/giil)\n\n### 1. Self-Refresh Mechanism\nWhen piped from curl, the installer re-fetches itself to avoid CDN stale cache issues:\n```bash\nmaybe_self_refresh_installer() {\n    if [[ -p /dev/stdin ]]; then\n        # Being piped - re-download fresh copy\n        exec bash \u003c(curl -fsSL \"$INSTALLER_URL?cb=$(date +%s)\")\n    fi\n}\n```\n\n### 2. Cache-Busting\nAppend timestamp to URLs to bypass CDN caching:\n```bash\nappend_cache_buster() {\n    local url=\"$1\"\n    echo \"${url}?cb=$(date +%s)\"\n}\n```\n\n### 3. Cross-Platform mktemp\n```bash\nmktemp_dir() {\n    mktemp -d 2\u003e/dev/null ||           # GNU (Linux)\n    mktemp -d -t pt 2\u003e/dev/null ||     # BSD (macOS)\n    mktemp -d -t pt.XXXXXXXXXX         # BSD fallback\n}\n```\n\n### 4. Multi-Package-Manager gum Installation\nSupport: apt, dnf, pacman, brew, direct binary download\n\n### 5. Optional Checksum Verification\n```bash\nif [[ \"${VERIFY:-}\" == \"1\" ]]; then\n    verify_checksum \"$downloaded_file\" \"$version\"\nfi\n```\n\n### 6. PATH Management\n- Auto-detect shell (bash, zsh, fish)\n- Add to appropriate config file\n- Skip if already in PATH\n- Disable with PT_NO_PATH=1\n\n### 7. Upgrade Detection\n- Show current → new version\n- Handle re-install of same version gracefully\n\n## Environment Variables\n| Variable | Purpose |\n|----------|---------|\n| DEST | Custom install directory |\n| PT_SYSTEM | Install to /usr/local/bin |\n| PT_NO_PATH | Skip PATH modification |\n| VERIFY | Enable checksum verification |\n| PT_VERSION | Install specific version |\n\n## Success Criteria\n- [ ] One-liner install works on Linux and macOS\n- [ ] Checksum verification works when enabled\n- [ ] PATH is correctly managed for bash/zsh/fish\n- [ ] Upgrade detection shows version changes\n- [ ] Clear success/failure messaging\n- [ ] Handles curl and wget as download tools","status":"open","priority":1,"issue_type":"epic","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:32:41.602455595-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:32:41.602455595-05:00"}
{"id":"process_triage-nao","title":"EPIC: Phase 4 - Inference Engine Integration","description":"## Overview\nThis epic covers integrating all the math primitives and collected evidence into a coherent Bayesian inference engine that produces posteriors, Bayes factors, and explainability ledgers.\n\n## Background \u0026 Context\nSection 4 of the plan specifies a sophisticated inference architecture:\n- Closed-form Bayesian core (no ML black boxes)\n- State space: {useful, useful-but-bad, abandoned, zombie}\n- Conjugate priors throughout (Beta, Gamma, Dirichlet)\n- Multiple layers: base Bayes, Hawkes processes, BOCPD, copulas, etc.\n- All layers feed deterministic summaries to the closed-form core\n\n## Why This Matters\n- **Auditability**: Every decision traceable to equations and evidence\n- **Correctness**: Conjugate priors guarantee proper probability updates\n- **Transparency**: Galaxy-brain mode shows the full math\n- **Robustness**: Multiple layers handle different evidence types\n\n## Scope\n1. Core posterior computation P(C|x)\n2. Evidence ledger generation (per-feature contributions)\n3. Bayes factor computation for each feature\n4. Hawkes/marked point process layers for bursty events\n5. BOCPD for regime change detection\n6. Copula dependence modeling\n7. Kalman smoothing for noisy signals\n8. Belief propagation on PPID trees\n9. Wavelet/spectral features\n10. Model averaging and DRO layers\n\n## Success Criteria\n- Posteriors match analytical solutions on test cases\n- Evidence ledger accurately reflects each term's contribution\n- Inference completes within overhead budget\n- Galaxy-brain output matches underlying computation\n\n## Technical Constraints\n- Must remain closed-form (no iterative optimization in core)\n- Complex layers produce features, not posteriors directly\n- All computation auditable via ledger","status":"open","priority":0,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:26:39.727725005-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:26:39.727725005-05:00"}
{"id":"process_triage-nk1","title":"Create VERSION file as single source of truth","description":"## Purpose\nCreate a VERSION file that serves as the single source of truth for the project version, matching the pattern used in repo_updater and giil.\n\n## Why a Separate VERSION File?\n1. **CI/CD Access**: GitHub Actions can read it without parsing bash\n2. **Installer Access**: install.sh can fetch it independently\n3. **Self-Update**: Update checker compares against this file\n4. **Consistency Checks**: CI validates VERSION file matches script constant\n\n## Implementation\n\n### 1. Create VERSION file\n```\n1.0.0\n```\n(Just the version number, no newline issues - use `echo -n` or ensure single line)\n\n### 2. Update pt script to read from VERSION or define constant\n```bash\n# Option A: Read from file (if present)\nif [[ -f \"${BASH_SOURCE[0]%/*}/VERSION\" ]]; then\n    VERSION=\"$(\u003c \"${BASH_SOURCE[0]%/*}/VERSION\")\"\nelse\n    VERSION=\"1.0.0\"  # Fallback for standalone execution\nfi\n\n# Option B: Keep constant in script (simpler, CI validates consistency)\nVERSION=\"1.0.0\"\n```\n\n### 3. Ensure VERSION constant exists in script\nThe script already has VERSION=\"1.0.0\" on line 5. This is correct.\nThe VERSION file should match this value.\n\n## File Location\n```\nprocess_triage/\n├── VERSION          # ← New file\n├── pt\n├── ...\n```\n\n## Validation (for CI)\n```bash\nfile_version=$(cat VERSION)\nscript_version=$(grep '^VERSION=' pt | cut -d'\"' -f2)\n[[ \"$file_version\" == \"$script_version\" ]] || {\n    echo \"VERSION mismatch: file=$file_version, script=$script_version\"\n    exit 1\n}\n```\n\n## Success Criteria\n- [ ] VERSION file exists with current version\n- [ ] Script VERSION constant matches file\n- [ ] No trailing newline issues\n- [ ] File is tracked in git\n\n## Parent Epic\nThis is a foundational task for: Self-Update Mechanism (process_triage-097)","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:33:31.38327042-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:33:31.38327042-05:00"}
{"id":"process_triage-o0w","title":"Implement Value of Information (VOI)","description":"## Task\nImplement Value of Information for deciding whether to probe more or act now.\n\n## Background\nSection 5.3 specifies:\nVOI = E[loss_now - loss_after_measurement] - cost(measurement/waiting)\n\nIf VOI ≤ 0: act now (measurement not worth it)\nIf VOI \u003e 0: spend budget on measurement\n\n## Purpose\n- Avoid over-probing (expensive when low value)\n- Avoid under-probing (act prematurely)\n- Guide probe selection (which measurement next?)\n\n## Implementation Notes\n- Compute expected loss under current belief\n- Estimate posterior after measurement (using prior predictive)\n- Compute expected loss after update\n- Subtract cost of measurement\n- Compare probes by VOI/cost ratio\n\n## Probes to Consider\n- wait_15min: free but slow\n- deep_scan: moderate cost, good info\n- stack_sample: higher cost, specific info\n- strace: high cost, high info\n\n## Output Structure\n{\n  \"voi_analysis\": {\n    \"current_loss\": 25.3,\n    \"probes\": [\n      {\"probe\": \"wait_15min\", \"voi\": 2.1, \"cost\": 0.5, \"ratio\": 4.2},\n      {\"probe\": \"deep_scan\", \"voi\": 3.5, \"cost\": 1.0, \"ratio\": 3.5}\n    ],\n    \"best_probe\": \"wait_15min\",\n    \"act_now\": false\n  }\n}\n\n## Galaxy-Brain Card\nvoi card shows equation and current values\n\n## Deliverables\n- Rust module: decision/voi.rs\n- Per-probe cost model\n- Expected loss after measurement estimation\n- Unit tests\n- Documentation","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:28:42.698666302-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:28:42.698666302-05:00"}
{"id":"process_triage-o8m","title":"Define target identity and privilege contracts","description":"## Task\nSpecify the identity tuple used to safely target processes and the privilege model for cross-UID actions.\n\n## Background\nPID reuse is a fundamental safety concern. A process may die and its PID may be reused by the time an action is attempted. The plan specifies:\n- Identity tuple: (pid, start_id, uid, ...) where start_id is process start time\n- Revalidation: Must verify identity immediately before any action\n- Privilege scope: Default to same-UID only; cross-UID requires explicit policy\n\nSection 3.0 also specifies coordination:\n- Per-user 'pt lock' to prevent manual/agent/daemon races\n- Lock acquisition before any destructive action\n- Queuing behavior when lock is held\n\n## Deliverables\n- Identity tuple specification (what fields, how computed)\n- start_id format (e.g., epoch.pid for uniqueness)\n- Revalidation protocol (what to check, when)\n- Privilege levels:\n  - own_user: only processes owned by invoking user\n  - sudo: can target other users with sudo\n  - root: full system access\n- Lock semantics and coordination protocol\n- Error handling for identity mismatch\n\n## Technical Considerations\n- start_id from /proc/[pid]/stat (field 22, start time in jiffies)\n- Convert to epoch+pid for stability across reboots\n- Lock file location: ~/.local/share/pt/locks/\n- Lock must include session_id for debugging\n- Timeout for stale locks\n\n## Safety Implications\nWithout proper identity verification:\n- Could kill wrong process after PID reuse\n- Could affect processes user doesn't own\n- Concurrent pt runs could conflict","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:22:01.83926127-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:22:01.83926127-05:00"}
{"id":"process_triage-omq","title":"Add bash syntax validation job to CI","description":"## Purpose\nAdd a CI job that validates bash syntax using `bash -n` to catch parse errors.\n\n## Parent Epic\nGitHub Actions CI/CD Pipeline (process_triage-68c)\n\n## Depends On\n- Create ci.yml with ShellCheck job (add to same file)\n\n## Why bash -n?\n- Catches syntax errors that would cause script to fail\n- Catches unterminated heredocs\n- Catches mismatched quotes/brackets\n- Fast (no execution, just parsing)\n\n## Implementation\n\n### Add to ci.yml\n```yaml\n  syntax:\n    name: Bash Syntax\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      \n      - name: Validate pt syntax\n        run: bash -n pt\n      \n      - name: Validate install.sh syntax\n        run: bash -n install.sh\n      \n      - name: Validate test files\n        run: |\n          for file in test/*.bats; do\n            echo \"Checking $file...\"\n            # BATS files aren't pure bash, but we can check helper functions\n            # Skip actual test cases which use BATS syntax\n            bash -n \"$file\" 2\u003e/dev/null || true\n          done\n```\n\n## Note on BATS Files\nBATS files use special syntax (`@test`, `load`) that isn't valid bash.\nThe syntax check for .bats files may show warnings - that's expected.\nWe primarily care about pt and install.sh.\n\n## Success Criteria\n- [ ] Syntax job added to ci.yml\n- [ ] pt passes bash -n\n- [ ] install.sh passes bash -n\n- [ ] Job fails if syntax error introduced","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:37:31.687777577-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:37:31.687777577-05:00","dependencies":[{"issue_id":"process_triage-omq","depends_on_id":"process_triage-i5r","type":"blocks","created_at":"2026-01-14T22:40:46.266216181-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-or6","title":"Implement atomic file replacement","description":"## Purpose\nReplace the running script atomically to prevent corruption if the update is interrupted.\n\n## Parent Epic\nSelf-Update Mechanism (process_triage-097)\n\n## Depends On\n- Add bash syntax validation before replacement\n\n## The Problem\nNon-atomic replacement:\n```bash\n# DANGEROUS: If interrupted mid-write, file is corrupted\ncat downloaded_file \u003e /path/to/pt\n```\n\nAtomic replacement:\n```bash\n# SAFE: Either old file or new file, never partial\nmv temp_file /path/to/pt\n```\n\n## Implementation\n\n### Atomic Replacement Function\n```bash\natomic_replace() {\n    local source=\"$1\"\n    local target=\"$2\"\n    \n    # Preserve permissions from original\n    local perms\n    if [[ -f \"$target\" ]]; then\n        perms=$(stat -c '%a' \"$target\" 2\u003e/dev/null || stat -f '%Lp' \"$target\" 2\u003e/dev/null)\n    else\n        perms=\"755\"\n    fi\n    \n    # Set permissions on new file\n    chmod \"$perms\" \"$source\"\n    \n    # Atomic move\n    # mv is atomic on POSIX filesystems when source and target are on same filesystem\n    if \\! mv \"$source\" \"$target\"; then\n        log_error \"Failed to replace $target\"\n        log_error \"The original file is unchanged.\"\n        return 1\n    fi\n    \n    log_success \"Replaced $target\"\n    return 0\n}\n```\n\n### Complete Update Flow\n```bash\ndo_update() {\n    local version=\"$1\"\n    local script_path\n    \n    # Get path to currently running script\n    script_path=\"$(readlink -f \"${BASH_SOURCE[0]}\" 2\u003e/dev/null || realpath \"${BASH_SOURCE[0]}\" 2\u003e/dev/null)\"\n    \n    # Check we can write to target directory\n    local target_dir=\"${script_path%/*}\"\n    if [[ \\! -w \"$target_dir\" ]]; then\n        log_error \"Cannot write to $target_dir\"\n        log_error \"Try running with sudo, or move pt to a writable location.\"\n        return 1\n    fi\n    \n    # Create temp file IN SAME DIRECTORY (required for atomic mv)\n    local temp_file\n    temp_file=\"$(mktemp \"${script_path}.update.XXXXXX\")\"\n    \n    # Cleanup on exit\n    trap \"rm -f '$temp_file' 2\u003e/dev/null\" EXIT\n    \n    # Download\n    log_step \"Downloading pt v${version}...\"\n    if \\! curl -fsSL \"${RELEASES_URL}/download/v${version}/pt\" -o \"$temp_file\"; then\n        log_error \"Download failed\"\n        return 1\n    fi\n    \n    # Verify checksum\n    if \\! verify_checksum \"$temp_file\" \"$version\"; then\n        return 1\n    fi\n    \n    # Validate script\n    if \\! validate_script \"$temp_file\"; then\n        return 1\n    fi\n    \n    # Atomic replacement\n    log_step \"Installing update...\"\n    if \\! atomic_replace \"$temp_file\" \"$script_path\"; then\n        return 1\n    fi\n    \n    log_success \"Updated to pt v${version}\"\n    log_info \"Run 'pt --version' to verify.\"\n    \n    # Clear trap (file was moved, not deleted)\n    trap - EXIT\n    \n    return 0\n}\n```\n\n### Why Same Directory for Temp File?\n`mv` is only atomic when source and target are on the same filesystem.\n- If temp file is in /tmp and target is in /usr/local/bin, mv does a copy+delete (not atomic)\n- Creating temp file in same directory guarantees same filesystem\n\n### Cross-Platform stat\n```bash\n# Linux (GNU coreutils)\nstat -c '%a' file\n\n# macOS/BSD\nstat -f '%Lp' file\n```\n\n## Success Criteria\n- [ ] Temp file created in same directory as target\n- [ ] Permissions preserved from original\n- [ ] mv used for atomic replacement\n- [ ] Failure leaves original file unchanged\n- [ ] Cleanup on error (temp file removed)\n- [ ] Write permission checked before download","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:35:07.503149012-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:35:07.503149012-05:00","dependencies":[{"issue_id":"process_triage-or6","depends_on_id":"process_triage-nk1","type":"blocks","created_at":"2026-01-14T22:52:20.721805635-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-p15","title":"EPIC: Phase 5 - Decision Theory Engine","description":"## Overview\nThis epic covers the decision-making machinery that transforms posteriors into optimal actions.\n\n## Background \u0026 Context\nSection 5 specifies decision-theoretic foundations:\n- Expected loss minimization: a* = argmin_a Σ_C L(a,C) P(C|x)\n- SPRT-style threshold for kill decisions\n- Value of Information for probe selection\n- FDR control across multiple processes\n- Alpha-investing for long-term safety\n- Goal-oriented optimization\n\n## Why This Matters\n- **Optimal Actions**: Minimize expected regret\n- **Safety**: FDR/alpha-investing prevent error accumulation\n- **Efficiency**: VOI avoids unnecessary probing\n- **Goal Achievement**: Meet user resource targets\n\n## Scope\n1. Expected loss computation\n2. SPRT threshold calculation\n3. Value of Information\n4. FDR-gated kill set selection (e-values, BH/BY)\n5. Alpha-investing online budget\n6. Queueing-theoretic load adjustment\n7. Dependency-weighted loss\n8. Risk-sensitive control (CVaR)\n9. Whittle index for probe scheduling\n10. Goal-oriented optimization\n\n## Success Criteria\n- Decisions match analytical optimal on test cases\n- FDR control verified in simulation\n- Alpha-investing maintains safety over time\n- Goal optimization achieves targets when feasible\n\n## Technical Constraints\n- Decision must be traceable to math\n- Safety properties must be provable\n- Performance must scale to many processes","status":"open","priority":0,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:28:14.318767675-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:28:14.318767675-05:00"}
{"id":"process_triage-psc","title":"Implement shadow mode observation storage","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:34:48.513144299-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:34:48.513144299-05:00"}
{"id":"process_triage-qa9","title":"Implement capability detection and caching","description":"## Task\nImplement system capability detection that determines what tools and features are available.\n\n## Background\nAfter tools are installed (or attempted), we need to know what's actually usable:\n- Which tools are present and executable?\n- What permissions does the user have?\n- What kernel features are available?\n- What can we actually collect?\n\n## Capabilities to Detect\n- **Platform**: Linux/macOS/FreeBSD, kernel version, in container?\n- **Data sources**: procfs, sysfs, perf_events, ebpf, schedstat\n- **Tools**: For each tool, check: exists? version? works?\n- **Permissions**: effective UID, sudo available?, capabilities (CAP_SYS_PTRACE, etc.)\n- **Supervisors**: systemd, launchd, pm2, Docker available?\n- **Actions**: What can we do? kill, pause, renice, cgroup ops?\n\n## Implementation Notes\n- Run detection scripts at install time and cache\n- Re-detect if cache is stale (\u003e24h or explicit refresh)\n- Test tools actually work (not just exist)\n- Handle partial capabilities (sudo works for some things)\n\n## Output Format\n{\n  \"platform\": {\"os\": \"linux\", \"kernel\": \"6.1.0\", \"in_container\": false},\n  \"data_sources\": {\"procfs\": true, \"perf_events\": true, \"ebpf\": false},\n  \"tools\": {\"perf\": {\"available\": true, \"version\": \"6.1\"}, ...},\n  \"permissions\": {\"effective_uid\": 1000, \"can_sudo\": true, \"capabilities\": [...]},\n  \"detected_at\": \"2025-01-15T14:30:00Z\"\n}\n\n## Deliverables\n- Rust module: capabilities/detect.rs\n- Cache management: capabilities/cache.rs\n- CLI command: pt agent capabilities\n- Unit tests\n- Documentation","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:25:37.679880159-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:25:37.679880159-05:00"}
{"id":"process_triage-qje","title":"Define session model and artifact directory layout","description":"## Task\nSpecify the durable session model including:\n- Session ID generation scheme\n- Artifact directory structure\n- What artifacts exist for different run types\n- Session lifecycle states\n\n## Background\nSessions are central to pt's design:\n- Every run gets a session_id\n- Sessions persist to ~/.local/share/pt/sessions/\u003csession_id\u003e/\n- Sessions contain: initial snapshot, plan, telemetry, outcomes, audit log\n- Default retention: 7 days (configurable)\n- Sessions can be exported as .ptb bundles\n\nSession states:\n- planned (plan generated, awaiting action)\n- applied (actions executed)\n- interrupted (resumable)\n- completed (verified outcomes)\n\n## Deliverables\n- Session ID format specification (e.g., snap-20250115-143022-abc123)\n- Directory structure specification with file purposes\n- Session state machine with valid transitions\n- Retention policy specification\n- Cleanup semantics (what's preserved for priors/audit)\n\n## Technical Considerations\n- session_id must be URL-safe and sortable by time\n- Directory must support append-only writes during scan\n- Failures during scan should still leave analyzable artifacts\n- Session context must be efficiently loadable for resume operations\n\n## Dependency Chain\nThis informs how telemetry is written (Phase 3) and how bundles are created (Phase 7).","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:20:56.697638185-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:20:56.697638185-05:00"}
{"id":"process_triage-rqn","title":"Implement Beta distribution utilities","description":"## Task\nImplement Beta distribution functions needed for posterior computation.\n\n## Background\nThe Beta distribution is conjugate to Bernoulli/Binomial and appears throughout:\n- Prior on Bernoulli success probability\n- Posterior after observing successes/failures\n- Posterior predictive for next observation\n\nRequired functions:\n- beta_pdf(x, alpha, beta) - probability density\n- beta_cdf(x, alpha, beta) - cumulative distribution\n- beta_inv_cdf(p, alpha, beta) - quantile function\n- beta_mean(alpha, beta) = alpha / (alpha + beta)\n- beta_var(alpha, beta) = alpha*beta / ((alpha+beta)^2 * (alpha+beta+1))\n- log_beta_pdf(x, alpha, beta) - log-domain for stability\n\n## Implementation Notes\n- Use log-beta function for numerical stability\n- log_beta(a,b) = lgamma(a) + lgamma(b) - lgamma(a+b)\n- Handle edge cases: x=0, x=1, alpha\u003c1, beta\u003c1\n- Consider using Stirling approximation for large parameters\n\n## Test Cases\n- Beta(1,1) = Uniform(0,1)\n- Beta(2,5): mean=2/7, mode=1/5\n- Symmetry: Beta(a,b) at x = Beta(b,a) at 1-x\n- Known quantiles from tables\n\n## Deliverables\n- Rust module: math/beta.rs\n- Unit tests with comprehensive coverage\n- Documentation with equations\n- Benchmarks for performance verification","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:23:03.702110629-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:23:03.702110629-05:00"}
{"id":"process_triage-rtb","title":"Implement failure recovery and retry logic","description":"## Overview\nImplement robust failure recovery and intelligent retry logic for action execution.\n\n## Background\nProcess termination can fail for many reasons: permission denied, process already gone, signal handling by the process, race conditions. The plan specifies a staged approach: SIGTERM → wait → SIGKILL, with exponential backoff and configurable retries.\n\n## Why It Matters\nNaive retry logic can cause confusion (multiple signals to same PID), waste time (retrying permission errors), or miss opportunities (process respawned with new PID). Intelligent failure handling improves reliability and user experience.\n\n## Technical Approach\n1. Classify failure types:\n   - Transient (EAGAIN, timeout) → retry with backoff\n   - Permanent (EPERM, ESRCH) → fail fast with clear message\n   - Partial (SIGTERM ignored) → escalate to SIGKILL\n2. Implement exponential backoff with jitter\n3. Track attempt history for audit log\n4. Detect respawned processes (same command, new PID)\n5. Provide structured failure reports\n\n## Signal Escalation Protocol\n- Attempt 1: SIGTERM, wait policy.json:term_grace_seconds (default 5s)\n- Attempt 2: If still running, SIGKILL\n- Attempt 3: If still running after SIGKILL, report as unkillable (kernel zombie or protected)\n\n## Success Criteria\n- Transient failures auto-recovered\n- Permanent failures reported immediately\n- Signal escalation works correctly\n- Respawned process detection functional\n- Comprehensive failure audit trail","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:31:15.792131223-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:31:54.947491682-05:00"}
{"id":"process_triage-sj6","title":"EPIC: Phase 6 - Action Execution System","description":"## Overview\nThis epic covers the action execution system that safely applies decisions to processes.\n\n## Background \u0026 Context\nSection 6 specifies an action space beyond just kill:\n- keep, pause, resume, renice, cgroup freeze, cgroup throttle\n- cpuset quarantine, supervisor stop/restart\n- zombie resolution (parent reaping)\n- kill (SIGTERM → SIGKILL)\n\nActions must be:\n- Safe (identity verified, privilege checked)\n- Staged (less destructive first)\n- Reversible (when possible)\n- Auditable (fully logged)\n\n## Why This Matters\n- **Safety**: Wrong action on wrong process is catastrophic\n- **Reversibility**: Prefer pause over kill when possible\n- **Coordination**: Handle supervised processes correctly\n- **Auditability**: Every action must be traceable\n\n## Scope\n1. Action plan generation (per-PID with ordering)\n2. Identity revalidation before action\n3. Staged execution protocol\n4. Post-action verification\n5. Failure recovery trees\n6. Session/TTY protection\n7. Lock coordination\n\n## Success Criteria\n- No PID reuse errors in testing\n- Actions respect staging order\n- Failures trigger recovery tree\n- All actions logged with outcomes\n\n## Technical Constraints\n- Must revalidate (pid, start_id, uid) before action\n- Default to same-UID only\n- Acquire pt lock before action\n- Protect current session","status":"open","priority":0,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:29:47.221266355-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:29:47.221266355-05:00"}
{"id":"process_triage-sqe","title":"Implement FDR control via e-values and BH/BY","description":"## Task\nImplement False Discovery Rate control for safe multi-process decisions.\n\n## Background\nSection 4.32 and 5.8 specify FDR control:\n- Treat kill recommendations as multiple hypothesis tests\n- Use local false discovery rate (lfdr) or e-values\n- Apply BH/BY procedure for dependent hypotheses\n- Default to conservative BY under unknown dependence\n\n## e-Value Approach (Preferred)\n1. Compute e_i from Bayes factor (e_i = BF for abandoned vs useful)\n2. Sort e-values descending\n3. Map to p-values: p_i = min(1, 1/e_i)\n4. BH: choose largest k with p_(k) ≤ (α×k)/m\n5. BY: choose largest k with p_(k) ≤ (α×k)/(m×c(m))\n\n## Why e-Values\n- Anytime-valid (sequential testing ok)\n- Works with optional stopping\n- Handles repeated scans correctly\n\n## Implementation Notes\n- Compute e-value per process\n- Sort and apply BH or BY\n- Return kill set with FDR guarantee\n- Handle process dependencies (prefer BY)\n\n## Output Structure\n{\n  \"fdr_control\": {\n    \"alpha\": 0.05,\n    \"method\": \"BY\",\n    \"candidates\": 15,\n    \"selected_k\": 3,\n    \"kill_set\": [1234, 2345, 3456],\n    \"estimated_fdr\": 0.04\n  }\n}\n\n## Galaxy-Brain Card\ne_fdr card shows e-values, p-values, selection\n\n## Deliverables\n- Rust module: decision/fdr.rs\n- e-value computation\n- BH/BY procedures\n- Unit tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:28:43.876530065-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:28:43.876530065-05:00"}
{"id":"process_triage-tcf","title":"Implement conformal prediction for robust intervals","description":"## Task\nImplement conformal prediction for distribution-free prediction intervals.\n\n## Background\nSection 4.31 specifies conformal prediction:\n- Distribution-free under exchangeability\n- Regression-style intervals for runtime/CPU\n- Classification-style prediction sets for state\n\n## Regression Conformal (Runtime/CPU)\n1. Choose predictor ŷ and score s_i = |y_i - ŷ_i|\n2. q = ⌈(n+1)(1-α)⌉-th smallest score in calibration window\n3. Interval: [ŷ_{n+1} - q, ŷ_{n+1} + q]\n4. Guarantees P(y_{n+1} ∈ interval) ≥ 1-α under exchangeability\n\n## Classification Conformal (State)\n1. Score s_i = 1 - P̂(C=y_i | x_i)\n2. For candidate label c: s_{n+1}(c) = 1 - P̂(C=c | x_{n+1})\n3. p-value: p_c = (1 + #{i: s_i ≥ s_{n+1}(c)}) / (n+1)\n4. Prediction set: {c : p_c \u003e α}\n\n## Implementation Notes\n- Use rolling window for calibration\n- Handle temporal dependence (blocked conformal)\n- Report coverage alongside intervals\n- Optional Mondrian (label-conditional) variant\n\n## Galaxy-Brain Cards\n- conformal_interval: shows scores, quantile, interval\n- conformal_class: shows p-values per class, prediction set\n\n## Deliverables\n- Rust module: inference/conformal.rs\n- Regression and classification variants\n- Calibration window management\n- Unit tests\n- Documentation","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:27:44.639067353-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:27:44.639067353-05:00"}
{"id":"process_triage-ucg","title":"Add scoring system unit tests","description":"## Purpose\nAdd comprehensive tests for the process scoring heuristics system.\n\n## Parent Epic\nExpanded Test Coverage (process_triage-bgd)\n\n## Current State\nNo tests exist for the scoring system, which is the core logic of pt.\n\n## Implementation\n\n### test/test_scoring.bats\n```bash\n#!/usr/bin/env bats\n\nsetup() {\n    # Source the pt script to get access to functions\n    # We need to extract functions or source with modifications\n    export TEST_MODE=1\n    source \"${BATS_TEST_DIRNAME}/../pt\" 2\u003e/dev/null || true\n}\n\n#------------------------------------------------------------------------------\n# Age-based scoring tests\n#------------------------------------------------------------------------------\n\n@test \"score_process: age \u003e 1 week gets +50\" {\n    # 8 days in seconds = 691200\n    local result\n    result=$(score_process 1234 1000 691200 100 \"some process\")\n    local score=${result%%|*}\n    \n    (( score \u003e= 50 ))\n}\n\n@test \"score_process: age \u003e 2 days gets +30\" {\n    # 3 days = 259200 seconds\n    local result\n    result=$(score_process 1234 1000 259200 100 \"some process\")\n    local score=${result%%|*}\n    \n    (( score \u003e= 30 \u0026\u0026 score \u003c 50 ))\n}\n\n@test \"score_process: age \u003e 1 day gets +20\" {\n    # 1.5 days = 129600 seconds\n    local result\n    result=$(score_process 1234 1000 129600 100 \"some process\")\n    local score=${result%%|*}\n    \n    (( score \u003e= 20 ))\n}\n\n@test \"score_process: age \u003c 1 day gets minimal score\" {\n    # 2 hours = 7200 seconds\n    local result\n    result=$(score_process 1234 1000 7200 100 \"some process\")\n    local score=${result%%|*}\n    \n    (( score \u003c 20 ))\n}\n\n#------------------------------------------------------------------------------\n# Orphan detection tests\n#------------------------------------------------------------------------------\n\n@test \"score_process: PPID=1 (orphan) gets +25\" {\n    # PPID=1 means parent died, process adopted by init\n    local result\n    result=$(score_process 1234 1 7200 100 \"orphaned process\")\n    local score=${result%%|*}\n    \n    (( score \u003e= 25 ))\n}\n\n@test \"score_process: normal PPID doesn't get orphan bonus\" {\n    local result\n    result=$(score_process 1234 5678 7200 100 \"normal process\")\n    local score=${result%%|*}\n    \n    # Should be much lower without orphan bonus\n    (( score \u003c 25 ))\n}\n\n#------------------------------------------------------------------------------\n# Pattern matching tests\n#------------------------------------------------------------------------------\n\n@test \"score_process: stuck test runner (bun test) gets +40\" {\n    # Age \u003e 1 hour = 3601 seconds\n    local result\n    result=$(score_process 1234 1000 3601 100 \"bun test --watch\")\n    local score=${result%%|*}\n    \n    (( score \u003e= 40 ))\n}\n\n@test \"score_process: stuck test runner (jest) gets +40\" {\n    local result\n    result=$(score_process 1234 1000 3601 100 \"node jest --runInBand\")\n    local score=${result%%|*}\n    \n    (( score \u003e= 40 ))\n}\n\n@test \"score_process: stuck test runner (pytest) gets +40\" {\n    local result\n    result=$(score_process 1234 1000 3601 100 \"python -m pytest\")\n    local score=${result%%|*}\n    \n    (( score \u003e= 40 ))\n}\n\n@test \"score_process: old dev server (next dev) gets +20\" {\n    # Age \u003e 2 days = 172801 seconds\n    local result\n    result=$(score_process 1234 1000 172801 100 \"next dev --port 3000\")\n    local score=${result%%|*}\n    \n    (( score \u003e= 20 ))\n}\n\n@test \"score_process: agent shell (claude) gets +35\" {\n    # Age \u003e 1 day = 86401 seconds\n    local result\n    result=$(score_process 1234 1000 86401 100 \"/bin/bash -c claude something\")\n    local score=${result%%|*}\n    \n    (( score \u003e= 35 ))\n}\n\n#------------------------------------------------------------------------------\n# Protection tests\n#------------------------------------------------------------------------------\n\n@test \"score_process: systemd service gets -200 (protected)\" {\n    local result\n    result=$(score_process 1234 1 691200 1000 \"/usr/lib/systemd/systemd\")\n    local score=${result%%|*}\n    \n    # Negative score = protected\n    (( score \u003c 0 ))\n}\n\n@test \"score_process: sshd is protected\" {\n    local result\n    result=$(score_process 1234 1 691200 1000 \"sshd: user@pts/0\")\n    local score=${result%%|*}\n    \n    (( score \u003c 0 ))\n}\n\n@test \"score_process: docker is protected\" {\n    local result\n    result=$(score_process 1234 1 691200 1000 \"dockerd --host=unix:///var/run/docker.sock\")\n    local score=${result%%|*}\n    \n    (( score \u003c 0 ))\n}\n\n#------------------------------------------------------------------------------\n# Memory hog tests\n#------------------------------------------------------------------------------\n\n@test \"score_process: high memory + old gets +15\" {\n    # \u003e 2000MB and \u003e 12 hours (43200 seconds)\n    local result\n    result=$(score_process 1234 1000 50000 2500 \"memory hog process\")\n    local score=${result%%|*}\n    \n    (( score \u003e= 15 ))\n}\n\n#------------------------------------------------------------------------------\n# Recommendation tests\n#------------------------------------------------------------------------------\n\n@test \"score_process: score \u003e= 50 recommends KILL\" {\n    local result\n    result=$(score_process 1234 1 691200 100 \"old orphaned process\")\n    local rec\n    IFS='|' read -r _ rec _ \u003c\u003c\u003c \"$result\"\n    \n    [[ \"$rec\" == \"KILL\" ]]\n}\n\n@test \"score_process: score 20-49 recommends REVIEW\" {\n    local result\n    result=$(score_process 1234 1000 129600 100 \"moderately old process\")\n    local rec\n    IFS='|' read -r _ rec _ \u003c\u003c\u003c \"$result\"\n    \n    [[ \"$rec\" == \"REVIEW\" ]]\n}\n\n@test \"score_process: score \u003c 20 recommends SPARE\" {\n    local result\n    result=$(score_process 1234 1000 3600 100 \"fresh process\")\n    local rec\n    IFS='|' read -r _ rec _ \u003c\u003c\u003c \"$result\"\n    \n    [[ \"$rec\" == \"SPARE\" ]]\n}\n```\n\n## Mocking Considerations\nThe score_process function may need to be refactored for testability:\n- Extract pure scoring logic that doesn't depend on external state\n- Or use TEST_MODE to skip decision memory lookup\n\n## Success Criteria\n- [ ] Age-based scoring tested at all thresholds\n- [ ] Orphan detection tested\n- [ ] All pattern matches tested (tests, dev servers, agents)\n- [ ] Protected patterns tested\n- [ ] Memory hog detection tested\n- [ ] Recommendation levels tested","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:39:22.235531431-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:39:22.235531431-05:00","dependencies":[{"issue_id":"process_triage-ucg","depends_on_id":"process_triage-h2y","type":"blocks","created_at":"2026-01-14T22:40:49.203228376-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-ume","title":"Create install.sh with self-refresh mechanism","description":"## Purpose\nCreate a professional installation script that can be piped from curl, with self-refresh to avoid CDN caching issues.\n\n## Parent Epic\nInstallation Infrastructure (process_triage-n0r)\n\n## Depends On\n- Create VERSION file as single source of truth\n\n## The Self-Refresh Pattern\nWhen piped from curl, the installer re-fetches itself to avoid stale CDN cache:\n\n```bash\n#\\!/usr/bin/env bash\nset -euo pipefail\n\nGITHUB_REPO=\"Dicklesworthstone/process_triage\"\nRAW_URL=\"https://raw.githubusercontent.com/${GITHUB_REPO}/main\"\n\n#------------------------------------------------------------------------------\n# Self-refresh: re-download fresh copy when piped\n#------------------------------------------------------------------------------\nmaybe_self_refresh() {\n    # Only refresh if being piped AND not already refreshed\n    if [[ -p /dev/stdin ]] \u0026\u0026 [[ -z \"${PT_REFRESHED:-}\" ]]; then\n        # Re-execute with cache-busted URL\n        export PT_REFRESHED=1\n        exec bash \u003c(curl -fsSL \"${RAW_URL}/install.sh?cb=$(date +%s)\")\n    fi\n}\n\nmaybe_self_refresh\n```\n\n## Why Self-Refresh?\nGitHub's CDN (raw.githubusercontent.com) caches files aggressively.\n- User runs `curl ... | bash` right after a release\n- Gets old cached version\n- Installs outdated script\n\nSelf-refresh ensures fresh download by:\n1. Detecting piped input (`-p /dev/stdin`)\n2. Re-downloading with cache-buster timestamp\n3. Exec-ing the fresh version\n\n## Core Implementation Structure\n\n```bash\n#\\!/usr/bin/env bash\nset -euo pipefail\n\nVERSION=\"1.0.0\"  # Installer version (not pt version)\nGITHUB_REPO=\"Dicklesworthstone/process_triage\"\nRAW_URL=\"https://raw.githubusercontent.com/${GITHUB_REPO}/main\"\nRELEASES_URL=\"https://github.com/${GITHUB_REPO}/releases\"\n\n#==============================================================================\n# SELF-REFRESH\n#==============================================================================\nmaybe_self_refresh() { ... }\nmaybe_self_refresh\n\n#==============================================================================\n# LOGGING\n#==============================================================================\nlog_info() { printf '\\033[0;34mℹ\\033[0m %s\\n' \"$*\" \u003e\u00262; }\nlog_success() { printf '\\033[0;32m✓\\033[0m %s\\n' \"$*\" \u003e\u00262; }\nlog_error() { printf '\\033[0;31m✗\\033[0m %s\\n' \"$*\" \u003e\u00262; }\nlog_step() { printf '\\033[0;36m→\\033[0m %s\\n' \"$*\" \u003e\u00262; }\n\n#==============================================================================\n# UTILITIES\n#==============================================================================\nmktemp_dir() {\n    mktemp -d 2\u003e/dev/null || mktemp -d -t pt 2\u003e/dev/null || mktemp -d -t pt.XXXXXXXXXX\n}\n\nget_latest_version() { ... }\n\n#==============================================================================\n# DOWNLOAD\n#==============================================================================\ndownload() { ... }\nverify_checksum() { ... }\n\n#==============================================================================\n# INSTALLATION\n#==============================================================================\ninstall_pt() { ... }\nadd_to_path() { ... }\n\n#==============================================================================\n# MAIN\n#==============================================================================\nmain() {\n    log_step \"Installing pt (Process Triage)...\"\n    \n    # Determine version to install\n    local version=\"${PT_VERSION:-}\"\n    if [[ -z \"$version\" ]]; then\n        version=$(get_latest_version)\n    fi\n    \n    # Determine install location\n    local dest=\"${DEST:-$HOME/.local/bin}\"\n    if [[ \"${PT_SYSTEM:-}\" == \"1\" ]]; then\n        dest=\"/usr/local/bin\"\n    fi\n    \n    # Download and install\n    local temp_dir\n    temp_dir=$(mktemp_dir)\n    trap \"rm -rf '$temp_dir'\" EXIT\n    \n    download \"$version\" \"$temp_dir/pt\"\n    \n    if [[ \"${VERIFY:-}\" == \"1\" ]]; then\n        verify_checksum \"$temp_dir/pt\" \"$version\"\n    fi\n    \n    install_pt \"$temp_dir/pt\" \"$dest\"\n    \n    # Add to PATH if needed\n    if [[ \"${PT_NO_PATH:-}\" \\!= \"1\" ]]; then\n        add_to_path \"$dest\"\n    fi\n    \n    log_success \"pt v${version} installed to $dest/pt\"\n    log_info \"Run 'pt help' to get started.\"\n}\n\nmain \"$@\"\n```\n\n## Success Criteria\n- [ ] Self-refresh mechanism works\n- [ ] One-liner install works: `curl ... | bash`\n- [ ] Version detection from releases\n- [ ] Custom install location via DEST\n- [ ] System-wide install via PT_SYSTEM=1\n- [ ] Cache-busting on URLs","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:36:30.398788198-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:36:30.398788198-05:00","dependencies":[{"issue_id":"process_triage-ume","depends_on_id":"process_triage-nk1","type":"blocks","created_at":"2026-01-14T22:40:45.368196458-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-un6","title":"Implement dependency-weighted loss scaling","description":"## Task\nImplement loss scaling based on process dependencies.\n\n## Background\nSection 5.5 specifies:\nL_kill = L_kill × (1 + impact_score)\n\nKilling a process with many dependents is costlier.\n\n## Impact Factors\n- Child process count\n- Socket connections (ESTABLISHED)\n- Listening ports with clients\n- Shared memory segments\n- Lock files held\n- Open transactions\n\n## Implementation Notes\n- Compute impact score from collected evidence\n- Scale loss matrix entries\n- Preserve relative ordering (more dependencies = higher cost)\n- Consider dependency graph depth\n\n## Impact Score Formula\nimpact_score = \n  0.1 × child_count +\n  0.2 × established_connections +\n  0.5 × listening_ports +\n  0.3 × open_write_handles +\n  0.1 × shared_memory_segments\n\n## Output Structure\n{\n  \"dependency_scaling\": {\n    \"impact_score\": 1.5,\n    \"original_kill_loss\": 100,\n    \"scaled_kill_loss\": 250,\n    \"factors\": {\"children\": 3, \"connections\": 5, \"ports\": 1}\n  }\n}\n\n## Deliverables\n- Rust module: decision/dependency_loss.rs\n- Impact score computation\n- Loss scaling\n- Unit tests\n- Documentation","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:29:17.131682166-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:29:17.131682166-05:00"}
{"id":"process_triage-urd","title":"Implement cgroup and systemd unit collection","description":"## Task\nImplement collection of cgroup membership and systemd unit information.\n\n## Background\nCgroup/systemd info reveals:\n- Whether process is supervised\n- Resource limits applied\n- Unit/service name for supervisor-aware actions\n- Container membership\n\n## Data to Collect\nPer process:\n- Cgroup hierarchy path\n- Systemd unit (if any)\n- Resource limits (cpu, memory)\n- Container ID (Docker, podman, etc.)\n- Slice membership\n\n## Data Sources\n- /proc/[pid]/cgroup: cgroup membership\n- /sys/fs/cgroup/...: cgroup limits and stats\n- systemctl status [pid]: unit info (via systemd)\n- Container detection from cgroup path patterns\n\n## Implementation Notes\n- cgroup v1 vs v2 handling\n- Parse cgroup paths to extract:\n  - /docker/\u003ccontainer_id\u003e\n  - /kubepods/\u003cpod\u003e/\u003ccontainer\u003e\n  - /system.slice/\u003cunit\u003e\n  - /user.slice/user-\u003cuid\u003e.slice\n- Query systemctl for unit details\n- Handle non-systemd systems gracefully\n\n## Output Structure\n{\n  \"pid\": 1234,\n  \"cgroup_v2_path\": \"/system.slice/myapp.service\",\n  \"systemd_unit\": {\"name\": \"myapp.service\", \"type\": \"service\", \"active\": true},\n  \"container\": {\"type\": \"docker\", \"id\": \"abc123\"},\n  \"resource_limits\": {\"cpu_quota_us\": 100000, \"memory_max_bytes\": 1073741824}\n}\n\n## Deliverables\n- Rust module: collect/cgroup.rs\n- Systemd integration: collect/systemd.rs\n- Container detection: collect/container.rs\n- Unit tests\n- Documentation","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:26:06.397975543-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:26:06.397975543-05:00"}
{"id":"process_triage-v1w","title":"Implement audit logging with integrity verification","description":"## Overview\nImplement comprehensive audit logging with cryptographic integrity verification.\n\n## Background\nThe plan specifies an append-only audit log capturing all decisions and actions. The log should be tamper-evident: if someone modifies historical entries, the integrity check should detect it.\n\n## Why It Matters\nAudit logs are essential for:\n1. Debugging: Understanding why a process was killed\n2. Compliance: Proving proper procedures were followed\n3. Learning: Feeding back to improve the model\n4. Forensics: Investigating incidents after the fact\n\n## Technical Approach\n1. Structured log format (JSON lines)\n2. Hash chain: each entry includes hash of previous entry\n3. Periodic checkpoints with full state hash\n4. Log rotation with integrity preservation\n5. Export capability for external analysis\n\n## Log Entry Schema\n- timestamp: ISO-8601 with microseconds\n- event_type: scan|recommend|action|policy_check|error\n- session_id: UUID for this pt session\n- details: Event-specific structured data\n- prev_hash: SHA-256 of previous entry\n- entry_hash: SHA-256 of this entry (excluding entry_hash field)\n\n## Integrity Verification\n- bd triage verify-log: Check hash chain integrity\n- Detect: Missing entries, modified entries, truncated log\n- Report: First broken link in chain\n\n## Log Rotation\n- Rotate at 100MB or daily (configurable)\n- Rotated files get final checkpoint hash\n- New file starts with reference to previous file's checkpoint\n\n## Success Criteria\n- All events logged with full context\n- Hash chain unbroken during normal operation\n- Tampering detected by verification\n- Log rotation preserves integrity chain","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:33:01.188865596-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:33:50.384628714-05:00"}
{"id":"process_triage-vfz","title":"Implement signature-based prior override system","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:34:59.90604139-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:34:59.90604139-05:00"}
{"id":"process_triage-vpb","title":"Implement log_* functions with emoji prefixes","description":"## Purpose\nCreate a consistent set of logging functions with emoji prefixes and color coding, matching the pattern from repo_updater and giil.\n\n## Parent Epic\nConsole Output Styling Enhancement (process_triage-y8e)\n\n## Depends On\n- Add TTY detection and NO_COLOR support (must have color variables defined)\n\n## Current State\npt has some output functions but they're inconsistent:\n- `log()` writes to log file only\n- Direct `printf` calls scattered throughout\n- No consistent prefix scheme\n\n## Implementation\n\n### Logging Function Set\n```bash\n#------------------------------------------------------------------------------\n# Logging functions (all output to stderr)\n#------------------------------------------------------------------------------\n\nlog_info() {\n    printf '%b\\n' \"${BLUE}ℹ${RESET} $*\" \u003e\u00262\n}\n\nlog_success() {\n    printf '%b\\n' \"${GREEN}✓${RESET} $*\" \u003e\u00262\n}\n\nlog_warn() {\n    printf '%b\\n' \"${YELLOW}⚠${RESET} $*\" \u003e\u00262\n}\n\nlog_error() {\n    printf '%b\\n' \"${RED}✗${RESET} $*\" \u003e\u00262\n}\n\nlog_step() {\n    printf '%b\\n' \"${CYAN}→${RESET} $*\" \u003e\u00262\n}\n\nlog_debug() {\n    [[ \"${PT_DEBUG:-}\" == \"1\" ]] || return 0\n    printf '%b\\n' \"${DIM}[DEBUG] $*${RESET}\" \u003e\u00262\n}\n\nlog_verbose() {\n    [[ \"${VERBOSE:-}\" == \"1\" ]] || return 0\n    printf '%b\\n' \"${DIM}$*${RESET}\" \u003e\u00262\n}\n```\n\n### Emoji Prefix Scheme\n| Function | Emoji | Color | Purpose |\n|----------|-------|-------|---------|\n| log_info | ℹ | Blue | Informational messages |\n| log_success | ✓ | Green | Success confirmations |\n| log_warn | ⚠ | Yellow | Warnings (non-fatal) |\n| log_error | ✗ | Red | Errors |\n| log_step | → | Cyan | Progress steps |\n| log_debug | [DEBUG] | Dim | Debug output (PT_DEBUG=1) |\n| log_verbose | (none) | Dim | Verbose output |\n\n### Why stderr?\nAll logging goes to stderr (`\u003e\u00262`) because:\n1. stdout is reserved for data output (JSON, process lists)\n2. Allows piping: `pt scan --json | jq '.'`\n3. Matches Unix convention\n\n### File Logging (keep existing)\n```bash\n# Existing log() function writes to file - keep it\nlog() {\n    printf '[%s] %s\\n' \"$(date '+%Y-%m-%d %H:%M:%S')\" \"$1\" \u003e\u003e \"$LOG_FILE\"\n}\n\n# Consider: Also call log() from log_info/log_error for audit trail\nlog_error() {\n    printf '%b\\n' \"${RED}✗${RESET} $*\" \u003e\u00262\n    log \"ERROR: $*\"  # Also write to file\n}\n```\n\n## Migration\nReplace existing output calls:\n```bash\n# Before\necho \"Found $count candidates\"\nprintf 'Error: %s\\n' \"$msg\"\n\n# After  \nlog_info \"Found $count candidates\"\nlog_error \"$msg\"\n```\n\n## Success Criteria\n- [ ] All log_* functions implemented\n- [ ] Consistent emoji prefix scheme\n- [ ] All output goes to stderr\n- [ ] Colors respect USE_COLOR variable\n- [ ] Debug output only shown when PT_DEBUG=1\n- [ ] Existing file logging preserved","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:33:31.728774252-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:33:31.728774252-05:00","dependencies":[{"issue_id":"process_triage-vpb","depends_on_id":"process_triage-18z","type":"blocks","created_at":"2026-01-14T22:40:43.702908755-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-wb3","title":"Implement log-odds and posterior computation","description":"## Task\nImplement the core posterior computation that combines all evidence.\n\n## Background\nSection 4.3 specifies:\nP(C|x) ∝ P(C) × Π_j P(x_j|C)\n\nIn log domain:\nlog P(C|x) = log P(C) + Σ_j log P(x_j|C) - log_normalizer\n\nwhere log_normalizer = log_sum_exp over all classes.\n\nFor SPRT-style decisions (Section 5.2):\nlog_odds = log P(abandoned|x) - log P(useful|x)\n\n## Functions Needed\n- compute_log_posterior(log_prior, log_likelihoods) → log_posterior\n- normalize_log_posterior(log_unnormalized) → log_posterior\n- log_odds(log_p1, log_p2) = log_p1 - log_p2\n- posterior_to_odds(posterior_vec, class1, class2)\n- odds_to_posterior(odds, prior_odds)\n\n## Implementation Notes\n- log_normalizer via log_sum_exp\n- Handle numerical edge cases (all likelihoods very small)\n- Store both unnormalized and normalized for auditing\n- Support incremental updates (streaming evidence)\n\n## Output Structure\nFor galaxy-brain mode, output should include:\n- log_prior per class\n- log_likelihood per feature per class\n- log_posterior per class\n- log_odds for key comparisons\n\n## Deliverables\n- Rust module: math/posterior.rs\n- Unit tests\n- Documentation","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:24:00.4661426-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:24:00.4661426-05:00"}
{"id":"process_triage-wlp","title":"Implement process ancestry analysis for supervision","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:34:50.518833855-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:34:50.518833855-05:00"}
{"id":"process_triage-wme","title":"Implement galaxy-brain mode mathematical display","description":"## Overview\nImplement galaxy-brain mode: full mathematical transparency showing every step of Bayesian inference.\n\n## Background\nThe plan specifies galaxy-brain mode for power users who want to see the complete mathematical reasoning. This means showing prior distributions, likelihood computations, posterior updates, and decision-theoretic calculations in accessible mathematical notation.\n\n## Why It Matters\nGalaxy-brain mode serves multiple purposes:\n1. Education: Users learn Bayesian inference through concrete examples\n2. Debugging: Developers can verify the math is correct\n3. Trust: Full transparency eliminates black-box concerns\n4. Tuning: Users can see which priors to adjust for their environment\n\n## Technical Approach\n1. Capture computation trace during inference\n2. Format mathematical expressions for terminal display\n3. Support multiple verbosity levels (summary → detail → full trace)\n4. Use Unicode math symbols where supported\n5. Provide fallback ASCII representation\n\n## Display Format\n\n\n## Success Criteria\n- Full math trace available for any process\n- Multiple verbosity levels implemented\n- Both Unicode and ASCII modes work\n- Computation trace matches actual inference","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:32:04.122111209-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:32:48.881691652-05:00"}
{"id":"process_triage-y1z","title":"Define semantic exit codes","description":"## Purpose\nDefine meaningful exit codes for all error conditions, enabling scripting and automation.\n\n## Parent Epic\nCode Organization \u0026 Standards (process_triage-a6q)\n\n## Current State\npt uses generic exit codes (0 for success, 1 for error). No semantic meaning.\n\n## Exit Code Scheme\n\n```bash\n#==============================================================================\n# EXIT CODES\n#==============================================================================\n# Semantic exit codes for scripting and automation\n#\n# 0-9:   Success and user/usage states\n# 10-19: Dependency and environment errors\n# 20-29: Operation errors\n# 30-39: Update errors\n# 90+:   Internal errors\n\n# Success\nreadonly EXIT_SUCCESS=0\n\n# User/usage (1-9)\nreadonly EXIT_USAGE_ERROR=1       # Bad CLI arguments\nreadonly EXIT_NO_CANDIDATES=2     # No processes found (not an error, but distinct)\nreadonly EXIT_USER_CANCELLED=3    # User cancelled operation\n\n# Dependencies (10-19)\nreadonly EXIT_MISSING_GUM=10      # gum not available and couldn't install\nreadonly EXIT_MISSING_JQ=11       # jq not available (optional feature degraded)\nreadonly EXIT_MISSING_BASH=12     # Bash version too old\n\n# Operations (20-29)\nreadonly EXIT_KILL_FAILED=20      # Some processes couldn't be killed\nreadonly EXIT_KILL_PARTIAL=21     # Some killed, some failed\nreadonly EXIT_PERMISSION=22       # Permission denied\n\n# Updates (30-39)\nreadonly EXIT_UPDATE_NETWORK=30   # Network error during update check\nreadonly EXIT_UPDATE_CHECKSUM=31  # Checksum verification failed\nreadonly EXIT_UPDATE_SYNTAX=32    # Downloaded file not valid bash\nreadonly EXIT_UPDATE_WRITE=33     # Couldn't write updated script\n\n# Internal (90+)\nreadonly EXIT_INTERNAL=90         # Bug in pt (should never happen)\n```\n\n## Usage in Code\n\n```bash\n# Before (generic)\nlog_error \"Unknown command\"\nexit 1\n\n# After (semantic)\nlog_error \"Unknown command: $1\"\nlog_info \"Run 'pt help' for usage.\"\nexit $EXIT_USAGE_ERROR\n```\n\n## Documentation in Help\n```bash\ncmd_help() {\n    cat \u003c\u003c 'EOF'\n...\n\nEXIT CODES\n  0   Success\n  1   Usage error (bad arguments)\n  2   No candidates found\n  3   User cancelled\n  10  gum not available\n  20  Kill operation failed\n  30  Network error (update)\n  31  Checksum mismatch (update)\n  90  Internal error (bug)\nEOF\n}\n```\n\n## Benefits\n1. **Scripting**: `pt scan; case $? in 2) echo \"System clean\";; esac`\n2. **CI/CD**: Different handling for different failures\n3. **Debugging**: Know what went wrong without parsing output\n4. **Consistency**: Same meaning every time\n\n## Success Criteria\n- [ ] All exit codes defined as readonly constants\n- [ ] Every exit statement uses a constant\n- [ ] Exit codes documented in help\n- [ ] README includes exit code reference\n- [ ] No raw exit 1 statements remain","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:40:16.838311908-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:40:16.838311908-05:00","dependencies":[{"issue_id":"process_triage-y1z","depends_on_id":"process_triage-8ng","type":"blocks","created_at":"2026-01-14T22:40:50.649458071-05:00","created_by":"Dicklesworthstone"}]}
{"id":"process_triage-y4a","title":"Implement time-varying hazard model","description":"## Task\nImplement the regime-based hazard model for abandonment risk.\n\n## Background\nSection 4.5 and 4.21 specify time-varying hazards:\n- Define regimes based on covariates (TTY lost, PPID=1, IO flatline)\n- Per-regime hazard λ_r ~ Gamma(α_r, β_r)\n- Posterior after exposure E_r and events N_r: Gamma(α_r + N_r, β_r + E_r)\n- Survival: S(t) = exp(-Σ_r λ_r × E_r)\n\n## Regime Examples\n1. **tty_lost**: Process lost controlling terminal\n2. **orphaned**: PPID became 1 (init)\n3. **io_flatline**: No IO for extended period\n4. **cpu_runaway**: Sustained high CPU\n5. **normal**: None of the above\n\n## Implementation Notes\n- Track time spent in each regime\n- Update Gamma posteriors per regime\n- Compute conditional survival (point estimate λ̂)\n- Compute marginal survival (Lomax tails for uncertainty)\n- Use hazard inflation as evidence term\n\n## Output Structure\n{\n  \"regimes\": [\n    {\"name\": \"tty_lost\", \"exposure_s\": 3600, \"events\": 0, \"lambda_mean\": 0.00083},\n    {\"name\": \"io_flatline\", \"exposure_s\": 1800, \"events\": 0, \"lambda_mean\": 0.00056}\n  ],\n  \"survival_estimate\": 0.02,\n  \"hazard_interpretation\": \"TTY loss dominates hazard; high abandonment risk\"\n}\n\n## Galaxy-Brain Card\nhazard_time_varying card shows:\n- λ_r | data ~ Gamma(α_r + N_r, β_r + E_r)\n- S(t) = exp(-Σ_r λ_r × E_r)\n- Per-regime breakdown\n\n## Deliverables\n- Rust module: inference/hazard.rs\n- Regime detection logic\n- Unit tests\n- Documentation","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-15T03:27:16.295311124-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-15T03:27:16.295311124-05:00"}
{"id":"process_triage-y8e","title":"Console Output Styling Enhancement","description":"## Overview\nUpgrade pt's console output system to match the quality standards established in repo_updater and giil projects.\n\n## Current State\n- pt uses gum for UI but has NO fallback when gum is unavailable\n- No TTY detection - colors may break in non-interactive environments\n- No NO_COLOR environment variable support (accessibility standard)\n- Logging functions exist but lack consistent emoji prefixes and color coding\n\n## Target State\nImplement a 3-tier fallback system:\n1. **Tier 1: gum** - Beautiful styled output with borders/spinners when available\n2. **Tier 2: ANSI** - Colored text with emoji prefixes when TTY detected\n3. **Tier 3: Plain** - No formatting for pipes, CI, or NO_COLOR environments\n\n## Rationale\n- **Accessibility**: NO_COLOR is a recognized standard (https://no-color.org/)\n- **CI Compatibility**: GitHub Actions and other CI systems need clean output\n- **Graceful Degradation**: Tool should work everywhere, look best where possible\n- **Consistency**: Match the UX quality of our other bash tools\n\n## Implementation Pattern (from repo_updater)\n```bash\nif [[ -t 2 ]] \u0026\u0026 [[ -z \"${NO_COLOR:-}\" ]]; then\n    RED='\\033[0;31m'\n    GREEN='\\033[0;32m'\n    # etc...\nelse\n    RED='' GREEN='' YELLOW='' # Disable all color\nfi\n```\n\n## Success Criteria\n- [ ] Works in interactive terminal with full styling\n- [ ] Works in CI environments without ANSI garbage\n- [ ] Respects NO_COLOR environment variable\n- [ ] All log output goes to stderr (stdout reserved for data)\n- [ ] Consistent emoji prefix scheme across all log levels","status":"open","priority":1,"issue_type":"epic","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:31:04.083856408-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:31:04.083856408-05:00"}
{"id":"process_triage-zbd","title":"Add E2E test for main pt workflow","description":"## Purpose\nCreate comprehensive end-to-end tests that verify the complete pt workflow from scan through kill, including decision memory persistence.\n\n## Parent Epic\nExpanded Test Coverage (process_triage-bgd)\n\n## Depends On\n- Test helper with mock injection (process_triage-h2y)\n\n## Why E2E Tests Are Critical\nUnit tests verify individual functions work. E2E tests verify:\n- Components integrate correctly\n- Data flows through the entire pipeline\n- User-visible behavior matches expectations\n- Real-world scenarios work end-to-end\n\n## Test Scenarios\n\n### test/test_e2e_workflow.bats\n\n```bash\n#\\!/usr/bin/env bats\n\nload 'test_helper/common'\n\nsetup() {\n    setup_test_env\n    test_start \"$BATS_TEST_NAME\" \"E2E workflow test\"\n}\n\nteardown() {\n    test_end \"$BATS_TEST_NAME\" \"${BATS_TEST_COMPLETED:-fail}\"\n    restore_path\n    teardown_test_env\n}\n\n#==============================================================================\n# SCAN WORKFLOW TESTS\n#==============================================================================\n\n@test \"E2E: scan finds stuck test runner and scores correctly\" {\n    test_info \"Setting up: mock ps with stuck bun test process\"\n    \n    # Create mock ps with a stuck test\n    create_mock_ps \"$(mock_ps_with_stuck_test 7200)\"\n    use_mock_bin\n    \n    test_info \"Running: pt scan\"\n    run \"$PT_SCRIPT\" scan\n    \n    test_info \"Exit code: $status\"\n    test_info \"Output lines: $(echo \"$output\" | wc -l)\"\n    \n    # Verify exit code\n    assert_equals \"0\" \"$status\" \"pt scan should succeed\"\n    \n    # Verify stuck test is detected\n    assert_contains \"$output\" \"bun test\" \"Should find bun test process\"\n    \n    # Verify scoring (should be KILL or REVIEW based on age)\n    assert_contains \"$output\" \"KILL\\|REVIEW\" \"Should recommend action\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E: scan with no candidates shows clean message\" {\n    test_info \"Setting up: mock ps with only short-lived processes\"\n    \n    # Create mock ps with only recent/protected processes\n    create_mock_ps \"$(mock_process 1000 1 1800 64 'vim file.txt')\"\n    use_mock_bin\n    \n    test_info \"Running: pt scan\"\n    run \"$PT_SCRIPT\" scan\n    \n    test_info \"Exit code: $status\"\n    \n    # Should succeed but indicate no candidates\n    assert_equals \"0\" \"$status\" \"pt scan should succeed\"\n    \n    # Output should indicate no candidates or be empty\n    test_info \"Verifying output indicates no candidates\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E: scan excludes protected system processes\" {\n    test_info \"Setting up: mock ps with system processes\"\n    \n    create_mock_ps \"\\\n$(mock_process 1 0 9999999 100 '/usr/lib/systemd/systemd')\n$(mock_process 2000 1 9999999 50 'sshd: user@pts/0')\n$(mock_process 3000 1 9999999 30 '/usr/sbin/cron')\n$(mock_process 4000 1000 200000 512 'bun test --watch')\n\"\n    use_mock_bin\n    \n    test_info \"Running: pt scan\"\n    run \"$PT_SCRIPT\" scan\n    \n    # Should NOT include protected processes\n    assert_not_contains \"$output\" \"systemd\" \"Should not flag systemd\"\n    assert_not_contains \"$output\" \"sshd\" \"Should not flag sshd\"\n    assert_not_contains \"$output\" \"cron\" \"Should not flag cron\"\n    \n    # Should include the test runner\n    assert_contains \"$output\" \"bun test\" \"Should flag stuck test\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E: scan with mixed processes sorts by score\" {\n    test_info \"Setting up: mock ps with mixed scenarios\"\n    \n    create_mock_ps \"$(mock_ps_mixed_scenario)\"\n    use_mock_bin\n    \n    test_info \"Running: pt scan\"\n    run \"$PT_SCRIPT\" scan\n    \n    test_info \"Verifying score-based ordering\"\n    \n    # Higher-scored items should appear first\n    # Orphan + old should score higher than just old\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# DECISION MEMORY INTEGRATION TESTS\n#==============================================================================\n\n@test \"E2E: decision memory persists across invocations\" {\n    skip_if_no_jq\n    \n    test_info \"Setting up: save a kill decision\"\n    \n    # Manually write a decision\n    echo '{\"bun test --watch\": \"kill\"}' \u003e \"${CONFIG_DIR}/decisions.json\"\n    \n    test_info \"Verifying decision file exists\"\n    [[ -f \"${CONFIG_DIR}/decisions.json\" ]]\n    \n    test_info \"Running: pt history\"\n    run \"$PT_SCRIPT\" history\n    \n    # Should show the saved decision\n    assert_contains \"$output\" \"bun test\" \"History should show saved pattern\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E: past kill decision increases score\" {\n    skip_if_no_jq\n    \n    test_info \"Setting up: decision memory with kill pattern\"\n    \n    # Save a kill decision for a pattern\n    echo '{\"bun test\": \"kill\"}' \u003e \"${CONFIG_DIR}/decisions.json\"\n    \n    # Create process matching that pattern\n    create_mock_ps \"$(mock_process 12345 1000 4000 100 'bun test --watch')\"\n    use_mock_bin\n    \n    test_info \"Running: pt scan\"\n    run \"$PT_SCRIPT\" scan\n    \n    # The process should get boosted score due to past kill decision\n    # This is hard to verify directly without seeing the score\n    # But we can verify it's flagged\n    assert_contains \"$output\" \"bun test\" \"Process should be flagged\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E: past spare decision decreases score\" {\n    skip_if_no_jq\n    \n    test_info \"Setting up: decision memory with spare pattern\"\n    \n    # Save a spare decision\n    echo '{\"gunicorn\": \"spare\"}' \u003e \"${CONFIG_DIR}/decisions.json\"\n    \n    # Create a gunicorn process that would normally be flagged\n    create_mock_ps \"$(mock_process 12345 1000 100000 200 'gunicorn --workers 4')\"\n    use_mock_bin\n    \n    test_info \"Running: pt scan\"\n    run \"$PT_SCRIPT\" scan\n    \n    # With spare decision, score should be lower\n    # May not appear at all, or should be SPARE recommendation\n    test_info \"Verifying spare decision affects scoring\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E: clear command removes all decisions\" {\n    skip_if_no_jq\n    \n    test_info \"Setting up: populate decision memory\"\n    \n    echo '{\"pattern1\": \"kill\", \"pattern2\": \"spare\", \"pattern3\": \"kill\"}' \u003e \"${CONFIG_DIR}/decisions.json\"\n    \n    # Verify decisions exist\n    local count_before\n    count_before=$(jq 'length' \"${CONFIG_DIR}/decisions.json\")\n    test_info \"Decisions before clear: $count_before\"\n    assert_equals \"3\" \"$count_before\" \"Should have 3 decisions\"\n    \n    test_info \"Running: pt clear (with mocked confirmation)\"\n    # Need to mock gum confirm or run in non-interactive mode\n    echo 'y' | \"$PT_SCRIPT\" clear 2\u003e/dev/null || true\n    \n    # Verify decisions cleared\n    local count_after\n    count_after=$(jq 'length' \"${CONFIG_DIR}/decisions.json\")\n    test_info \"Decisions after clear: $count_after\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# HELP AND VERSION TESTS\n#==============================================================================\n\n@test \"E2E: help command shows all subcommands\" {\n    test_info \"Running: pt help\"\n    run \"$PT_SCRIPT\" help\n    \n    assert_equals \"0\" \"$status\" \"Help should succeed\"\n    \n    # Verify all commands documented\n    assert_contains \"$output\" \"scan\" \"Should document scan command\"\n    assert_contains \"$output\" \"history\" \"Should document history command\"\n    assert_contains \"$output\" \"clear\" \"Should document clear command\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E: version command shows version number\" {\n    test_info \"Running: pt --version\"\n    run \"$PT_SCRIPT\" --version\n    \n    assert_equals \"0\" \"$status\" \"Version should succeed\"\n    assert_contains \"$output\" \"pt version\" \"Should show version prefix\"\n    \n    # Verify semver format\n    [[ \"$output\" =~ [0-9]+\\.[0-9]+\\.[0-9]+ ]]\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E: unknown command shows error and hint\" {\n    test_info \"Running: pt unknowncommand\"\n    run \"$PT_SCRIPT\" unknowncommand\n    \n    # Should fail\n    [[ $status -ne 0 ]]\n    \n    # Should show helpful message\n    assert_contains \"$output\" \"Unknown\\|unknown\\|help\" \"Should hint at help\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n#==============================================================================\n# CONFIGURATION TESTS\n#==============================================================================\n\n@test \"E2E: respects PROCESS_TRIAGE_CONFIG environment variable\" {\n    test_info \"Setting up: custom config directory\"\n    \n    local custom_config=\"${TEST_DIR}/custom_config\"\n    mkdir -p \"$custom_config\"\n    \n    export PROCESS_TRIAGE_CONFIG=\"$custom_config\"\n    \n    test_info \"Running: pt history (should use custom config)\"\n    run \"$PT_SCRIPT\" history\n    \n    # Should succeed and potentially create files in custom location\n    assert_equals \"0\" \"$status\" \"Should succeed with custom config\"\n    \n    BATS_TEST_COMPLETED=pass\n}\n\n@test \"E2E: creates config directory if missing\" {\n    test_info \"Setting up: empty config path\"\n    \n    local new_config=\"${TEST_DIR}/new_config_dir\"\n    export PROCESS_TRIAGE_CONFIG=\"$new_config\"\n    \n    # Verify doesn't exist\n    [[ \\! -d \"$new_config\" ]]\n    \n    test_info \"Running: pt (should create config dir)\"\n    run \"$PT_SCRIPT\" help  # Safe command that triggers init\n    \n    # Verify created (or would be created on first real operation)\n    \n    BATS_TEST_COMPLETED=pass\n}\n```\n\n## Setup Requirements\n\n### test/test_e2e_workflow.bats setup\n```bash\n# At top of file\nPT_SCRIPT=\"${BATS_TEST_DIRNAME}/../pt\"\n\n# Verify pt script exists\nsetup_file() {\n    if [[ \\! -x \"$PT_SCRIPT\" ]]; then\n        echo \"ERROR: pt script not found at $PT_SCRIPT\" \u003e\u00262\n        exit 1\n    fi\n}\n```\n\n## Success Criteria\n- [ ] Scan workflow tested end-to-end\n- [ ] Protected process exclusion verified\n- [ ] Decision memory persistence tested\n- [ ] Clear command tested\n- [ ] Help and version tested\n- [ ] Unknown command error handling tested\n- [ ] Configuration override tested\n- [ ] All tests have detailed logging\n- [ ] All tests log start/end with pass/fail","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-14T22:46:42.878971197-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-14T22:46:42.878971197-05:00","dependencies":[{"issue_id":"process_triage-zbd","depends_on_id":"process_triage-h2y","type":"blocks","created_at":"2026-01-14T22:50:29.019098458-05:00","created_by":"Dicklesworthstone"}]}
